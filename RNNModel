<?xml version="1.0" ?>
<root>
	<model>
		Model details:
		<layers>
			<layer>1 name:input_1 shape:[(None, 1, 120)] </layer>
			<layer>2 name:lstm units:256  return_sequences:False </layer>
			<layer>3 name:dense units:32 </layer>
			<layer>4 name:dropout units:0.05 </layer>
			<layer>5 name:dense_1 units:10 </layer>
			<layer>6 name:dense_2 units:1 </layer>
		</layers>
		<history>
			<loss> epoch:0 value:0.016589945182204247 </loss>
			<loss> epoch:1 value:0.053581465035676956 </loss>
			<loss> epoch:2 value:0.06298468261957169 </loss>
			<loss> epoch:3 value:0.06348811835050583 </loss>
			<loss> epoch:4 value:0.06867840886116028 </loss>
			<loss> epoch:5 value:0.0663367211818695 </loss>
		</history>
	</model>
	<data>
		<row> train/prediction: 0.7791817496373028/[0.47743765] </row>
		<row> train/prediction: 0.7792580386353052/[0.47819713] </row>
		<row> train/prediction: 0.7793343276332507/[0.47850406] </row>
		<row> train/prediction: 0.7794106166312531/[0.47926432] </row>
		<row> train/prediction: 0.7794869056292555/[0.48080656] </row>
		<row> train/prediction: 0.779563194627201/[0.4816166] </row>
		<row> train/prediction: 0.7796394836252034/[0.48207128] </row>
		<row> train/prediction: 0.7797157726232058/[0.48380426] </row>
		<row> train/prediction: 0.7797920616211513/[0.48418754] </row>
		<row> train/prediction: 0.7798683506191537/[0.48352966] </row>
		<row> train/prediction: 0.7799446396170993/[0.48363304] </row>
		<row> train/prediction: 0.7800209286151016/[0.48223162] </row>
		<row> train/prediction: 0.780097217613104/[0.48099917] </row>
		<row> train/prediction: 0.7801735066110496/[0.4803614] </row>
		<row> train/prediction: 0.7802497956090519/[0.47912824] </row>
		<row> train/prediction: 0.7803260846070543/[0.47881687] </row>
		<row> train/prediction: 0.7804023736049999/[0.47894317] </row>
		<row> train/prediction: 0.7804786626030022/[0.4783698] </row>
		<row> train/prediction: 0.7844456904980461/[0.47797513] </row>
		<row> train/prediction: 0.7845219794960485/[0.4784229] </row>
		<row> train/prediction: 0.7845982684940509/[0.47919038] </row>
		<row> train/prediction: 0.7846745574919964/[0.4805637] </row>
		<row> train/prediction: 0.7847508464899988/[0.48141846] </row>
		<row> train/prediction: 0.7848271354880012/[0.48269486] </row>
		<row> train/prediction: 0.784903678782598/[0.4839598] </row>
		<row> train/prediction: 0.7849799677806004/[0.48592618] </row>
		<row> train/prediction: 0.7850562567786028/[0.48781088] </row>
		<row> train/prediction: 0.7851325457765483/[0.48904085] </row>
		<row> train/prediction: 0.7852088347745507/[0.49076203] </row>
		<row> train/prediction: 0.7852851237725531/[0.49190587] </row>
		<row> train/prediction: 0.7853614127704986/[0.49239826] </row>
		<row> train/prediction: 0.785437701768501/[0.4929208] </row>
		<row> train/prediction: 0.7855139907665034/[0.4940169] </row>
		<row> train/prediction: 0.785590279764449/[0.4938347] </row>
		<row> train/prediction: 0.7856665687624513/[0.49399543] </row>
		<row> train/prediction: 0.7857428577604537/[0.49359712] </row>
		<row> train/prediction: 0.7858191467583993/[0.49473923] </row>
		<row> train/prediction: 0.7858954357564016/[0.49574926] </row>
		<row> train/prediction: 0.7859717247543472/[0.4962965] </row>
		<row> train/prediction: 0.7860480137523496/[0.4954671] </row>
		<row> train/prediction: 0.7861243027503519/[0.49398026] </row>
		<row> train/prediction: 0.7862005917482975/[0.49281305] </row>
		<row> train/prediction: 0.7862768807462999/[0.49180657] </row>
		<row> train/prediction: 0.7863531697443022/[0.49019015] </row>
		<row> train/prediction: 0.7864294587422478/[0.48849338] </row>
		<row> train/prediction: 0.7865057477402502/[0.4878495] </row>
		<row> train/prediction: 0.7865820367382526/[0.4876473] </row>
		<row> train/prediction: 0.7866583257361981/[0.487473] </row>
		<row> train/prediction: 0.7867346147342005/[0.4867618] </row>
		<row> train/prediction: 0.7868109037322029/[0.48536825] </row>
		<row> train/prediction: 0.7868871927301484/[0.48442134] </row>
		<row> train/prediction: 0.7869634817281508/[0.48404473] </row>
		<row> train/prediction: 0.7870397707260963/[0.48308715] </row>
		<row> train/prediction: 0.7871160597240987/[0.48230743] </row>
		<row> train/prediction: 0.7871923487221011/[0.48187315] </row>
		<row> train/prediction: 0.7872686377200466/[0.4811516] </row>
		<row> train/prediction: 0.787344926718049/[0.48045534] </row>
		<row> train/prediction: 0.7874212157160514/[0.47964096] </row>
		<row> train/prediction: 0.7874975047139969/[0.47820652] </row>
		<row> train/prediction: 0.7875737937119993/[0.47668904] </row>
		<row> train/prediction: 0.7876500827100017/[0.4756059] </row>
		<row> train/prediction: 0.7877263717079472/[0.47399846] </row>
		<row> train/prediction: 0.7878026607059496/[0.47287697] </row>
		<row> train/prediction: 0.787878949703952/[0.4721294] </row>
		<row> train/prediction: 0.7879552387018975/[0.4718266] </row>
		<row> train/prediction: 0.7880315276998999/[0.4722637] </row>
		<row> train/prediction: 0.7881078166979023/[0.47234467] </row>
		<row> train/prediction: 0.7881841056958478/[0.47250682] </row>
		<row> train/prediction: 0.7882603946938502/[0.4724595] </row>
		<row> train/prediction: 0.7883366836917958/[0.47201014] </row>
		<row> train/prediction: 0.7884129726897982/[0.4711447] </row>
		<row> train/prediction: 0.7884892616878005/[0.47104546] </row>
		<row> train/prediction: 0.7885655506857461/[0.47124383] </row>
		<row> train/prediction: 0.7886418396837485/[0.47173503] </row>
		<row> train/prediction: 0.7887181286817508/[0.47219506] </row>
		<row> train/prediction: 0.7887944176796964/[0.47237918] </row>
		<row> train/prediction: 0.7888707066776988/[0.47289246] </row>
		<row> train/prediction: 0.7889469956757011/[0.47379634] </row>
		<row> train/prediction: 0.7890232846736467/[0.47478008] </row>
		<row> train/prediction: 0.7890995736716491/[0.474956] </row>
		<row> train/prediction: 0.7891758626696515/[0.47520494] </row>
		<row> train/prediction: 0.789252151667597/[0.47493556] </row>
		<row> train/prediction: 0.7893284406655994/[0.47549295] </row>
		<row> train/prediction: 0.7894047296635449/[0.47554874] </row>
		<row> train/prediction: 0.7894810186615473/[0.475417] </row>
		<row> train/prediction: 0.7895573076595497/[0.47556356] </row>
		<row> train/prediction: 0.7896335966574952/[0.47566724] </row>
		<row> train/prediction: 0.7897098856554976/[0.4745512] </row>
		<row> train/prediction: 0.7897861746535/[0.47366652] </row>
		<row> train/prediction: 0.7898624636514455/[0.47296306] </row>
		<row> train/prediction: 0.7899387526494479/[0.47276026] </row>
		<row> train/prediction: 0.7900150416474503/[0.4724686] </row>
		<row> train/prediction: 0.7900913306453958/[0.47139484] </row>
		<row> train/prediction: 0.7901676196433982/[0.47131783] </row>
		<row> train/prediction: 0.7902439086414006/[0.47242546] </row>
		<row> train/prediction: 0.7903201976393461/[0.47417548] </row>
		<row> train/prediction: 0.7903967409339998/[0.47599304] </row>
		<row> train/prediction: 0.7904730299320022/[0.47711912] </row>
		<row> train/prediction: 0.7905493189299477/[0.4786431] </row>
		<row> train/prediction: 0.7906256079279501/[0.4802526] </row>
		<row> train/prediction: 0.7907018969259525/[0.48262003] </row>
		<row> train/prediction: 0.790778185923898/[0.48435557] </row>
		<row> train/prediction: 0.7908544749219004/[0.48626462] </row>
		<row> train/prediction: 0.790930763919846/[0.48935518] </row>
		<row> train/prediction: 0.7910070529178483/[0.49291334] </row>
		<row> train/prediction: 0.7910833419158507/[0.49596205] </row>
		<row> train/prediction: 0.7911596309137963/[0.498965] </row>
		<row> train/prediction: 0.7912359199117986/[0.5022622] </row>
		<row> train/prediction: 0.791312208909801/[0.5051062] </row>
		<row> train/prediction: 0.7913884979077466/[0.5081895] </row>
		<row> train/prediction: 0.791464786905749/[0.511565] </row>
		<row> train/prediction: 0.7915410759037513/[0.5146712] </row>
		<row> train/prediction: 0.7916173649016969/[0.5169593] </row>
		<row> train/prediction: 0.7916936538996993/[0.5194841] </row>
		<row> train/prediction: 0.7917699428977016/[0.5218226] </row>
		<row> train/prediction: 0.7918462318956472/[0.52393645] </row>
		<row> train/prediction: 0.7919225208936496/[0.5257407] </row>
		<row> train/prediction: 0.791998809891652/[0.5266778] </row>
		<row> train/prediction: 0.7920750988895975/[0.5279312] </row>
		<row> train/prediction: 0.7921513878875999/[0.52874935] </row>
		<row> train/prediction: 0.7922276768855454/[0.5295494] </row>
		<row> train/prediction: 0.7923039658835478/[0.53041357] </row>
		<row> train/prediction: 0.7923802548815502/[0.5305704] </row>
		<row> train/prediction: 0.7924565438794957/[0.53084445] </row>
		<row> train/prediction: 0.7925328328774981/[0.53251356] </row>
		<row> train/prediction: 0.7926091218755005/[0.53466326] </row>
		<row> train/prediction: 0.792685410873446/[0.5351269] </row>
		<row> train/prediction: 0.7927616998714484/[0.5348876] </row>
		<row> train/prediction: 0.7928379888694508/[0.5346329] </row>
		<row> train/prediction: 0.7929142778673963/[0.5362433] </row>
		<row> train/prediction: 0.7929905668653987/[0.537993] </row>
		<row> train/prediction: 0.7930668558634011/[0.53902596] </row>
		<row> train/prediction: 0.7931431448613466/[0.5402749] </row>
		<row> train/prediction: 0.793219433859349/[0.54147327] </row>
		<row> train/prediction: 0.7932957228572945/[0.54348886] </row>
		<row> train/prediction: 0.7933720118552969/[0.5459198] </row>
		<row> train/prediction: 0.7934483008532993/[0.54756993] </row>
		<row> train/prediction: 0.7935245898512449/[0.5478987] </row>
		<row> train/prediction: 0.7936008788492472/[0.5497594] </row>
		<row> train/prediction: 0.7936771678472496/[0.55133647] </row>
		<row> train/prediction: 0.7937534568451952/[0.5518218] </row>
		<row> train/prediction: 0.7938297458431975/[0.55278236] </row>
		<row> train/prediction: 0.7939060348411999/[0.5533986] </row>
		<row> train/prediction: 0.7939823238391455/[0.55421025] </row>
		<row> train/prediction: 0.7940586128371478/[0.55543625] </row>
		<row> train/prediction: 0.7941349018351502/[0.55589664] </row>
		<row> train/prediction: 0.7942111908330958/[0.55573493] </row>
		<row> train/prediction: 0.7942874798310982/[0.5563305] </row>
		<row> train/prediction: 0.7943637688290437/[0.5559662] </row>
		<row> train/prediction: 0.7944400578270461/[0.5555481] </row>
		<row> train/prediction: 0.7945163468250485/[0.55632454] </row>
		<row> train/prediction: 0.794592635822994/[0.5564241] </row>
		<row> train/prediction: 0.7946689248209964/[0.5573152] </row>
		<row> train/prediction: 0.7947452138189988/[0.55744237] </row>
		<row> train/prediction: 0.7948215028169443/[0.5588685] </row>
		<row> train/prediction: 0.7948977918149467/[0.5592317] </row>
		<row> train/prediction: 0.7949740808129491/[0.56065387] </row>
		<row> train/prediction: 0.7950503698108946/[0.56173307] </row>
		<row> train/prediction: 0.795126658808897/[0.5620636] </row>
		<row> train/prediction: 0.7952029478068994/[0.56291586] </row>
		<row> train/prediction: 0.7955843927967976/[0.56399935] </row>
		<row> train/prediction: 0.7956606817947431/[0.563242] </row>
		<row> train/prediction: 0.7957369707927455/[0.5620874] </row>
		<row> train/prediction: 0.7958132597907479/[0.5621852] </row>
		<row> train/prediction: 0.7958900573820529/[0.5624795] </row>
		<row> train/prediction: 0.7959663463799984/[0.5630952] </row>
		<row> train/prediction: 0.7960426353780008/[0.5637414] </row>
		<row> train/prediction: 0.7961189243760032/[0.5635114] </row>
		<row> train/prediction: 0.7961952133739487/[0.5630553] </row>
		<row> train/prediction: 0.7962715023719511/[0.5624908] </row>
		<row> train/prediction: 0.7963477913699535/[0.5630712] </row>
		<row> train/prediction: 0.796424080367899/[0.56329316] </row>
		<row> train/prediction: 0.7965003693659014/[0.56385666] </row>
		<row> train/prediction: 0.796576658363847/[0.56394404] </row>
		<row> train/prediction: 0.7966529473618493/[0.56431717] </row>
		<row> train/prediction: 0.7967292363598517/[0.56459856] </row>
		<row> train/prediction: 0.7968055253577973/[0.56487954] </row>
		<row> train/prediction: 0.7968818143557996/[0.56504303] </row>
		<row> train/prediction: 0.796958103353802/[0.5657529] </row>
		<row> train/prediction: 0.7970343923517476/[0.5661954] </row>
		<row> train/prediction: 0.7971106813497499/[0.5659712] </row>
		<row> train/prediction: 0.7971869703477523/[0.56579417] </row>
		<row> train/prediction: 0.7972632593456979/[0.56650496] </row>
		<row> train/prediction: 0.7973395483437002/[0.5671396] </row>
		<row> train/prediction: 0.7974158373417026/[0.56821966] </row>
		<row> train/prediction: 0.7974921263396482/[0.56953436] </row>
		<row> train/prediction: 0.7975684153376505/[0.57060874] </row>
		<row> train/prediction: 0.7976447043355961/[0.5706564] </row>
		<row> train/prediction: 0.7977209933335985/[0.57099664] </row>
		<row> train/prediction: 0.7977972823316009/[0.5711751] </row>
		<row> train/prediction: 0.7978735713295464/[0.5705076] </row>
		<row> train/prediction: 0.7979498603275488/[0.57052296] </row>
		<row> train/prediction: 0.7980261493255512/[0.5701202] </row>
		<row> train/prediction: 0.7981024383234967/[0.5699937] </row>
		<row> train/prediction: 0.7981787273214991/[0.5687493] </row>
		<row> train/prediction: 0.7982550163195015/[0.5680157] </row>
		<row> train/prediction: 0.798331305317447/[0.56730384] </row>
		<row> train/prediction: 0.7984075943154494/[0.56667125] </row>
		<row> train/prediction: 0.7984838833134518/[0.5655872] </row>
		<row> train/prediction: 0.7985601723113973/[0.56524974] </row>
		<row> train/prediction: 0.7986364613093997/[0.56485736] </row>
		<row> train/prediction: 0.7987127503074021/[0.5639637] </row>
		<row> train/prediction: 0.7987890393053476/[0.5640112] </row>
		<row> train/prediction: 0.79886532830335/[0.5635448] </row>
		<row> train/prediction: 0.7989416173012955/[0.56372005] </row>
		<row> train/prediction: 0.7990179062992979/[0.5635606] </row>
		<row> train/prediction: 0.7990941952973003/[0.56436634] </row>
		<row> train/prediction: 0.7991704842952458/[0.56471395] </row>
		<row> train/prediction: 0.7992467732932482/[0.5646116] </row>
		<row> train/prediction: 0.7993230622912506/[0.5643809] </row>
		<row> train/prediction: 0.7993993512891961/[0.5639364] </row>
		<row> train/prediction: 0.7994756402871985/[0.563275] </row>
		<row> train/prediction: 0.7995519292852009/[0.5632624] </row>
		<row> train/prediction: 0.7996282182831465/[0.56340396] </row>
		<row> train/prediction: 0.7997045072811488/[0.56281406] </row>
		<row> train/prediction: 0.7997807962791512/[0.5627437] </row>
		<row> train/prediction: 0.7998570852770968/[0.56176215] </row>
		<row> train/prediction: 0.7999333742750991/[0.56051356] </row>
		<row> train/prediction: 0.8000096632730447/[0.5599056] </row>
		<row> train/prediction: 0.8000859522710471/[0.55925137] </row>
		<row> train/prediction: 0.8001622412690494/[0.55741256] </row>
		<row> train/prediction: 0.800238530266995/[0.55491644] </row>
		<row> train/prediction: 0.8003148192649974/[0.55292696] </row>
		<row> train/prediction: 0.8003911082629998/[0.5499787] </row>
		<row> train/prediction: 0.8004673972609453/[0.54760516] </row>
		<row> train/prediction: 0.8005436862589477/[0.5448013] </row>
		<row> train/prediction: 0.8006199752569501/[0.54165214] </row>
		<row> train/prediction: 0.8006962642548956/[0.53819406] </row>
		<row> train/prediction: 0.800772553252898/[0.5354593] </row>
		<row> train/prediction: 0.8008488422509004/[0.53189325] </row>
		<row> train/prediction: 0.8009251312488459/[0.5276851] </row>
		<row> train/prediction: 0.8010014202468483/[0.52410233] </row>
		<row> train/prediction: 0.8010777092447938/[0.5209095] </row>
		<row> train/prediction: 0.8011539982427962/[0.5182316] </row>
		<row> train/prediction: 0.8012302872407986/[0.51567024] </row>
		<row> train/prediction: 0.8013065762387441/[0.5128843] </row>
		<row> train/prediction: 0.8013831195333978/[0.51026356] </row>
		<row> train/prediction: 0.8014594085314002/[0.5081376] </row>
		<row> train/prediction: 0.8015356975293457/[0.50651044] </row>
		<row> train/prediction: 0.8016119865273481/[0.50447893] </row>
		<row> train/prediction: 0.8016882755253505/[0.5025032] </row>
		<row> train/prediction: 0.801764564523296/[0.50027645] </row>
		<row> train/prediction: 0.8018408535212984/[0.49822494] </row>
		<row> train/prediction: 0.8019171425193008/[0.49638364] </row>
		<row> train/prediction: 0.8019934315172463/[0.49466363] </row>
		<row> train/prediction: 0.8020697205152487/[0.49241918] </row>
		<row> train/prediction: 0.8021460095132511/[0.4902995] </row>
		<row> train/prediction: 0.8022222985111966/[0.48848057] </row>
		<row> train/prediction: 0.802298587509199/[0.4863229] </row>
		<row> train/prediction: 0.8023748765072014/[0.4845321] </row>
		<row> train/prediction: 0.802451165505147/[0.48285252] </row>
		<row> train/prediction: 0.8025274545031493/[0.4811929] </row>
		<row> train/prediction: 0.8026037435011517/[0.47940606] </row>
		<row> train/prediction: 0.8026800324990973/[0.47732443] </row>
		<row> train/prediction: 0.8027563214970996/[0.4758243] </row>
		<row> train/prediction: 0.8028326104950452/[0.47340387] </row>
		<row> train/prediction: 0.8029088994930476/[0.47129264] </row>
		<row> train/prediction: 0.8029851884910499/[0.46930653] </row>
		<row> train/prediction: 0.8030614774889955/[0.46745965] </row>
		<row> train/prediction: 0.8031377664869979/[0.46577108] </row>
		<row> train/prediction: 0.8032140554850002/[0.46416086] </row>
		<row> train/prediction: 0.8032903444829458/[0.46257722] </row>
		<row> train/prediction: 0.8033666334809482/[0.46101668] </row>
		<row> train/prediction: 0.8034429224789505/[0.45964363] </row>
		<row> train/prediction: 0.8035192114768961/[0.4586144] </row>
		<row> train/prediction: 0.8035955004748985/[0.45775] </row>
		<row> train/prediction: 0.8036717894729009/[0.45634595] </row>
		<row> train/prediction: 0.8037480784708464/[0.45477355] </row>
		<row> train/prediction: 0.8038243674688488/[0.45334297] </row>
		<row> train/prediction: 0.8039006564667943/[0.45222342] </row>
		<row> train/prediction: 0.8039769454647967/[0.45110363] </row>
		<row> train/prediction: 0.8040532344627991/[0.44931844] </row>
		<row> train/prediction: 0.8041295234607446/[0.44778934] </row>
		<row> train/prediction: 0.804205812458747/[0.4460953] </row>
		<row> train/prediction: 0.8042821014567494/[0.444679] </row>
		<row> train/prediction: 0.8043583904546949/[0.44270638] </row>
		<row> train/prediction: 0.8044346794526973/[0.44039777] </row>
		<row> train/prediction: 0.8045109684506997/[0.4381757] </row>
		<row> train/prediction: 0.8045872574486452/[0.43623734] </row>
		<row> train/prediction: 0.8046635464466476/[0.43516648] </row>
		<row> train/prediction: 0.80473983544465/[0.43349957] </row>
		<row> train/prediction: 0.8048161244425955/[0.43183511] </row>
		<row> train/prediction: 0.8048924134405979/[0.42996874] </row>
		<row> train/prediction: 0.8049687024385435/[0.42861775] </row>
		<row> train/prediction: 0.8050449914365458/[0.42724478] </row>
		<row> train/prediction: 0.8051212804345482/[0.4268192] </row>
		<row> train/prediction: 0.8051975694324938/[0.42641404] </row>
		<row> train/prediction: 0.8052738584304961/[0.4264652] </row>
		<row> train/prediction: 0.8053501474284985/[0.42617252] </row>
		<row> train/prediction: 0.8054264364264441/[0.424987] </row>
		<row> train/prediction: 0.8055027254244465/[0.42467466] </row>
		<row> train/prediction: 0.8055790144224488/[0.42431363] </row>
		<row> train/prediction: 0.8056553034203944/[0.42376262] </row>
		<row> train/prediction: 0.8057315924183968/[0.42400822] </row>
		<row> train/prediction: 0.8058078814163991/[0.42390043] </row>
		<row> train/prediction: 0.8058841704143447/[0.42389905] </row>
		<row> train/prediction: 0.8059604594123471/[0.42315146] </row>
		<row> train/prediction: 0.8060367484102926/[0.42311862] </row>
		<row> train/prediction: 0.806113037408295/[0.42266908] </row>
		<row> train/prediction: 0.8061893264062974/[0.42307922] </row>
		<row> train/prediction: 0.8062656154042429/[0.42405152] </row>
		<row> train/prediction: 0.8063419044022453/[0.4243398] </row>
		<row> train/prediction: 0.8064181934002477/[0.4237508] </row>
		<row> train/prediction: 0.8064944823981932/[0.4238007] </row>
		<row> train/prediction: 0.8065707713961956/[0.4234916] </row>
		<row> train/prediction: 0.806647060394198/[0.4230811] </row>
		<row> train/prediction: 0.8067233493921435/[0.42326015] </row>
		<row> train/prediction: 0.8067996383901459/[0.42314264] </row>
		<row> train/prediction: 0.8068761816847996/[0.42303666] </row>
		<row> train/prediction: 0.8069524706827451/[0.42285398] </row>
		<row> train/prediction: 0.8070287596807475/[0.422278] </row>
		<row> train/prediction: 0.8071050486787499/[0.42207125] </row>
		<row> train/prediction: 0.8071813376766954/[0.4217049] </row>
		<row> train/prediction: 0.8072576266746978/[0.42154202] </row>
		<row> train/prediction: 0.8073339156727002/[0.42130855] </row>
		<row> train/prediction: 0.8074102046706457/[0.42206168] </row>
		<row> train/prediction: 0.8074864936686481/[0.42267418] </row>
		<row> train/prediction: 0.8075627826666505/[0.42292452] </row>
		<row> train/prediction: 0.807639071664596/[0.4224057] </row>
		<row> train/prediction: 0.8077153606625984/[0.42255315] </row>
		<row> train/prediction: 0.807791649660544/[0.42258593] </row>
		<row> train/prediction: 0.8078679386585463/[0.42290354] </row>
		<row> train/prediction: 0.8079442276565487/[0.423604] </row>
		<row> train/prediction: 0.8080205166544943/[0.4237246] </row>
		<row> train/prediction: 0.8080968056524966/[0.42411256] </row>
		<row> train/prediction: 0.808173094650499/[0.4251776] </row>
		<row> train/prediction: 0.8082493836484446/[0.42618662] </row>
		<row> train/prediction: 0.808325672646447/[0.42686045] </row>
		<row> train/prediction: 0.8084019616444493/[0.42727894] </row>
		<row> train/prediction: 0.8084782506423949/[0.42819604] </row>
		<row> train/prediction: 0.8085545396403973/[0.4293669] </row>
		<row> train/prediction: 0.8086308286383996/[0.43010515] </row>
		<row> train/prediction: 0.8087071176363452/[0.43141124] </row>
		<row> train/prediction: 0.8087834066343476/[0.43166074] </row>
		<row> train/prediction: 0.8088596956322931/[0.4325855] </row>
		<row> train/prediction: 0.8089359846302955/[0.43305638] </row>
		<row> train/prediction: 0.8090122736282979/[0.43342444] </row>
		<row> train/prediction: 0.8090885626262434/[0.43370214] </row>
		<row> train/prediction: 0.8091648516242458/[0.43390632] </row>
		<row> train/prediction: 0.8092411406222482/[0.43410566] </row>
		<row> train/prediction: 0.8093174296201937/[0.43439126] </row>
		<row> train/prediction: 0.8093937186181961/[0.43402088] </row>
		<row> train/prediction: 0.8094700076161985/[0.43365246] </row>
		<row> train/prediction: 0.809546296614144/[0.43429187] </row>
		<row> train/prediction: 0.8096225856121464/[0.43487218] </row>
		<row> train/prediction: 0.8096988746101488/[0.43526727] </row>
		<row> train/prediction: 0.8097751636080943/[0.43552393] </row>
		<row> train/prediction: 0.8098514526060967/[0.43669894] </row>
		<row> train/prediction: 0.8099277416040991/[0.4379398] </row>
		<row> train/prediction: 0.8100040306020446/[0.4391704] </row>
		<row> train/prediction: 0.810080319600047/[0.44065034] </row>
		<row> train/prediction: 0.8101566085979925/[0.44189498] </row>
		<row> train/prediction: 0.8102328975959949/[0.44365492] </row>
		<row> train/prediction: 0.8103091865939973/[0.44499996] </row>
		<row> train/prediction: 0.8103854755919428/[0.4460365] </row>
		<row> train/prediction: 0.8104617645899452/[0.44732693] </row>
		<row> train/prediction: 0.8105380535879476/[0.44937897] </row>
		<row> train/prediction: 0.8106143425858932/[0.4510088] </row>
		<row> train/prediction: 0.8106906315838955/[0.45280278] </row>
		<row> train/prediction: 0.8107669205818979/[0.45429075] </row>
		<row> train/prediction: 0.8108432095798435/[0.45504656] </row>
		<row> train/prediction: 0.8109194985778458/[0.45634478] </row>
		<row> train/prediction: 0.8109957875758482/[0.45830977] </row>
		<row> train/prediction: 0.8110720765737938/[0.45994303] </row>
		<row> train/prediction: 0.8111483655717961/[0.46116316] </row>
		<row> train/prediction: 0.8112246545697417/[0.46286586] </row>
		<row> train/prediction: 0.8113009435677441/[0.46418718] </row>
		<row> train/prediction: 0.8113772325657465/[0.4658314] </row>
		<row> train/prediction: 0.811453521563692/[0.4674592] </row>
		<row> train/prediction: 0.8115298105616944/[0.4693479] </row>
		<row> train/prediction: 0.8122164115435453/[0.4697464] </row>
		<row> train/prediction: 0.8122927005414908/[0.4704983] </row>
		<row> train/prediction: 0.8123692438361445/[0.47184488] </row>
		<row> train/prediction: 0.8124455328341469/[0.47358832] </row>
		<row> train/prediction: 0.8125218218321493/[0.47513628] </row>
		<row> train/prediction: 0.8125981108300948/[0.47750136] </row>
		<row> train/prediction: 0.8126743998280972/[0.4798248] </row>
		<row> train/prediction: 0.8127506888260427/[0.48187184] </row>
		<row> train/prediction: 0.8128269778240451/[0.48411423] </row>
		<row> train/prediction: 0.8129032668220475/[0.48604083] </row>
		<row> train/prediction: 0.812979555819993/[0.4878558] </row>
		<row> train/prediction: 0.8130558448179954/[0.48931986] </row>
		<row> train/prediction: 0.8131321338159978/[0.49061567] </row>
		<row> train/prediction: 0.8132084228139433/[0.49265483] </row>
		<row> train/prediction: 0.8132847118119457/[0.49485964] </row>
		<row> train/prediction: 0.8133610008099481/[0.4962626] </row>
		<row> train/prediction: 0.8134372898078936/[0.49789044] </row>
		<row> train/prediction: 0.813513578805896/[0.4992061] </row>
		<row> train/prediction: 0.8135898678038984/[0.50037676] </row>
		<row> train/prediction: 0.813666156801844/[0.5019281] </row>
		<row> train/prediction: 0.8137424457998463/[0.50320464] </row>
		<row> train/prediction: 0.8138187347978487/[0.5054011] </row>
		<row> train/prediction: 0.8138950237957943/[0.5079793] </row>
		<row> train/prediction: 0.8139713127937966/[0.5109388] </row>
		<row> train/prediction: 0.8140476017917422/[0.5127092] </row>
		<row> train/prediction: 0.8141238907897446/[0.51503325] </row>
		<row> train/prediction: 0.814200179787747/[0.51641786] </row>
		<row> train/prediction: 0.8142764687856925/[0.5189951] </row>
		<row> train/prediction: 0.8143527577836949/[0.5211392] </row>
		<row> train/prediction: 0.8144290467816973/[0.52274865] </row>
		<row> train/prediction: 0.8145053357796428/[0.5240973] </row>
		<row> train/prediction: 0.8145816247776452/[0.5243809] </row>
		<row> train/prediction: 0.8146579137756476/[0.52546906] </row>
		<row> train/prediction: 0.8147342027735931/[0.5257159] </row>
		<row> train/prediction: 0.8148104917715955/[0.52636135] </row>
		<row> train/prediction: 0.8148867807695979/[0.5266588] </row>
		<row> train/prediction: 0.8149630697675434/[0.52610785] </row>
		<row> train/prediction: 0.8150393587655458/[0.5257154] </row>
		<row> train/prediction: 0.8151156477634913/[0.5263544] </row>
		<row> train/prediction: 0.8151919367614937/[0.5265536] </row>
		<row> train/prediction: 0.8152682257594961/[0.5260292] </row>
		<row> train/prediction: 0.8153445147574416/[0.5251608] </row>
		<row> train/prediction: 0.815420803755444/[0.5246623] </row>
		<row> train/prediction: 0.8154970927534464/[0.52440995] </row>
		<row> train/prediction: 0.8155733817513919/[0.52403563] </row>
		<row> train/prediction: 0.8156496707493943/[0.52380383] </row>
		<row> train/prediction: 0.8157259597473967/[0.5226358] </row>
		<row> train/prediction: 0.8158022487453422/[0.5207212] </row>
		<row> train/prediction: 0.8158785377433446/[0.5191557] </row>
		<row> train/prediction: 0.815954826741347/[0.51702017] </row>
		<row> train/prediction: 0.8160311157392925/[0.5154862] </row>
		<row> train/prediction: 0.8161074047372949/[0.51243097] </row>
		<row> train/prediction: 0.8161836937352405/[0.5105491] </row>
		<row> train/prediction: 0.8162599827332429/[0.50864625] </row>
		<row> train/prediction: 0.8163362717312452/[0.50619227] </row>
		<row> train/prediction: 0.8164125607291908/[0.5039877] </row>
		<row> train/prediction: 0.8164888497271932/[0.5010019] </row>
		<row> train/prediction: 0.8165651387251955/[0.49804914] </row>
		<row> train/prediction: 0.8166414277231411/[0.49640107] </row>
		<row> train/prediction: 0.8167177167211435/[0.49425018] </row>
		<row> train/prediction: 0.8167940057191458/[0.49204612] </row>
		<row> train/prediction: 0.8168702947170914/[0.49063644] </row>
		<row> train/prediction: 0.8169465837150938/[0.48850444] </row>
		<row> train/prediction: 0.8170228727130961/[0.48733652] </row>
		<row> train/prediction: 0.8170991617110417/[0.4859562] </row>
		<row> train/prediction: 0.8171754507090441/[0.48307964] </row>
		<row> train/prediction: 0.8172517397069896/[0.4818903] </row>
		<row> train/prediction: 0.817328028704992/[0.48082507] </row>
		<row> train/prediction: 0.8174043177029944/[0.47990823] </row>
		<row> train/prediction: 0.8174806067009399/[0.47818148] </row>
		<row> train/prediction: 0.8175568956989423/[0.47820383] </row>
		<row> train/prediction: 0.8176331846969447/[0.47702527] </row>
		<row> train/prediction: 0.8177094736948902/[0.4765549] </row>
		<row> train/prediction: 0.8177857626928926/[0.47690776] </row>
		<row> train/prediction: 0.8178623059875463/[0.4771174] </row>
		<row> train/prediction: 0.8179385949854918/[0.4776523] </row>
		<row> train/prediction: 0.8180148839834942/[0.47608188] </row>
		<row> train/prediction: 0.8180911729814966/[0.47465095] </row>
		<row> train/prediction: 0.8181674619794421/[0.4730215] </row>
		<row> train/prediction: 0.8182437509774445/[0.47170824] </row>
		<row> train/prediction: 0.8183200399754469/[0.47094655] </row>
		<row> train/prediction: 0.8183963289733924/[0.47102308] </row>
		<row> train/prediction: 0.8184726179713948/[0.46943733] </row>
		<row> train/prediction: 0.8185489069693972/[0.4675587] </row>
		<row> train/prediction: 0.8186251959673427/[0.46643293] </row>
		<row> train/prediction: 0.8187014849653451/[0.46413666] </row>
		<row> train/prediction: 0.8187777739633475/[0.46329644] </row>
		<row> train/prediction: 0.818854062961293/[0.46151236] </row>
		<row> train/prediction: 0.8189303519592954/[0.46072298] </row>
		<row> train/prediction: 0.819006640957241/[0.46078828] </row>
		<row> train/prediction: 0.8190829299552433/[0.4599742] </row>
		<row> train/prediction: 0.8191592189532457/[0.45977408] </row>
		<row> train/prediction: 0.8192355079511913/[0.4584112] </row>
		<row> train/prediction: 0.8193117969491936/[0.45819098] </row>
		<row> train/prediction: 0.819388085947196/[0.45671907] </row>
		<row> train/prediction: 0.8194643749451416/[0.45661557] </row>
		<row> train/prediction: 0.819540663943144/[0.45560756] </row>
		<row> train/prediction: 0.8196169529411463/[0.4536215] </row>
		<row> train/prediction: 0.8196932419390919/[0.4515339] </row>
		<row> train/prediction: 0.8197695309370943/[0.4509917] </row>
		<row> train/prediction: 0.8198458199350966/[0.4502136] </row>
		<row> train/prediction: 0.8199221089330422/[0.4488291] </row>
		<row> train/prediction: 0.8199983979310446/[0.44871557] </row>
		<row> train/prediction: 0.8200746869289901/[0.44792837] </row>
		<row> train/prediction: 0.8201509759269925/[0.44632894] </row>
		<row> train/prediction: 0.8202272649249949/[0.44464135] </row>
		<row> train/prediction: 0.8203035539229404/[0.443058] </row>
		<row> train/prediction: 0.8203798429209428/[0.4421989] </row>
		<row> train/prediction: 0.8204561319189452/[0.44064337] </row>
		<row> train/prediction: 0.8205324209168907/[0.43951935] </row>
		<row> train/prediction: 0.8206087099148931/[0.4376967] </row>
		<row> train/prediction: 0.8206849989128955/[0.43688694] </row>
		<row> train/prediction: 0.820761287910841/[0.43504933] </row>
		<row> train/prediction: 0.8208375769088434/[0.43367708] </row>
		<row> train/prediction: 0.8209138659068458/[0.4312939] </row>
		<row> train/prediction: 0.8209901549047913/[0.42929795] </row>
		<row> train/prediction: 0.8210664439027937/[0.4282536] </row>
		<row> train/prediction: 0.8211427329007961/[0.42965472] </row>
		<row> train/prediction: 0.8212190218987416/[0.42981535] </row>
		<row> train/prediction: 0.821295310896744/[0.42942008] </row>
		<row> train/prediction: 0.8213715998946896/[0.4283536] </row>
		<row> train/prediction: 0.8214478888926919/[0.42959443] </row>
		<row> train/prediction: 0.8215241778906943/[0.43064687] </row>
		<row> train/prediction: 0.8216004668886399/[0.43067998] </row>
		<row> train/prediction: 0.8216767558866422/[0.43078002] </row>
		<row> train/prediction: 0.8217530448846446/[0.4316555] </row>
		<row> train/prediction: 0.8218293338825902/[0.4318333] </row>
		<row> train/prediction: 0.8219056228805925/[0.43113118] </row>
		<row> train/prediction: 0.8219819118785949/[0.43073425] </row>
		<row> train/prediction: 0.8220582008765405/[0.42956847] </row>
		<row> train/prediction: 0.8221344898745429/[0.42857465] </row>
		<row> train/prediction: 0.8222107788725452/[0.42765105] </row>
		<row> train/prediction: 0.8222870678704908/[0.42785615] </row>
		<row> train/prediction: 0.8223633568684932/[0.42727593] </row>
		<row> train/prediction: 0.8224396458664387/[0.42663294] </row>
		<row> train/prediction: 0.8225159348644411/[0.42500973] </row>
		<row> train/prediction: 0.8225922238624435/[0.42498225] </row>
		<row> train/prediction: 0.822668512860389/[0.4227331] </row>
		<row> train/prediction: 0.8227448018583914/[0.42172593] </row>
		<row> train/prediction: 0.8228210908563938/[0.42192435] </row>
		<row> train/prediction: 0.8228973798543393/[0.41932973] </row>
		<row> train/prediction: 0.8229736688523417/[0.41983616] </row>
		<row> train/prediction: 0.8232788248442944/[0.41945064] </row>
		<row> train/prediction: 0.8233553681388912/[0.4180968] </row>
		<row> train/prediction: 0.8234316571368936/[0.4168761] </row>
		<row> train/prediction: 0.823507946134896/[0.41325265] </row>
		<row> train/prediction: 0.8235842351328415/[0.412481] </row>
		<row> train/prediction: 0.8236605241308439/[0.4128713] </row>
		<row> train/prediction: 0.8237368131288463/[0.41274068] </row>
		<row> train/prediction: 0.8238131021267918/[0.41334328] </row>
		<row> train/prediction: 0.8238893911247942/[0.41337016] </row>
		<row> train/prediction: 0.8239656801227397/[0.41122785] </row>
		<row> train/prediction: 0.8240419691207421/[0.41274238] </row>
		<row> train/prediction: 0.8241182581187445/[0.4139725] </row>
		<row> train/prediction: 0.82419454711669/[0.41383204] </row>
		<row> train/prediction: 0.8242708361146924/[0.41595265] </row>
		<row> train/prediction: 0.8243471251126948/[0.4153198] </row>
		<row> train/prediction: 0.8244234141106404/[0.4154088] </row>
		<row> train/prediction: 0.8244997031086427/[0.41678312] </row>
		<row> train/prediction: 0.8245759921066451/[0.4151133] </row>
		<row> train/prediction: 0.8246522811045907/[0.41507328] </row>
		<row> train/prediction: 0.824728570102593/[0.41432863] </row>
		<row> train/prediction: 0.8248048591005954/[0.41607106] </row>
		<row> train/prediction: 0.824881148098541/[0.41546068] </row>
		<row> train/prediction: 0.8249574370965433/[0.4161794] </row>
		<row> train/prediction: 0.8250337260945457/[0.4153711] </row>
		<row> train/prediction: 0.8430458128147507/[0.41428477] </row>
		<row> train/prediction: 0.843122101812753/[0.41616464] </row>
		<row> train/prediction: 0.8431983908107554/[0.41762283] </row>
		<row> train/prediction: 0.843274679808701/[0.41702238] </row>
		<row> train/prediction: 0.8433509688067033/[0.4166741] </row>
		<row> train/prediction: 0.8434272578046489/[0.4169417] </row>
		<row> train/prediction: 0.8435035468026513/[0.41598922] </row>
		<row> train/prediction: 0.8435798358006537/[0.41661662] </row>
		<row> train/prediction: 0.8436561247985992/[0.41660905] </row>
		<row> train/prediction: 0.8437324137966016/[0.4170658] </row>
		<row> train/prediction: 0.843808702794604/[0.41698673] </row>
		<row> train/prediction: 0.8438849917925495/[0.41637212] </row>
		<row> train/prediction: 0.8439612807905519/[0.41695365] </row>
		<row> train/prediction: 0.8440375697885543/[0.41633385] </row>
		<row> train/prediction: 0.8441138587864998/[0.41787732] </row>
		<row> train/prediction: 0.8441901477845022/[0.41863787] </row>
		<row> train/prediction: 0.8442664367825046/[0.4220848] </row>
		<row> train/prediction: 0.8443427257804501/[0.42527008] </row>
		<row> train/prediction: 0.8444190147784525/[0.42955968] </row>
		<row> train/prediction: 0.844495303776398/[0.4313569] </row>
		<row> train/prediction: 0.8445715927744004/[0.43338147] </row>
		<row> train/prediction: 0.8446478817724028/[0.4347805] </row>
		<row> train/prediction: 0.8447241707703483/[0.4368544] </row>
		<row> train/prediction: 0.8448004597683507/[0.43992573] </row>
		<row> train/prediction: 0.8448767487663531/[0.44184047] </row>
		<row> train/prediction: 0.8449530377642986/[0.44214612] </row>
		<row> train/prediction: 0.845029326762301/[0.44328696] </row>
		<row> train/prediction: 0.8451056157603034/[0.44501165] </row>
		<row> train/prediction: 0.845181904758249/[0.44645748] </row>
		<row> train/prediction: 0.8452581937562513/[0.44562584] </row>
		<row> train/prediction: 0.8453344827542537/[0.44590375] </row>
		<row> train/prediction: 0.8454107717521993/[0.4467481] </row>
		<row> train/prediction: 0.8454870607502016/[0.44517177] </row>
		<row> train/prediction: 0.845563349748204/[0.44582966] </row>
		<row> train/prediction: 0.8456396387461496/[0.44525546] </row>
		<row> train/prediction: 0.8457159277441519/[0.44590107] </row>
		<row> train/prediction: 0.8457922167420975/[0.44707283] </row>
		<row> train/prediction: 0.8458685057400999/[0.4476196] </row>
		<row> train/prediction: 0.8459447947381022/[0.4469065] </row>
		<row> train/prediction: 0.8460210837360478/[0.44728103] </row>
		<row> train/prediction: 0.8460973727340502/[0.4474559] </row>
		<row> train/prediction: 0.8461736617320526/[0.4483998] </row>
		<row> train/prediction: 0.8462499507299981/[0.44776264] </row>
		<row> train/prediction: 0.8463262397280005/[0.44596657] </row>
		<row> train/prediction: 0.8464025287260029/[0.44741294] </row>
		<row> train/prediction: 0.8464788177239484/[0.4480634] </row>
		<row> train/prediction: 0.8465551067219508/[0.4496465] </row>
		<row> train/prediction: 0.8466313957199532/[0.44906384] </row>
		<row> train/prediction: 0.8467076847178987/[0.45045367] </row>
		<row> train/prediction: 0.8467839737159011/[0.451684] </row>
		<row> train/prediction: 0.8468602627138466/[0.4531666] </row>
		<row> train/prediction: 0.846936551711849/[0.45328346] </row>
		<row> train/prediction: 0.8470128407098514/[0.45340878] </row>
		<row> train/prediction: 0.8470891297077969/[0.45439836] </row>
		<row> train/prediction: 0.8471654187057993/[0.4550534] </row>
		<row> train/prediction: 0.8472417077038017/[0.4561487] </row>
		<row> train/prediction: 0.8473179967017472/[0.45620584] </row>
		<row> train/prediction: 0.8473942856997496/[0.45803344] </row>
		<row> train/prediction: 0.847470574697752/[0.45938325] </row>
		<row> train/prediction: 0.8475468636956975/[0.45996496] </row>
		<row> train/prediction: 0.8476231526936999/[0.4601792] </row>
		<row> train/prediction: 0.8476994416917023/[0.46063188] </row>
		<row> train/prediction: 0.8477757306896478/[0.46008566] </row>
		<row> train/prediction: 0.8478520196876502/[0.4605574] </row>
		<row> train/prediction: 0.8479283086855958/[0.46201545] </row>
		<row> train/prediction: 0.8480045976835981/[0.4614297] </row>
		<row> train/prediction: 0.8480808866816005/[0.46220285] </row>
		<row> train/prediction: 0.8481571756795461/[0.46068424] </row>
		<row> train/prediction: 0.8482334646775485/[0.46037975] </row>
		<row> train/prediction: 0.8483097536755508/[0.45956552] </row>
		<row> train/prediction: 0.8502932676230444/[0.45943797] </row>
		<row> train/prediction: 0.8503695566210467/[0.45602593] </row>
		<row> train/prediction: 0.8504458456190491/[0.4535444] </row>
		<row> train/prediction: 0.8505221346169947/[0.45107377] </row>
		<row> train/prediction: 0.850598423614997/[0.44865113] </row>
		<row> train/prediction: 0.8506747126129994/[0.44676384] </row>
		<row> train/prediction: 0.850751001610945/[0.4445681] </row>
		<row> train/prediction: 0.8508272906089474/[0.44227943] </row>
		<row> train/prediction: 0.8509035796069497/[0.43999964] </row>
		<row> train/prediction: 0.8509798686048953/[0.4379522] </row>
		<row> train/prediction: 0.8510561576028977/[0.4360531] </row>
		<row> train/prediction: 0.8511324466009/[0.43455675] </row>
		<row> train/prediction: 0.8512087355988456/[0.43325284] </row>
		<row> train/prediction: 0.851285024596848/[0.43190998] </row>
		<row> train/prediction: 0.8513613135947935/[0.4303339] </row>
		<row> train/prediction: 0.8514376025927959/[0.42887902] </row>
		<row> train/prediction: 0.8515138915907983/[0.42743018] </row>
		<row> train/prediction: 0.8515901805887438/[0.4259464] </row>
		<row> train/prediction: 0.8516664695867462/[0.4244645] </row>
		<row> train/prediction: 0.8517427585847486/[0.42212987] </row>
		<row> train/prediction: 0.8518190475826941/[0.41947323] </row>
		<row> train/prediction: 0.8518953365806965/[0.41683283] </row>
		<row> train/prediction: 0.8519716255786989/[0.41468704] </row>
		<row> train/prediction: 0.8520479145766444/[0.41310975] </row>
		<row> train/prediction: 0.8521247121679494/[0.41159606] </row>
		<row> train/prediction: 0.8522010011659518/[0.41010478] </row>
		<row> train/prediction: 0.8522772901638973/[0.40880752] </row>
		<row> train/prediction: 0.8523535791618997/[0.4069109] </row>
		<row> train/prediction: 0.8524298681599021/[0.40546274] </row>
		<row> train/prediction: 0.8525061571578476/[0.40349492] </row>
		<row> train/prediction: 0.85258244615585/[0.40169698] </row>
		<row> train/prediction: 0.8526587351538524/[0.40010288] </row>
		<row> train/prediction: 0.8527350241517979/[0.39894068] </row>
		<row> train/prediction: 0.8528113131498003/[0.39801368] </row>
		<row> train/prediction: 0.8528876021478027/[0.39698732] </row>
		<row> train/prediction: 0.8529638911457482/[0.39623174] </row>
		<row> train/prediction: 0.8530401801437506/[0.39523935] </row>
		<row> train/prediction: 0.853116469141753/[0.3940273] </row>
		<row> train/prediction: 0.8531927581396985/[0.3928864] </row>
		<row> train/prediction: 0.8532690471377009/[0.39162722] </row>
		<row> train/prediction: 0.8533453361357033/[0.39026317] </row>
		<row> train/prediction: 0.8534216251336488/[0.3889813] </row>
		<row> train/prediction: 0.8534979141316512/[0.38784698] </row>
		<row> train/prediction: 0.8535742031295968/[0.38713694] </row>
		<row> train/prediction: 0.8536504921275991/[0.38698474] </row>
		<row> train/prediction: 0.8537267811256015/[0.38664475] </row>
		<row> train/prediction: 0.8538030701235471/[0.3863358] </row>
		<row> train/prediction: 0.8538793591215494/[0.3856906] </row>
		<row> train/prediction: 0.8539556481195518/[0.385259] </row>
		<row> train/prediction: 0.8540319371174974/[0.38475022] </row>
		<row> train/prediction: 0.8541082261154997/[0.38472036] </row>
		<row> train/prediction: 0.8541845151135021/[0.38428655] </row>
		<row> train/prediction: 0.8542608041114477/[0.38463536] </row>
		<row> train/prediction: 0.85433709310945/[0.38538447] </row>
		<row> train/prediction: 0.8544133821074524/[0.38628373] </row>
		<row> train/prediction: 0.854489671105398/[0.3867361] </row>
		<row> train/prediction: 0.8545659601034004/[0.3867382] </row>
		<row> train/prediction: 0.8546422491013459/[0.38685796] </row>
		<row> train/prediction: 0.8547185380993483/[0.3874881] </row>
		<row> train/prediction: 0.8547948270973507/[0.38780376] </row>
		<row> train/prediction: 0.8548711160952962/[0.3877926] </row>
		<row> train/prediction: 0.8549474050932986/[0.3876362] </row>
		<row> train/prediction: 0.855023694091301/[0.38813865] </row>
		<row> train/prediction: 0.8550999830892465/[0.38857287] </row>
		<row> train/prediction: 0.8551762720872489/[0.38876483] </row>
		<row> train/prediction: 0.8552525610852513/[0.3889548] </row>
		<row> train/prediction: 0.8553288500831968/[0.38867417] </row>
		<row> train/prediction: 0.8554051390811992/[0.38845578] </row>
		<row> train/prediction: 0.8554814280792016/[0.38773292] </row>
		<row> train/prediction: 0.8555577170771471/[0.3869805] </row>
		<row> train/prediction: 0.8556340060751495/[0.38643938] </row>
		<row> train/prediction: 0.855710295073095/[0.3858461] </row>
		<row> train/prediction: 0.8557865840710974/[0.3855567] </row>
		<row> train/prediction: 0.8558628730690998/[0.38519287] </row>
		<row> train/prediction: 0.8559391620670453/[0.3842607] </row>
		<row> train/prediction: 0.8560154510650477/[0.38366327] </row>
		<row> train/prediction: 0.8560917400630501/[0.38347507] </row>
		<row> train/prediction: 0.8561680290609957/[0.3828948] </row>
		<row> train/prediction: 0.856244318058998/[0.38201225] </row>
		<row> train/prediction: 0.8563206070570004/[0.38096073] </row>
		<row> train/prediction: 0.856396896054946/[0.38058043] </row>
		<row> train/prediction: 0.8564731850529483/[0.38023055] </row>
		<row> train/prediction: 0.8565494740509507/[0.37994084] </row>
		<row> train/prediction: 0.8566257630488963/[0.37979886] </row>
		<row> train/prediction: 0.8567020520468986/[0.38012174] </row>
		<row> train/prediction: 0.8567783410448442/[0.3808507] </row>
		<row> train/prediction: 0.8568546300428466/[0.38184825] </row>
		<row> train/prediction: 0.856930919040849/[0.38267288] </row>
		<row> train/prediction: 0.8570072080387945/[0.38366824] </row>
		<row> train/prediction: 0.8570834970367969/[0.3853226] </row>
		<row> train/prediction: 0.8571597860347993/[0.38680336] </row>
		<row> train/prediction: 0.8572360750327448/[0.38817218] </row>
		<row> train/prediction: 0.8573123640307472/[0.38953397] </row>
		<row> train/prediction: 0.8573886530287496/[0.3908642] </row>
		<row> train/prediction: 0.8574649420266951/[0.3919478] </row>
		<row> train/prediction: 0.8575412310246975/[0.39310136] </row>
		<row> train/prediction: 0.8576180286160024/[0.3941692] </row>
		<row> train/prediction: 0.8576943176140048/[0.39490917] </row>
		<row> train/prediction: 0.8577706066119504/[0.395545] </row>
		<row> train/prediction: 0.8578468956099528/[0.39575586] </row>
		<row> train/prediction: 0.8579231846078983/[0.3960482] </row>
		<row> train/prediction: 0.8579994736059007/[0.39575687] </row>
		<row> train/prediction: 0.8580757626039031/[0.39599967] </row>
		<row> train/prediction: 0.8581520516018486/[0.3958509] </row>
		<row> train/prediction: 0.858228340599851/[0.3962697] </row>
		<row> train/prediction: 0.8583046295978534/[0.39669546] </row>
		<row> train/prediction: 0.8583809185957989/[0.39723226] </row>
		<row> train/prediction: 0.8584572075938013/[0.39771727] </row>
		<row> train/prediction: 0.8585334965918037/[0.39838165] </row>
		<row> train/prediction: 0.8586097855897492/[0.39937562] </row>
		<row> train/prediction: 0.8586860745877516/[0.40035048] </row>
		<row> train/prediction: 0.858762363585754/[0.4018183] </row>
		<row> train/prediction: 0.8588386525836995/[0.40328673] </row>
		<row> train/prediction: 0.8589149415817019/[0.40492633] </row>
		<row> train/prediction: 0.8589912305796474/[0.4065538] </row>
		<row> train/prediction: 0.8590675195776498/[0.40860724] </row>
		<row> train/prediction: 0.8591438085756522/[0.41079774] </row>
		<row> train/prediction: 0.8592200975735977/[0.41291386] </row>
		<row> train/prediction: 0.8592963865716001/[0.41502184] </row>
		<row> train/prediction: 0.8593726755696025/[0.41720936] </row>
		<row> train/prediction: 0.859448964567548/[0.4192909] </row>
		<row> train/prediction: 0.8595252535655504/[0.42123505] </row>
		<row> train/prediction: 0.8596015425635528/[0.4230781] </row>
		<row> train/prediction: 0.8596778315614984/[0.42453486] </row>
		<row> train/prediction: 0.8597541205595007/[0.42655694] </row>
		<row> train/prediction: 0.8598304095575031/[0.4286842] </row>
		<row> train/prediction: 0.8599066985554487/[0.4310284] </row>
		<row> train/prediction: 0.859982987553451/[0.43312293] </row>
		<row> train/prediction: 0.8600592765514534/[0.43523964] </row>
		<row> train/prediction: 0.860135565549399/[0.43765312] </row>
		<row> train/prediction: 0.8602118545474013/[0.44030806] </row>
		<row> train/prediction: 0.8602881435453469/[0.44317302] </row>
		<row> train/prediction: 0.8603644325433493/[0.44601235] </row>
		<row> train/prediction: 0.8604407215413516/[0.44916075] </row>
		<row> train/prediction: 0.8605170105392972/[0.45263112] </row>
		<row> train/prediction: 0.8605932995372996/[0.45617348] </row>
		<row> train/prediction: 0.860669588535302/[0.4594271] </row>
		<row> train/prediction: 0.8607458775332475/[0.46302512] </row>
		<row> train/prediction: 0.8608221665312499/[0.46683004] </row>
		<row> train/prediction: 0.8608984555292523/[0.4699638] </row>
		<row> train/prediction: 0.8609747445271978/[0.47321427] </row>
		<row> train/prediction: 0.8610510335252002/[0.47629285] </row>
		<row> train/prediction: 0.8611273225232026/[0.47936407] </row>
		<row> train/prediction: 0.8612036115211481/[0.48262972] </row>
		<row> train/prediction: 0.8612799005191505/[0.48574197] </row>
		<row> train/prediction: 0.861356189517096/[0.48931965] </row>
		<row> train/prediction: 0.8614324785150984/[0.4928115] </row>
		<row> train/prediction: 0.8615087675131008/[0.4968299] </row>
		<row> train/prediction: 0.8615850565110463/[0.5003101] </row>
		<row> train/prediction: 0.8616613455090487/[0.50394005] </row>
		<row> train/prediction: 0.8617376345070511/[0.5076511] </row>
		<row> train/prediction: 0.8618139235049966/[0.5114385] </row>
		<row> train/prediction: 0.861890212502999/[0.5152881] </row>
		<row> train/prediction: 0.8619665015010014/[0.51886034] </row>
		<row> train/prediction: 0.8620427904989469/[0.5219598] </row>
		<row> train/prediction: 0.8621190794969493/[0.52532864] </row>
		<row> train/prediction: 0.8621953684949517/[0.528655] </row>
		<row> train/prediction: 0.8622716574928972/[0.53162926] </row>
		<row> train/prediction: 0.8623479464908996/[0.53486264] </row>
		<row> train/prediction: 0.8624242354888452/[0.5378309] </row>
		<row> train/prediction: 0.8625005244868476/[0.5406528] </row>
		<row> train/prediction: 0.8625768134848499/[0.54333127] </row>
		<row> train/prediction: 0.8626531024827955/[0.54551584] </row>
		<row> train/prediction: 0.8627293914807979/[0.54806066] </row>
		<row> train/prediction: 0.8628056804788002/[0.5503713] </row>
		<row> train/prediction: 0.8628819694767458/[0.5530638] </row>
		<row> train/prediction: 0.8629582584747482/[0.55585307] </row>
		<row> train/prediction: 0.8630345474727505/[0.5584155] </row>
		<row> train/prediction: 0.8631110907673474/[0.5604455] </row>
		<row> train/prediction: 0.8631873797653498/[0.56271607] </row>
		<row> train/prediction: 0.8632636687633521/[0.5648079] </row>
		<row> train/prediction: 0.8633399577612977/[0.5668261] </row>
		<row> train/prediction: 0.8634162467593001/[0.5685261] </row>
		<row> train/prediction: 0.8634925357573024/[0.56985235] </row>
		<row> train/prediction: 0.863568824755248/[0.5717942] </row>
		<row> train/prediction: 0.8636451137532504/[0.573215] </row>
		<row> train/prediction: 0.8637214027512528/[0.57408214] </row>
		<row> train/prediction: 0.8637976917491983/[0.57532996] </row>
		<row> train/prediction: 0.8638739807472007/[0.5763754] </row>
		<row> train/prediction: 0.8639502697452031/[0.5771796] </row>
		<row> train/prediction: 0.8640265587431486/[0.5772871] </row>
		<row> train/prediction: 0.864102847741151/[0.57744914] </row>
		<row> train/prediction: 0.8641791367390965/[0.5777225] </row>
		<row> train/prediction: 0.8642554257370989/[0.5774882] </row>
		<row> train/prediction: 0.8643317147351013/[0.5777961] </row>
		<row> train/prediction: 0.8644080037330468/[0.57768035] </row>
		<row> train/prediction: 0.8644842927310492/[0.5776253] </row>
		<row> train/prediction: 0.8645605817290516/[0.57763356] </row>
		<row> train/prediction: 0.8646368707269971/[0.5775008] </row>
		<row> train/prediction: 0.8647131597249995/[0.5771391] </row>
		<row> train/prediction: 0.8647894487230019/[0.5774539] </row>
		<row> train/prediction: 0.8648657377209474/[0.577529] </row>
		<row> train/prediction: 0.8649420267189498/[0.5780799] </row>
		<row> train/prediction: 0.8650183157169522/[0.57903063] </row>
		<row> train/prediction: 0.8650946047148977/[0.58015466] </row>
		<row> train/prediction: 0.8651708937129001/[0.58215445] </row>
		<row> train/prediction: 0.8652471827108457/[0.5839213] </row>
		<row> train/prediction: 0.865323471708848/[0.5857891] </row>
		<row> train/prediction: 0.8653997607068504/[0.58754754] </row>
		<row> train/prediction: 0.865476049704796/[0.58953995] </row>
		<row> train/prediction: 0.8655523387027984/[0.59136057] </row>
		<row> train/prediction: 0.8656286277008007/[0.59282416] </row>
		<row> train/prediction: 0.8657049166987463/[0.59412044] </row>
		<row> train/prediction: 0.8657812056967487/[0.5951068] </row>
		<row> train/prediction: 0.865857494694751/[0.5958197] </row>
		<row> train/prediction: 0.8659337836926966/[0.5966475] </row>
		<row> train/prediction: 0.866010072690699/[0.59696686] </row>
		<row> train/prediction: 0.8660863616887013/[0.5964113] </row>
		<row> train/prediction: 0.8661626506866469/[0.5960203] </row>
		<row> train/prediction: 0.8662389396846493/[0.595358] </row>
		<row> train/prediction: 0.8663152286825948/[0.5945852] </row>
		<row> train/prediction: 0.8663915176805972/[0.59386474] </row>
		<row> train/prediction: 0.8664678066785996/[0.5933306] </row>
		<row> train/prediction: 0.8665440956765451/[0.5929397] </row>
		<row> train/prediction: 0.8666203846745475/[0.5928923] </row>
		<row> train/prediction: 0.8666966736725499/[0.5931985] </row>
		<row> train/prediction: 0.8667729626704954/[0.59319705] </row>
		<row> train/prediction: 0.8668492516684978/[0.5934254] </row>
		<row> train/prediction: 0.8669255406665002/[0.59372616] </row>
		<row> train/prediction: 0.8670018296644457/[0.5942308] </row>
		<row> train/prediction: 0.8670781186624481/[0.5949545] </row>
		<row> train/prediction: 0.8671544076604505/[0.5956125] </row>
		<row> train/prediction: 0.867230696658396/[0.5957151] </row>
		<row> train/prediction: 0.8673069856563984/[0.59588784] </row>
		<row> train/prediction: 0.867383274654344/[0.5962442] </row>
		<row> train/prediction: 0.8674595636523463/[0.5961625] </row>
		<row> train/prediction: 0.8675358526503487/[0.5964009] </row>
		<row> train/prediction: 0.8676121416482943/[0.59622747] </row>
		<row> train/prediction: 0.8676884306462966/[0.5957531] </row>
		<row> train/prediction: 0.867764719644299/[0.59510505] </row>
		<row> train/prediction: 0.8678410086422446/[0.5948277] </row>
		<row> train/prediction: 0.8679172976402469/[0.5944529] </row>
		<row> train/prediction: 0.8679935866382493/[0.5936104] </row>
		<row> train/prediction: 0.8680698756361949/[0.5929531] </row>
		<row> train/prediction: 0.8681461646341972/[0.5923256] </row>
		<row> train/prediction: 0.8682224536321996/[0.5913923] </row>
		<row> train/prediction: 0.8682987426301452/[0.59005606] </row>
		<row> train/prediction: 0.8683750316281476/[0.58929545] </row>
		<row> train/prediction: 0.8684513206261499/[0.5881149] </row>
		<row> train/prediction: 0.8685276096240955/[0.58723694] </row>
		<row> train/prediction: 0.8686041529187492/[0.58612645] </row>
		<row> train/prediction: 0.8686804419167515/[0.5852139] </row>
		<row> train/prediction: 0.8687567309146971/[0.58432627] </row>
		<row> train/prediction: 0.8688330199126995/[0.58323413] </row>
		<row> train/prediction: 0.8689093089107018/[0.5819115] </row>
		<row> train/prediction: 0.8689855979086474/[0.5803533] </row>
		<row> train/prediction: 0.8690618869066498/[0.5790801] </row>
		<row> train/prediction: 0.8691381759045953/[0.57725674] </row>
		<row> train/prediction: 0.8692144649025977/[0.575403] </row>
		<row> train/prediction: 0.8692907539006001/[0.5730018] </row>
		<row> train/prediction: 0.8693670428985456/[0.5702413] </row>
		<row> train/prediction: 0.869443331896548/[0.56720746] </row>
		<row> train/prediction: 0.8695196208945504/[0.56426156] </row>
		<row> train/prediction: 0.8695959098924959/[0.5603934] </row>
		<row> train/prediction: 0.8696721988904983/[0.5558165] </row>
		<row> train/prediction: 0.8697484878885007/[0.55175555] </row>
		<row> train/prediction: 0.8698247768864462/[0.5476189] </row>
		<row> train/prediction: 0.8699010658844486/[0.5434831] </row>
		<row> train/prediction: 0.869977354882451/[0.53924674] </row>
		<row> train/prediction: 0.8700536438803965/[0.5353757] </row>
		<row> train/prediction: 0.8701299328783989/[0.5315343] </row>
		<row> train/prediction: 0.8702062218763444/[0.528482] </row>
		<row> train/prediction: 0.8702825108743468/[0.525577] </row>
		<row> train/prediction: 0.8703587998723492/[0.5223578] </row>
		<row> train/prediction: 0.8704350888702947/[0.5194849] </row>
		<row> train/prediction: 0.8705113778682971/[0.5166199] </row>
		<row> train/prediction: 0.8705876668662995/[0.5143657] </row>
		<row> train/prediction: 0.870663955864245/[0.5121169] </row>
		<row> train/prediction: 0.8707402448622474/[0.509411] </row>
		<row> train/prediction: 0.8708165338602498/[0.50666374] </row>
		<row> train/prediction: 0.8708928228581954/[0.5047135] </row>
		<row> train/prediction: 0.8709691118561977/[0.50270957] </row>
		<row> train/prediction: 0.8710454008542001/[0.50081384] </row>
		<row> train/prediction: 0.8711216898521457/[0.49879727] </row>
		<row> train/prediction: 0.871197978850148/[0.49657512] </row>
		<row> train/prediction: 0.8712742678480936/[0.49412334] </row>
		<row> train/prediction: 0.871350556846096/[0.491918] </row>
		<row> train/prediction: 0.8714268458440984/[0.48924914] </row>
		<row> train/prediction: 0.8715031348420439/[0.48650694] </row>
		<row> train/prediction: 0.8715794238400463/[0.4835509] </row>
		<row> train/prediction: 0.8716557128380487/[0.48078284] </row>
		<row> train/prediction: 0.8717320018359942/[0.4777593] </row>
		<row> train/prediction: 0.8718082908339966/[0.47481868] </row>
		<row> train/prediction: 0.871884579831999/[0.47160086] </row>
		<row> train/prediction: 0.8719608688299445/[0.4684091] </row>
		<row> train/prediction: 0.8720371578279469/[0.46529534] </row>
		<row> train/prediction: 0.8721134468259493/[0.46210122] </row>
		<row> train/prediction: 0.8721897358238948/[0.4592473] </row>
		<row> train/prediction: 0.8722660248218972/[0.45640674] </row>
		<row> train/prediction: 0.8723423138198996/[0.45380193] </row>
		<row> train/prediction: 0.8724186028178451/[0.4512626] </row>
		<row> train/prediction: 0.8724948918158475/[0.4492979] </row>
		<row> train/prediction: 0.872571180813793/[0.44749868] </row>
		<row> train/prediction: 0.8726474698117954/[0.4457031] </row>
		<row> train/prediction: 0.8727237588097978/[0.4442572] </row>
		<row> train/prediction: 0.8728000478077433/[0.442875] </row>
		<row> train/prediction: 0.8728763368057457/[0.44174147] </row>
		<row> train/prediction: 0.8729526258037481/[0.4406806] </row>
		<row> train/prediction: 0.8730289148016936/[0.44031292] </row>
		<row> train/prediction: 0.873105203799696/[0.4401261] </row>
		<row> train/prediction: 0.8731814927976984/[0.44043317] </row>
		<row> train/prediction: 0.873257781795644/[0.44129238] </row>
		<row> train/prediction: 0.8733340707936463/[0.44234702] </row>
		<row> train/prediction: 0.8734103597916487/[0.44384962] </row>
		<row> train/prediction: 0.8734866487895943/[0.4453223] </row>
		<row> train/prediction: 0.8735629377875966/[0.44695368] </row>
		<row> train/prediction: 0.8736392267855422/[0.44893843] </row>
		<row> train/prediction: 0.8737155157835446/[0.4513256] </row>
		<row> train/prediction: 0.8737918047815469/[0.4539631] </row>
		<row> train/prediction: 0.8738680937794925/[0.4563602] </row>
		<row> train/prediction: 0.8739443827774949/[0.45853478] </row>
		<row> train/prediction: 0.8740206717754972/[0.46070984] </row>
		<row> train/prediction: 0.8740972150700941/[0.46285486] </row>
		<row> train/prediction: 0.8741735040680965/[0.46469268] </row>
		<row> train/prediction: 0.8742497930660988/[0.4662849] </row>
		<row> train/prediction: 0.8743260820640444/[0.4672274] </row>
		<row> train/prediction: 0.8744023710620468/[0.4678887] </row>
		<row> train/prediction: 0.8744786600600492/[0.46839285] </row>
		<row> train/prediction: 0.8745549490579947/[0.46856046] </row>
		<row> train/prediction: 0.8746312380559971/[0.46919733] </row>
		<row> train/prediction: 0.8747075270539995/[0.4692158] </row>
		<row> train/prediction: 0.874783816051945/[0.46949065] </row>
		<row> train/prediction: 0.8748601050499474/[0.46967688] </row>
		<row> train/prediction: 0.8749363940479498/[0.46991873] </row>
		<row> train/prediction: 0.8750126830458953/[0.4699208] </row>
		<row> train/prediction: 0.8750889720438977/[0.46997857] </row>
		<row> train/prediction: 0.8751652610419001/[0.47019637] </row>
		<row> train/prediction: 0.8752415500398456/[0.47019354] </row>
		<row> train/prediction: 0.875317839037848/[0.4697181] </row>
		<row> train/prediction: 0.8753941280357935/[0.46930236] </row>
		<row> train/prediction: 0.8754704170337959/[0.46983382] </row>
		<row> train/prediction: 0.8755467060317983/[0.47026974] </row>
		<row> train/prediction: 0.8756229950297438/[0.47117144] </row>
		<row> train/prediction: 0.8756992840277462/[0.47173324] </row>
		<row> train/prediction: 0.8757755730257486/[0.47261092] </row>
		<row> train/prediction: 0.8758518620236941/[0.47372833] </row>
		<row> train/prediction: 0.8759281510216965/[0.47463974] </row>
		<row> train/prediction: 0.8760044400196989/[0.47608447] </row>
		<row> train/prediction: 0.8760807290176444/[0.47748706] </row>
		<row> train/prediction: 0.8761570180156468/[0.47974604] </row>
		<row> train/prediction: 0.8762333070136492/[0.48118863] </row>
		<row> train/prediction: 0.8763095960115947/[0.48289567] </row>
		<row> train/prediction: 0.8763858850095971/[0.48397642] </row>
		<row> train/prediction: 0.8764621740075427/[0.4853272] </row>
		<row> train/prediction: 0.876538463005545/[0.48714542] </row>
		<row> train/prediction: 0.8766147520035474/[0.4885938] </row>
		<row> train/prediction: 0.876691041001493/[0.489549] </row>
		<row> train/prediction: 0.8767673299994954/[0.49017644] </row>
		<row> train/prediction: 0.8768436189974977/[0.4909165] </row>
		<row> train/prediction: 0.8769199079954433/[0.4915673] </row>
		<row> train/prediction: 0.8769961969934457/[0.49289215] </row>
		<row> train/prediction: 0.877072485991448/[0.4937771] </row>
		<row> train/prediction: 0.8771487749893936/[0.494742] </row>
		<row> train/prediction: 0.877225063987396/[0.49606785] </row>
		<row> train/prediction: 0.8773013529853984/[0.49697718] </row>
		<row> train/prediction: 0.8773776419833439/[0.49744698] </row>
		<row> train/prediction: 0.8774539309813463/[0.4974633] </row>
		<row> train/prediction: 0.8775302199792918/[0.4976633] </row>
		<row> train/prediction: 0.8776065089772942/[0.49804437] </row>
		<row> train/prediction: 0.8776827979752966/[0.4984846] </row>
		<row> train/prediction: 0.8777590869732421/[0.4980364] </row>
		<row> train/prediction: 0.8778353759712445/[0.498111] </row>
		<row> train/prediction: 0.8779116649692469/[0.49799567] </row>
		<row> train/prediction: 0.8779879539671924/[0.49761006] </row>
		<row> train/prediction: 0.8780642429651948/[0.49775028] </row>
		<row> train/prediction: 0.8781405319631972/[0.4968233] </row>
		<row> train/prediction: 0.8782168209611427/[0.49672928] </row>
		<row> train/prediction: 0.8782931099591451/[0.49730992] </row>
		<row> train/prediction: 0.8783693989571475/[0.4976412] </row>
		<row> train/prediction: 0.878445687955093/[0.49821955] </row>
		<row> train/prediction: 0.8785219769530954/[0.49854666] </row>
		<row> train/prediction: 0.878598265951041/[0.49812344] </row>
		<row> train/prediction: 0.8786745549490433/[0.49880275] </row>
		<row> train/prediction: 0.8787508439470457/[0.49962234] </row>
		<row> train/prediction: 0.8788271329449913/[0.49948984] </row>
		<row> train/prediction: 0.8789034219429936/[0.50099486] </row>
		<row> train/prediction: 0.878979710940996/[0.50169766] </row>
		<row> train/prediction: 0.8790559999389416/[0.50219846] </row>
		<row> train/prediction: 0.879132288936944/[0.5031849] </row>
		<row> train/prediction: 0.8792085779349463/[0.50441426] </row>
		<row> train/prediction: 0.8792848669328919/[0.5068919] </row>
		<row> train/prediction: 0.8793611559308943/[0.5091308] </row>
		<row> train/prediction: 0.8794374449288966/[0.5118905] </row>
		<row> train/prediction: 0.8795137339268422/[0.51442784] </row>
		<row> train/prediction: 0.8795900229248446/[0.5182901] </row>
		<row> train/prediction: 0.8796663119228469/[0.5211679] </row>
		<row> train/prediction: 0.8797426009207925/[0.5244234] </row>
		<row> train/prediction: 0.8798188899187949/[0.52676594] </row>
		<row> train/prediction: 0.8798951789167404/[0.52887535] </row>
		<row> train/prediction: 0.8799714679147428/[0.5310044] </row>
		<row> train/prediction: 0.8800477569127452/[0.5328618] </row>
		<row> train/prediction: 0.8801240459106907/[0.5344935] </row>
		<row> train/prediction: 0.8802003349086931/[0.5347019] </row>
		<row> train/prediction: 0.8802766239066955/[0.5359327] </row>
		<row> train/prediction: 0.880352912904641/[0.537177] </row>
		<row> train/prediction: 0.8804292019026434/[0.5375099] </row>
		<row> train/prediction: 0.8805054909006458/[0.5374585] </row>
		<row> train/prediction: 0.8805817798985913/[0.53789884] </row>
		<row> train/prediction: 0.8806580688965937/[0.5394169] </row>
		<row> train/prediction: 0.8807343578945961/[0.5407952] </row>
		<row> train/prediction: 0.8808106468925416/[0.54286367] </row>
		<row> train/prediction: 0.880886935890544/[0.54492414] </row>
		<row> train/prediction: 0.8809632248884895/[0.5484776] </row>
		<row> train/prediction: 0.8810395138864919/[0.5523035] </row>
		<row> train/prediction: 0.8811158028844943/[0.55540836] </row>
		<row> train/prediction: 0.8811920918824399/[0.5577846] </row>
		<row> train/prediction: 0.8812683808804422/[0.56099635] </row>
		<row> train/prediction: 0.8813446698784446/[0.5640781] </row>
		<row> train/prediction: 0.8814209588763902/[0.5671329] </row>
		<row> train/prediction: 0.8814972478743925/[0.5709578] </row>
		<row> train/prediction: 0.8815735368723949/[0.5736105] </row>
		<row> train/prediction: 0.8816498258703405/[0.5766672] </row>
		<row> train/prediction: 0.8817261148683428/[0.579798] </row>
		<row> train/prediction: 0.8818024038663452/[0.5822729] </row>
		<row> train/prediction: 0.8818786928642908/[0.58578855] </row>
		<row> train/prediction: 0.8819549818622932/[0.5884206] </row>
		<row> train/prediction: 0.8820312708602387/[0.5910956] </row>
		<row> train/prediction: 0.8821075598582411/[0.592965] </row>
		<row> train/prediction: 0.8821838488562435/[0.5937007] </row>
		<row> train/prediction: 0.882260137854189/[0.5950684] </row>
		<row> train/prediction: 0.8823364268521914/[0.596859] </row>
		<row> train/prediction: 0.8824127158501938/[0.59853196] </row>
		<row> train/prediction: 0.8824890048481393/[0.60024756] </row>
		<row> train/prediction: 0.8825652938461417/[0.6018216] </row>
		<row> train/prediction: 0.8826415828441441/[0.60281146] </row>
		<row> train/prediction: 0.8827178718420896/[0.6047459] </row>
		<row> train/prediction: 0.882794160840092/[0.6057928] </row>
		<row> train/prediction: 0.8828704498380944/[0.60775083] </row>
		<row> train/prediction: 0.8829467388360399/[0.60946125] </row>
		<row> train/prediction: 0.8830230278340423/[0.61062986] </row>
		<row> train/prediction: 0.8830993168319878/[0.6121388] </row>
		<row> train/prediction: 0.8831756058299902/[0.61325014] </row>
		<row> train/prediction: 0.8832518948279926/[0.6148457] </row>
		<row> train/prediction: 0.8833281838259381/[0.6164087] </row>
		<row> train/prediction: 0.8834044728239405/[0.61801887] </row>
		<row> train/prediction: 0.8834807618219429/[0.6185894] </row>
		<row> train/prediction: 0.8835570508198884/[0.6198679] </row>
		<row> train/prediction: 0.8836333398178908/[0.62041545] </row>
		<row> train/prediction: 0.8837096288158932/[0.62066793] </row>
		<row> train/prediction: 0.8837859178138388/[0.6208743] </row>
		<row> train/prediction: 0.8838622068118411/[0.620929] </row>
		<row> train/prediction: 0.8839384958098435/[0.6216252] </row>
		<row> train/prediction: 0.8840147848077891/[0.62265974] </row>
		<row> train/prediction: 0.8840910738057914/[0.62444603] </row>
		<row> train/prediction: 0.8841673628037938/[0.6254639] </row>
		<row> train/prediction: 0.8842436518017394/[0.6262685] </row>
		<row> train/prediction: 0.8843199407997417/[0.6273887] </row>
		<row> train/prediction: 0.8843962297976873/[0.6286909] </row>
		<row> train/prediction: 0.8844725187956897/[0.62954277] </row>
		<row> train/prediction: 0.884548807793692/[0.63187706] </row>
		<row> train/prediction: 0.8846250967916376/[0.63373697] </row>
		<row> train/prediction: 0.88470138578964/[0.6353558] </row>
		<row> train/prediction: 0.8847776747876424/[0.6378666] </row>
		<row> train/prediction: 0.8848539637855879/[0.63891655] </row>
		<row> train/prediction: 0.8849302527835903/[0.63985324] </row>
		<row> train/prediction: 0.8850065417815927/[0.64131415] </row>
		<row> train/prediction: 0.8850833393728976/[0.642623] </row>
		<row> train/prediction: 0.8851596283708432/[0.6431744] </row>
		<row> train/prediction: 0.8852359173688455/[0.6438871] </row>
		<row> train/prediction: 0.8853122063667911/[0.6443956] </row>
		<row> train/prediction: 0.8853884953647935/[0.644351] </row>
		<row> train/prediction: 0.8854647843627959/[0.64576834] </row>
		<row> train/prediction: 0.8855410733607414/[0.64692026] </row>
		<row> train/prediction: 0.8856173623587438/[0.6479415] </row>
		<row> train/prediction: 0.8856936513567462/[0.64891124] </row>
		<row> train/prediction: 0.8857699403546917/[0.64971167] </row>
		<row> train/prediction: 0.8858462293526941/[0.6506551] </row>
		<row> train/prediction: 0.8859225183506965/[0.6516166] </row>
		<row> train/prediction: 0.885998807348642/[0.65330404] </row>
		<row> train/prediction: 0.8860750963466444/[0.6543932] </row>
		<row> train/prediction: 0.8861513853446468/[0.655746] </row>
		<row> train/prediction: 0.8862276743425923/[0.6571193] </row>
		<row> train/prediction: 0.8863039633405947/[0.65850174] </row>
		<row> train/prediction: 0.8863802523385402/[0.65964484] </row>
		<row> train/prediction: 0.8864565413365426/[0.66115856] </row>
		<row> train/prediction: 0.886532830334545/[0.66288894] </row>
		<row> train/prediction: 0.8866091193324905/[0.6637078] </row>
		<row> train/prediction: 0.8866854083304929/[0.665247] </row>
		<row> train/prediction: 0.8867616973284953/[0.66604465] </row>
		<row> train/prediction: 0.8868379863264408/[0.6671628] </row>
		<row> train/prediction: 0.8869142753244432/[0.66794026] </row>
		<row> train/prediction: 0.8869905643224456/[0.6691624] </row>
		<row> train/prediction: 0.8870668533203911/[0.6701716] </row>
		<row> train/prediction: 0.8871431423183935/[0.67105967] </row>
		<row> train/prediction: 0.8872194313163959/[0.67209893] </row>
		<row> train/prediction: 0.8872957203143415/[0.6733547] </row>
		<row> train/prediction: 0.8873720093123438/[0.6752147] </row>
		<row> train/prediction: 0.8874482983103462/[0.6761417] </row>
		<row> train/prediction: 0.8875245873082918/[0.6780049] </row>
		<row> train/prediction: 0.8876008763062941/[0.6787733] </row>
		<row> train/prediction: 0.8876771653042397/[0.67994946] </row>
		<row> train/prediction: 0.8877534543022421/[0.68228424] </row>
		<row> train/prediction: 0.8878297433002444/[0.6839376] </row>
		<row> train/prediction: 0.88790603229819/[0.68553674] </row>
		<row> train/prediction: 0.8879823212961924/[0.68733907] </row>
		<row> train/prediction: 0.8880586102941948/[0.68919694] </row>
		<row> train/prediction: 0.8881348992921403/[0.68992233] </row>
		<row> train/prediction: 0.8882111882901427/[0.6910794] </row>
		<row> train/prediction: 0.888287477288145/[0.6913774] </row>
		<row> train/prediction: 0.8883637662860906/[0.69176745] </row>
		<row> train/prediction: 0.888440055284093/[0.69287354] </row>
		<row> train/prediction: 0.8885163442820954/[0.6934348] </row>
		<row> train/prediction: 0.8885926332800409/[0.694516] </row>
		<row> train/prediction: 0.8886689222780433/[0.69476646] </row>
		<row> train/prediction: 0.8887452112759888/[0.6942994] </row>
		<row> train/prediction: 0.8888215002739912/[0.6940205] </row>
		<row> train/prediction: 0.8888977892719936/[0.6939226] </row>
		<row> train/prediction: 0.8889740782699391/[0.6935824] </row>
		<row> train/prediction: 0.8890503672679415/[0.69343793] </row>
		<row> train/prediction: 0.8891266562659439/[0.69333404] </row>
		<row> train/prediction: 0.8892029452638894/[0.69351417] </row>
		<row> train/prediction: 0.8892792342618918/[0.69368744] </row>
		<row> train/prediction: 0.8893555232598942/[0.6932397] </row>
		<row> train/prediction: 0.8894318122578397/[0.69349676] </row>
		<row> train/prediction: 0.8895081012558421/[0.69406897] </row>
		<row> train/prediction: 0.8895843902538445/[0.69418955] </row>
		<row> train/prediction: 0.88966067925179/[0.6948839] </row>
		<row> train/prediction: 0.8897369682497924/[0.6947832] </row>
		<row> train/prediction: 0.889813257247738/[0.69445044] </row>
		<row> train/prediction: 0.8898895462457403/[0.69388294] </row>
		<row> train/prediction: 0.8899658352437427/[0.69463587] </row>
		<row> train/prediction: 0.8900421242416883/[0.6942152] </row>
		<row> train/prediction: 0.8901184132396907/[0.6947117] </row>
		<row> train/prediction: 0.890194702237693/[0.6941067] </row>
		<row> train/prediction: 0.8902709912356386/[0.6933283] </row>
		<row> train/prediction: 0.890347280233641/[0.692652] </row>
		<row> train/prediction: 0.8904235692316433/[0.6916227] </row>
		<row> train/prediction: 0.8904998582295889/[0.69081247] </row>
		<row> train/prediction: 0.8905764015242426/[0.68924594] </row>
		<row> train/prediction: 0.8906526905222449/[0.68863964] </row>
		<row> train/prediction: 0.8907289795201905/[0.68747866] </row>
		<row> train/prediction: 0.8908052685181929/[0.68724287] </row>
		<row> train/prediction: 0.8908815575161952/[0.6871669] </row>
		<row> train/prediction: 0.8909578465141408/[0.6868119] </row>
		<row> train/prediction: 0.8910341355121432/[0.68681544] </row>
		<row> train/prediction: 0.8911104245101455/[0.68696404] </row>
		<row> train/prediction: 0.8911867135080911/[0.6866362] </row>
		<row> train/prediction: 0.8912630025060935/[0.6852532] </row>
		<row> train/prediction: 0.8913392915040959/[0.6841197] </row>
		<row> train/prediction: 0.8914155805020414/[0.6826004] </row>
		<row> train/prediction: 0.8914918695000438/[0.6809766] </row>
		<row> train/prediction: 0.8915681584979893/[0.67998606] </row>
		<row> train/prediction: 0.8916444474959917/[0.6791169] </row>
		<row> train/prediction: 0.8917207364939941/[0.67744577] </row>
		<row> train/prediction: 0.8917970254919396/[0.6754365] </row>
		<row> train/prediction: 0.891873314489942/[0.67352575] </row>
		<row> train/prediction: 0.8919496034879444/[0.6713445] </row>
		<row> train/prediction: 0.8920258924858899/[0.66891545] </row>
		<row> train/prediction: 0.8921021814838923/[0.6663739] </row>
		<row> train/prediction: 0.8921784704818947/[0.6645423] </row>
		<row> train/prediction: 0.8922547594798402/[0.662137] </row>
		<row> train/prediction: 0.8923310484778426/[0.6599342] </row>
		<row> train/prediction: 0.892407337475845/[0.6575601] </row>
		<row> train/prediction: 0.8924836264737905/[0.6557279] </row>
		<row> train/prediction: 0.8925599154717929/[0.65415335] </row>
		<row> train/prediction: 0.8926362044697385/[0.65207326] </row>
		<row> train/prediction: 0.8927124934677408/[0.6500432] </row>
		<row> train/prediction: 0.8927887824657432/[0.648468] </row>
		<row> train/prediction: 0.8928650714636888/[0.6460672] </row>
		<row> train/prediction: 0.8929413604616911/[0.6437856] </row>
		<row> train/prediction: 0.8930176494596935/[0.6420261] </row>
		<row> train/prediction: 0.8930939384576391/[0.6411219] </row>
		<row> train/prediction: 0.8931702274556415/[0.63971967] </row>
		<row> train/prediction: 0.8932465164536438/[0.63905096] </row>
		<row> train/prediction: 0.8933228054515894/[0.6382228] </row>
		<row> train/prediction: 0.8933990944495918/[0.6367698] </row>
		<row> train/prediction: 0.8934753834475941/[0.6354759] </row>
		<row> train/prediction: 0.8935516724455397/[0.6332783] </row>
		<row> train/prediction: 0.8936279614435421/[0.63110346] </row>
		<row> train/prediction: 0.8937042504414876/[0.62928766] </row>
		<row> train/prediction: 0.89378053943949/[0.6274082] </row>
		<row> train/prediction: 0.8938568284374924/[0.62530154] </row>
		<row> train/prediction: 0.8939331174354379/[0.6229277] </row>
		<row> train/prediction: 0.8940094064334403/[0.61934793] </row>
		<row> train/prediction: 0.8940856954314427/[0.6164712] </row>
		<row> train/prediction: 0.8941619844293882/[0.6133133] </row>
		<row> train/prediction: 0.8942382734273906/[0.60973746] </row>
		<row> train/prediction: 0.894314562425393/[0.6061572] </row>
		<row> train/prediction: 0.8943908514233385/[0.6032358] </row>
		<row> train/prediction: 0.8944671404213409/[0.60152113] </row>
		<row> train/prediction: 0.8945434294193433/[0.59935915] </row>
		<row> train/prediction: 0.8946197184172888/[0.59808224] </row>
		<row> train/prediction: 0.8946960074152912/[0.59704226] </row>
		<row> train/prediction: 0.8947722964132936/[0.5968411] </row>
		<row> train/prediction: 0.8948485854112391/[0.5952458] </row>
		<row> train/prediction: 0.8949248744092415/[0.5933313] </row>
		<row> train/prediction: 0.895001163407187/[0.5915643] </row>
		<row> train/prediction: 0.8950774524051894/[0.5897298] </row>
		<row> train/prediction: 0.8951537414031918/[0.58923703] </row>
		<row> train/prediction: 0.8952300304011374/[0.5882031] </row>
		<row> train/prediction: 0.8953063193991397/[0.5880059] </row>
		<row> train/prediction: 0.8953826083971421/[0.58658093] </row>
		<row> train/prediction: 0.8954588973950877/[0.5862013] </row>
		<row> train/prediction: 0.89553518639309/[0.5856131] </row>
		<row> train/prediction: 0.8956114753910924/[0.5855621] </row>
		<row> train/prediction: 0.895687764389038/[0.58502156] </row>
		<row> train/prediction: 0.8957640533870403/[0.5847554] </row>
		<row> train/prediction: 0.8958403423850427/[0.58513904] </row>
		<row> train/prediction: 0.8959166313829883/[0.5859957] </row>
		<row> train/prediction: 0.8959929203809907/[0.58641165] </row>
		<row> train/prediction: 0.8960694636756443/[0.58691597] </row>
		<row> train/prediction: 0.8961457526735899/[0.58764607] </row>
		<row> train/prediction: 0.8962220416715923/[0.58870274] </row>
		<row> train/prediction: 0.8962983306695946/[0.5899928] </row>
		<row> train/prediction: 0.8963746196675402/[0.5906782] </row>
		<row> train/prediction: 0.8964509086655426/[0.5910185] </row>
		<row> train/prediction: 0.8965271976634881/[0.59082496] </row>
		<row> train/prediction: 0.8966034866614905/[0.5911212] </row>
		<row> train/prediction: 0.8966797756594929/[0.59139395] </row>
		<row> train/prediction: 0.8967560646574384/[0.59120417] </row>
		<row> train/prediction: 0.8968323536554408/[0.5923666] </row>
		<row> train/prediction: 0.8969086426534432/[0.59251755] </row>
		<row> train/prediction: 0.8969849316513887/[0.5927726] </row>
		<row> train/prediction: 0.8970612206493911/[0.5921647] </row>
		<row> train/prediction: 0.8971375096473935/[0.59081084] </row>
		<row> train/prediction: 0.897213798645339/[0.5895384] </row>
		<row> train/prediction: 0.8972900876433414/[0.5881366] </row>
		<row> train/prediction: 0.8973663766413438/[0.58613825] </row>
		<row> train/prediction: 0.8974426656392893/[0.5853482] </row>
		<row> train/prediction: 0.8975189546372917/[0.58458054] </row>
		<row> train/prediction: 0.8975952436352372/[0.58347934] </row>
		<row> train/prediction: 0.8976715326332396/[0.58202326] </row>
		<row> train/prediction: 0.897747821631242/[0.58132714] </row>
		<row> train/prediction: 0.8978241106291875/[0.58075106] </row>
		<row> train/prediction: 0.8979003996271899/[0.5801706] </row>
		<row> train/prediction: 0.8979766886251923/[0.579607] </row>
		<row> train/prediction: 0.8980529776231378/[0.57867485] </row>
		<row> train/prediction: 0.8981292666211402/[0.5780266] </row>
		<row> train/prediction: 0.8982055556191426/[0.57783127] </row>
		<row> train/prediction: 0.8982818446170882/[0.5775319] </row>
		<row> train/prediction: 0.8983581336150905/[0.57699484] </row>
		<row> train/prediction: 0.8984344226130929/[0.57628644] </row>
		<row> train/prediction: 0.8985107116110385/[0.5754582] </row>
		<row> train/prediction: 0.8985870006090408/[0.5743007] </row>
		<row> train/prediction: 0.8986632896070432/[0.57290316] </row>
		<row> train/prediction: 0.8987395786049888/[0.5717549] </row>
		<row> train/prediction: 0.8988158676029911/[0.57047755] </row>
		<row> train/prediction: 0.8988921566009367/[0.5700427] </row>
		<row> train/prediction: 0.8989684455989391/[0.5688848] </row>
		<row> train/prediction: 0.8990447345969415/[0.5683598] </row>
		<row> train/prediction: 0.899121023594887/[0.56747675] </row>
		<row> train/prediction: 0.8991973125928894/[0.56704265] </row>
		<row> train/prediction: 0.8992736015908918/[0.56674814] </row>
		<row> train/prediction: 0.8993498905888373/[0.5658118] </row>
		<row> train/prediction: 0.8994261795868397/[0.56463253] </row>
		<row> train/prediction: 0.8995024685848421/[0.5624892] </row>
		<row> train/prediction: 0.8995787575827876/[0.5611073] </row>
		<row> train/prediction: 0.89965504658079/[0.5590202] </row>
		<row> train/prediction: 0.8997313355787924/[0.5577855] </row>
		<row> train/prediction: 0.8998076245767379/[0.5560704] </row>
		<row> train/prediction: 0.8998839135747403/[0.5552135] </row>
		<row> train/prediction: 0.8999602025726858/[0.5547043] </row>
		<row> train/prediction: 0.9000364915706882/[0.5540553] </row>
		<row> train/prediction: 0.9001127805686906/[0.5521909] </row>
		<row> train/prediction: 0.9001890695666361/[0.5501608] </row>
		<row> train/prediction: 0.9002653585646385/[0.54852027] </row>
		<row> train/prediction: 0.9003416475626409/[0.54659647] </row>
		<row> train/prediction: 0.9004179365605864/[0.54498196] </row>
		<row> train/prediction: 0.9004942255585888/[0.54341984] </row>
		<row> train/prediction: 0.9005705145565912/[0.5424943] </row>
		<row> train/prediction: 0.9006468035545367/[0.5416009] </row>
		<row> train/prediction: 0.9007230925525391/[0.5408745] </row>
		<row> train/prediction: 0.9007993815505415/[0.54001033] </row>
		<row> train/prediction: 0.900875670548487/[0.5398337] </row>
		<row> train/prediction: 0.9009519595464894/[0.54011905] </row>
		<row> train/prediction: 0.901028248544435/[0.5403636] </row>
		<row> train/prediction: 0.9011045375424374/[0.5412661] </row>
		<row> train/prediction: 0.9011808265404397/[0.54197466] </row>
		<row> train/prediction: 0.9012571155383853/[0.5433844] </row>
		<row> train/prediction: 0.9013334045363877/[0.5446931] </row>
		<row> train/prediction: 0.90140969353439/[0.5475315] </row>
		<row> train/prediction: 0.9014859825323356/[0.54960346] </row>
		<row> train/prediction: 0.9015625258269893/[0.5523136] </row>
		<row> train/prediction: 0.9016388148249916/[0.55418694] </row>
		<row> train/prediction: 0.9017151038229372/[0.55605763] </row>
		<row> train/prediction: 0.9017913928209396/[0.5574667] </row>
		<row> train/prediction: 0.901867681818942/[0.5584268] </row>
		<row> train/prediction: 0.9019439708168875/[0.55943996] </row>
		<row> train/prediction: 0.9020202598148899/[0.5605861] </row>
		<row> train/prediction: 0.9020965488128923/[0.5612623] </row>
		<row> train/prediction: 0.9021728378108378/[0.56212205] </row>
		<row> train/prediction: 0.9022491268088402/[0.56326586] </row>
		<row> train/prediction: 0.9023254158068426/[0.56390285] </row>
		<row> train/prediction: 0.9024017048047881/[0.56470615] </row>
		<row> train/prediction: 0.9024779938027905/[0.56546557] </row>
		<row> train/prediction: 0.9025542828007929/[0.5663007] </row>
		<row> train/prediction: 0.9026305717987384/[0.56693774] </row>
		<row> train/prediction: 0.9027068607967408/[0.56835663] </row>
		<row> train/prediction: 0.9027831497946863/[0.5691936] </row>
		<row> train/prediction: 0.9028594387926887/[0.56980956] </row>
		<row> train/prediction: 0.9029357277906911/[0.5708025] </row>
		<row> train/prediction: 0.9030120167886366/[0.5719689] </row>
		<row> train/prediction: 0.903088305786639/[0.57385355] </row>
		<row> train/prediction: 0.9031645947846414/[0.5761464] </row>
		<row> train/prediction: 0.9032408837825869/[0.57806474] </row>
		<row> train/prediction: 0.9033171727805893/[0.5796265] </row>
		<row> train/prediction: 0.9033934617785917/[0.5805451] </row>
		<row> train/prediction: 0.9034697507765372/[0.58103347] </row>
		<row> train/prediction: 0.9035460397745396/[0.58240587] </row>
		<row> train/prediction: 0.903622328772542/[0.58423656] </row>
		<row> train/prediction: 0.9036986177704875/[0.5858845] </row>
		<row> train/prediction: 0.9037749067684899/[0.58794904] </row>
		<row> train/prediction: 0.9038511957664355/[0.58964354] </row>
		<row> train/prediction: 0.9039274847644378/[0.5905081] </row>
		<row> train/prediction: 0.9040037737624402/[0.59092665] </row>
		<row> train/prediction: 0.9040800627603858/[0.5904964] </row>
		<row> train/prediction: 0.9041563517583882/[0.5907263] </row>
		<row> train/prediction: 0.9042326407563905/[0.5911346] </row>
		<row> train/prediction: 0.9043089297543361/[0.59064996] </row>
		<row> train/prediction: 0.9043852187523385/[0.5904919] </row>
		<row> train/prediction: 0.9044615077503408/[0.5891164] </row>
		<row> train/prediction: 0.9045377967482864/[0.5885652] </row>
		<row> train/prediction: 0.9046140857462888/[0.58765] </row>
		<row> train/prediction: 0.9046903747442911/[0.58716476] </row>
		<row> train/prediction: 0.9047666637422367/[0.58665687] </row>
		<row> train/prediction: 0.9048429527402391/[0.58651656] </row>
		<row> train/prediction: 0.9049192417381846/[0.58653116] </row>
		<row> train/prediction: 0.904995530736187/[0.5847925] </row>
		<row> train/prediction: 0.9050718197341894/[0.5828281] </row>
		<row> train/prediction: 0.9051481087321349/[0.5820491] </row>
		<row> train/prediction: 0.9052243977301373/[0.5808523] </row>
		<row> train/prediction: 0.9053006867281397/[0.580084] </row>
		<row> train/prediction: 0.9053769757260852/[0.5789888] </row>
		<row> train/prediction: 0.9054532647240876/[0.57772374] </row>
		<row> train/prediction: 0.90552955372209/[0.57661134] </row>
		<row> train/prediction: 0.9056058427200355/[0.57404447] </row>
		<row> train/prediction: 0.9056821317180379/[0.5719748] </row>
		<row> train/prediction: 0.9057584207160403/[0.56965196] </row>
		<row> train/prediction: 0.9058347097139858/[0.5682825] </row>
		<row> train/prediction: 0.9059109987119882/[0.5688714] </row>
		<row> train/prediction: 0.9059872877099906/[0.5686532] </row>
		<row> train/prediction: 0.9060635767079361/[0.5673993] </row>
		<row> train/prediction: 0.9061398657059385/[0.5664685] </row>
		<row> train/prediction: 0.9062161547038841/[0.5664822] </row>
		<row> train/prediction: 0.9062924437018864/[0.5664138] </row>
		<row> train/prediction: 0.9063687326998888/[0.56694627] </row>
		<row> train/prediction: 0.9064450216978344/[0.56711394] </row>
		<row> train/prediction: 0.9065213106958367/[0.5672462] </row>
		<row> train/prediction: 0.9065975996938391/[0.56815916] </row>
		<row> train/prediction: 0.9066738886917847/[0.56891483] </row>
		<row> train/prediction: 0.906750177689787/[0.5691555] </row>
		<row> train/prediction: 0.9068264666877894/[0.5698799] </row>
		<row> train/prediction: 0.906902755685735/[0.56981486] </row>
		<row> train/prediction: 0.9069790446837374/[0.56975394] </row>
		<row> train/prediction: 0.907055587978391/[0.56981236] </row>
		<row> train/prediction: 0.9071318769763366/[0.570889] </row>
		<row> train/prediction: 0.907208165974339/[0.57000834] </row>
		<row> train/prediction: 0.9072844549723413/[0.5702492] </row>
		<row> train/prediction: 0.9073607439702869/[0.5705227] </row>
		<row> train/prediction: 0.9074370329682893/[0.5696746] </row>
		<row> train/prediction: 0.9075133219662916/[0.56976813] </row>
		<row> train/prediction: 0.9075896109642372/[0.5685231] </row>
		<row> train/prediction: 0.9076658999622396/[0.56837016] </row>
		<row> train/prediction: 0.9077421889601851/[0.5667955] </row>
		<row> train/prediction: 0.9078184779581875/[0.56549245] </row>
		<row> train/prediction: 0.9078947669561899/[0.56549555] </row>
		<row> train/prediction: 0.9079710559541354/[0.56408733] </row>
		<row> train/prediction: 0.9080473449521378/[0.5613217] </row>
		<row> train/prediction: 0.9081236339501402/[0.5599258] </row>
		<row> train/prediction: 0.9081999229480857/[0.55802417] </row>
		<row> train/prediction: 0.9082762119460881/[0.5565813] </row>
		<row> train/prediction: 0.9083525009440905/[0.5541614] </row>
		<row> train/prediction: 0.908428789942036/[0.5521258] </row>
		<row> train/prediction: 0.9085050789400384/[0.55073476] </row>
		<row> train/prediction: 0.9085813679380408/[0.54960704] </row>
		<row> train/prediction: 0.9086576569359863/[0.5499564] </row>
		<row> train/prediction: 0.9087339459339887/[0.5475288] </row>
		<row> train/prediction: 0.9088102349319342/[0.54535455] </row>
		<row> train/prediction: 0.9088865239299366/[0.54409295] </row>
		<row> train/prediction: 0.908962812927939/[0.54353964] </row>
		<row> train/prediction: 0.9090391019258846/[0.5451583] </row>
		<row> train/prediction: 0.9091153909238869/[0.5438605] </row>
		<row> train/prediction: 0.9091916799218893/[0.54308385] </row>
		<row> train/prediction: 0.9092679689198349/[0.54317164] </row>
		<row> train/prediction: 0.9093442579178372/[0.54315877] </row>
		<row> train/prediction: 0.9094205469158396/[0.5436731] </row>
		<row> train/prediction: 0.9094968359137852/[0.5465488] </row>
		<row> train/prediction: 0.9095731249117875/[0.5476479] </row>
		<row> train/prediction: 0.9096494139097899/[0.5487131] </row>
		<row> train/prediction: 0.9097257029077355/[0.5512452] </row>
		<row> train/prediction: 0.9098019919057379/[0.5518728] </row>
		<row> train/prediction: 0.9098782809037402/[0.55411935] </row>
		<row> train/prediction: 0.9099545699016858/[0.555855] </row>
		<row> train/prediction: 0.9100308588996882/[0.5572295] </row>
		<row> train/prediction: 0.9101071478976337/[0.5601665] </row>
		<row> train/prediction: 0.9101834368956361/[0.5610291] </row>
		<row> train/prediction: 0.9102597258936385/[0.5630062] </row>
		<row> train/prediction: 0.910336014891584/[0.5639956] </row>
		<row> train/prediction: 0.9104123038895864/[0.565072] </row>
		<row> train/prediction: 0.9104885928875888/[0.56432676] </row>
		<row> train/prediction: 0.9105648818855343/[0.5648195] </row>
		<row> train/prediction: 0.9106411708835367/[0.56524646] </row>
		<row> train/prediction: 0.9107174598815391/[0.5644201] </row>
		<row> train/prediction: 0.9107937488794846/[0.5623832] </row>
		<row> train/prediction: 0.910870037877487/[0.56331193] </row>
		<row> train/prediction: 0.9109463268754894/[0.5639822] </row>
		<row> train/prediction: 0.9110226158734349/[0.56488895] </row>
		<row> train/prediction: 0.9110989048714373/[0.5664727] </row>
		<row> train/prediction: 0.9111751938693828/[0.5672869] </row>
		<row> train/prediction: 0.9112514828673852/[0.56792635] </row>
		<row> train/prediction: 0.9113277718653876/[0.56785125] </row>
		<row> train/prediction: 0.9114040608633331/[0.5686287] </row>
		<row> train/prediction: 0.9114803498613355/[0.5687442] </row>
		<row> train/prediction: 0.9115566388593379/[0.5688875] </row>
		<row> train/prediction: 0.9116329278572834/[0.5715335] </row>
		<row> train/prediction: 0.9117092168552858/[0.57166713] </row>
		<row> train/prediction: 0.9117855058532882/[0.5722465] </row>
		<row> train/prediction: 0.9118617948512338/[0.5720139] </row>
		<row> train/prediction: 0.9119380838492361/[0.5709975] </row>
		<row> train/prediction: 0.9120143728472385/[0.570008] </row>
		<row> train/prediction: 0.9120906618451841/[0.5704069] </row>
		<row> train/prediction: 0.9121669508431864/[0.57046145] </row>
		<row> train/prediction: 0.912243239841132/[0.5711339] </row>
		<row> train/prediction: 0.9123195288391344/[0.57092863] </row>
		<row> train/prediction: 0.9123958178371367/[0.56945074] </row>
		<row> train/prediction: 0.9124721068350823/[0.5688436] </row>
		<row> train/prediction: 0.912548650129736/[0.5704241] </row>
		<row> train/prediction: 0.9126249391277383/[0.57110703] </row>
		<row> train/prediction: 0.9127012281256839/[0.5711153] </row>
		<row> train/prediction: 0.9127775171236863/[0.57068753] </row>
		<row> train/prediction: 0.9128538061216886/[0.57235247] </row>
		<row> train/prediction: 0.9129300951196342/[0.57214016] </row>
		<row> train/prediction: 0.9130063841176366/[0.57096994] </row>
		<row> train/prediction: 0.913082673115639/[0.57264173] </row>
		<row> train/prediction: 0.9131589621135845/[0.57249475] </row>
		<row> train/prediction: 0.9132352511115869/[0.5734304] </row>
		<row> train/prediction: 0.9133115401095893/[0.5731675] </row>
		<row> train/prediction: 0.9133878291075348/[0.5730138] </row>
		<row> train/prediction: 0.9134641181055372/[0.57210314] </row>
		<row> train/prediction: 0.9135404071035396/[0.5722109] </row>
		<row> train/prediction: 0.9136166961014851/[0.57085186] </row>
		<row> train/prediction: 0.9136929850994875/[0.56941897] </row>
		<row> train/prediction: 0.9137692740974899/[0.56818473] </row>
		<row> train/prediction: 0.9138455630954354/[0.5684251] </row>
		<row> train/prediction: 0.9139218520934378/[0.568137] </row>
		<row> train/prediction: 0.9139981410913833/[0.5659818] </row>
		<row> train/prediction: 0.9140744300893857/[0.56421953] </row>
		<row> train/prediction: 0.9141507190873881/[0.562479] </row>
		<row> train/prediction: 0.9142270080853336/[0.56195885] </row>
		<row> train/prediction: 0.914303297083336/[0.5603212] </row>
		<row> train/prediction: 0.9143795860813384/[0.5586248] </row>
		<row> train/prediction: 0.9144558750792839/[0.55668116] </row>
		<row> train/prediction: 0.9145321640772863/[0.55591756] </row>
		<row> train/prediction: 0.9146084530752887/[0.55500823] </row>
		<row> train/prediction: 0.9146847420732342/[0.55407655] </row>
		<row> train/prediction: 0.9147610310712366/[0.553953] </row>
		<row> train/prediction: 0.914837320069239/[0.5529327] </row>
		<row> train/prediction: 0.9149136090671846/[0.5530384] </row>
		<row> train/prediction: 0.9149898980651869/[0.5513992] </row>
		<row> train/prediction: 0.9150661870631325/[0.54939693] </row>
		<row> train/prediction: 0.9151424760611349/[0.5479912] </row>
		<row> train/prediction: 0.9152187650591372/[0.546571] </row>
		<row> train/prediction: 0.9152950540570828/[0.54492974] </row>
		<row> train/prediction: 0.9153713430550852/[0.54446626] </row>
		<row> train/prediction: 0.9154476320530875/[0.54317874] </row>
		<row> train/prediction: 0.9155239210510331/[0.54176855] </row>
		<row> train/prediction: 0.9156002100490355/[0.5413564] </row>
		<row> train/prediction: 0.9156764990470379/[0.53920406] </row>
		<row> train/prediction: 0.9157527880449834/[0.5386315] </row>
		<row> train/prediction: 0.9158290770429858/[0.53804266] </row>
		<row> train/prediction: 0.9159053660409882/[0.53711003] </row>
		<row> train/prediction: 0.9198729025293346/[0.53597444] </row>
		<row> train/prediction: 0.919949191527337/[0.5364417] </row>
		<row> train/prediction: 0.9200254805253394/[0.53684545] </row>
		<row> train/prediction: 0.9201017695232849/[0.5375864] </row>
		<row> train/prediction: 0.9201780585212873/[0.5376139] </row>
		<row> train/prediction: 0.9202543475192897/[0.53755134] </row>
		<row> train/prediction: 0.9203306365172352/[0.5376019] </row>
		<row> train/prediction: 0.9204069255152376/[0.53756696] </row>
		<row> train/prediction: 0.92048321451324/[0.5371358] </row>
		<row> train/prediction: 0.9205595035111855/[0.5363536] </row>
		<row> train/prediction: 0.9206357925091879/[0.53535783] </row>
		<row> train/prediction: 0.9207120815071335/[0.53459626] </row>
		<row> train/prediction: 0.9207883705051358/[0.53394467] </row>
		<row> train/prediction: 0.9208646595031382/[0.53319997] </row>
		<row> train/prediction: 0.9209409485010838/[0.5322994] </row>
		<row> train/prediction: 0.9210172374990861/[0.5315042] </row>
		<row> train/prediction: 0.9210935264970885/[0.53012246] </row>
		<row> train/prediction: 0.9211698154950341/[0.52932733] </row>
		<row> train/prediction: 0.9212461044930365/[0.52839047] </row>
		<row> train/prediction: 0.9213223934910388/[0.5274466] </row>
		<row> train/prediction: 0.9213986824889844/[0.52757734] </row>
		<row> train/prediction: 0.9214749714869868/[0.527089] </row>
		<row> train/prediction: 0.9215512604849891/[0.52615243] </row>
		<row> train/prediction: 0.9216275494829347/[0.5255864] </row>
		<row> train/prediction: 0.9217038384809371/[0.52473897] </row>
		<row> train/prediction: 0.9217801274788826/[0.5242312] </row>
		<row> train/prediction: 0.921856416476885/[0.5243414] </row>
		<row> train/prediction: 0.9219327054748874/[0.5239735] </row>
		<row> train/prediction: 0.9220089944728329/[0.5234122] </row>
		<row> train/prediction: 0.9220852834708353/[0.5228905] </row>
		<row> train/prediction: 0.9221615724688377/[0.52192503] </row>
		<row> train/prediction: 0.9222378614667832/[0.52157164] </row>
		<row> train/prediction: 0.9223141504647856/[0.52088404] </row>
		<row> train/prediction: 0.922390439462788/[0.51967573] </row>
		<row> train/prediction: 0.9224667284607335/[0.51904225] </row>
		<row> train/prediction: 0.9225430174587359/[0.51749015] </row>
		<row> train/prediction: 0.9226193064567383/[0.51625115] </row>
		<row> train/prediction: 0.9226955954546838/[0.5139276] </row>
		<row> train/prediction: 0.9227718844526862/[0.5113639] </row>
		<row> train/prediction: 0.9228481734506317/[0.50937605] </row>
		<row> train/prediction: 0.9229244624486341/[0.5076582] </row>
		<row> train/prediction: 0.9230007514466365/[0.50582814] </row>
		<row> train/prediction: 0.923077040444582/[0.5038911] </row>
		<row> train/prediction: 0.9231533294425844/[0.50191444] </row>
		<row> train/prediction: 0.9232296184405868/[0.5001216] </row>
		<row> train/prediction: 0.9233059074385324/[0.49813366] </row>
		<row> train/prediction: 0.9233821964365347/[0.4957811] </row>
		<row> train/prediction: 0.9234584854345371/[0.49365333] </row>
		<row> train/prediction: 0.9235347744324827/[0.4913497] </row>
		<row> train/prediction: 0.923611063430485/[0.48876688] </row>
		<row> train/prediction: 0.9236873524284874/[0.48614436] </row>
		<row> train/prediction: 0.923763641426433/[0.48362792] </row>
		<row> train/prediction: 0.9238399304244354/[0.48130888] </row>
		<row> train/prediction: 0.9239162194223809/[0.47861812] </row>
		<row> train/prediction: 0.9239925084203833/[0.4763727] </row>
		<row> train/prediction: 0.9240687974183857/[0.47311932] </row>
		<row> train/prediction: 0.9241450864163312/[0.46999976] </row>
		<row> train/prediction: 0.9242213754143336/[0.4668229] </row>
		<row> train/prediction: 0.924297664412336/[0.46371403] </row>
		<row> train/prediction: 0.9243739534102815/[0.46103] </row>
		<row> train/prediction: 0.9244502424082839/[0.4600131] </row>
		<row> train/prediction: 0.9245265314062863/[0.4587844] </row>
		<row> train/prediction: 0.9246028204042318/[0.4577906] </row>
		<row> train/prediction: 0.9246791094022342/[0.4558896] </row>
		<row> train/prediction: 0.9247553984002366/[0.45451498] </row>
		<row> train/prediction: 0.9248316873981821/[0.45376024] </row>
		<row> train/prediction: 0.9249079763961845/[0.4528412] </row>
		<row> train/prediction: 0.9249842653941869/[0.45187694] </row>
		<row> train/prediction: 0.9250605543921324/[0.4505522] </row>
		<row> train/prediction: 0.9251368433901348/[0.44940937] </row>
		<row> train/prediction: 0.9252131323880803/[0.44837672] </row>
		<row> train/prediction: 0.9252894213860827/[0.44661513] </row>
		<row> train/prediction: 0.9253657103840851/[0.44550103] </row>
		<row> train/prediction: 0.9254419993820306/[0.44440705] </row>
		<row> train/prediction: 0.925518288380033/[0.44298846] </row>
		<row> train/prediction: 0.9255945773780354/[0.44276634] </row>
		<row> train/prediction: 0.925670866375981/[0.44131932] </row>
		<row> train/prediction: 0.9257471553739833/[0.43968558] </row>
		<row> train/prediction: 0.9258234443719857/[0.4387714] </row>
		<row> train/prediction: 0.9258997333699313/[0.4382847] </row>
		<row> train/prediction: 0.9259760223679336/[0.4373493] </row>
		<row> train/prediction: 0.926052311365936/[0.43671647] </row>
		<row> train/prediction: 0.9261286003638816/[0.43599066] </row>
		<row> train/prediction: 0.9262048893618839/[0.43523517] </row>
		<row> train/prediction: 0.9262811783598295/[0.43554783] </row>
		<row> train/prediction: 0.9263574673578319/[0.4351123] </row>
		<row> train/prediction: 0.9264337563558342/[0.4347652] </row>
		<row> train/prediction: 0.9265100453537798/[0.43425003] </row>
		<row> train/prediction: 0.9265863343517822/[0.4336022] </row>
		<row> train/prediction: 0.9266626233497846/[0.43297288] </row>
		<row> train/prediction: 0.9267389123477301/[0.43309352] </row>
		<row> train/prediction: 0.9268152013457325/[0.43344438] </row>
		<row> train/prediction: 0.9268914903437349/[0.4336289] </row>
		<row> train/prediction: 0.9269677793416804/[0.43378747] </row>
		<row> train/prediction: 0.9270440683396828/[0.43311593] </row>
		<row> train/prediction: 0.9271203573376852/[0.43308145] </row>
		<row> train/prediction: 0.9271966463356307/[0.4331238] </row>
		<row> train/prediction: 0.9272729353336331/[0.43289244] </row>
		<row> train/prediction: 0.9273492243315786/[0.43257487] </row>
		<row> train/prediction: 0.927425513329581/[0.43224525] </row>
		<row> train/prediction: 0.9275018023275834/[0.43279713] </row>
		<row> train/prediction: 0.9275780913255289/[0.4328847] </row>
		<row> train/prediction: 0.9276543803235313/[0.43188855] </row>
		<row> train/prediction: 0.9277306693215337/[0.43218082] </row>
		<row> train/prediction: 0.9278069583194792/[0.4321081] </row>
		<row> train/prediction: 0.9278832473174816/[0.43302625] </row>
		<row> train/prediction: 0.927959536315484/[0.43346608] </row>
		<row> train/prediction: 0.9280358253134295/[0.43424648] </row>
		<row> train/prediction: 0.9281121143114319/[0.4349478] </row>
		<row> train/prediction: 0.9281884033094343/[0.43646997] </row>
		<row> train/prediction: 0.9282646923073798/[0.43811396] </row>
		<row> train/prediction: 0.9283409813053822/[0.43959484] </row>
		<row> train/prediction: 0.9284172703033278/[0.44091314] </row>
		<row> train/prediction: 0.9284935593013302/[0.4418067] </row>
		<row> train/prediction: 0.9285698482993325/[0.4429853] </row>
		<row> train/prediction: 0.9286461372972781/[0.44348654] </row>
		<row> train/prediction: 0.9287224262952805/[0.44380504] </row>
		<row> train/prediction: 0.9287987152932828/[0.44426587] </row>
		<row> train/prediction: 0.9288750042912284/[0.4454156] </row>
		<row> train/prediction: 0.9289512932892308/[0.44588867] </row>
		<row> train/prediction: 0.9290278365838844/[0.44627833] </row>
		<row> train/prediction: 0.92910412558183/[0.44669855] </row>
		<row> train/prediction: 0.9291804145798324/[0.44673374] </row>
		<row> train/prediction: 0.9292567035778347/[0.44749779] </row>
		<row> train/prediction: 0.9293329925757803/[0.44728705] </row>
		<row> train/prediction: 0.9294092815737827/[0.44827583] </row>
		<row> train/prediction: 0.929485570571785/[0.44904202] </row>
		<row> train/prediction: 0.9295618595697306/[0.45058808] </row>
		<row> train/prediction: 0.929638148567733/[0.45119214] </row>
		<row> train/prediction: 0.9297144375657354/[0.4516774] </row>
		<row> train/prediction: 0.9297907265636809/[0.4522349] </row>
		<row> train/prediction: 0.9298670155616833/[0.4532814] </row>
		<row> train/prediction: 0.9299433045596857/[0.4548255] </row>
		<row> train/prediction: 0.9300195935576312/[0.4558652] </row>
		<row> train/prediction: 0.9300958825556336/[0.45604578] </row>
		<row> train/prediction: 0.9301721715535791/[0.4565332] </row>
		<row> train/prediction: 0.9302484605515815/[0.45779252] </row>
		<row> train/prediction: 0.9303247495495839/[0.45890954] </row>
		<row> train/prediction: 0.9304010385475294/[0.45926023] </row>
		<row> train/prediction: 0.9304773275455318/[0.4601378] </row>
		<row> train/prediction: 0.9305536165435342/[0.461421] </row>
		<row> train/prediction: 0.9306299055414797/[0.46131942] </row>
		<row> train/prediction: 0.9307061945394821/[0.46216065] </row>
		<row> train/prediction: 0.9307824835374845/[0.46244103] </row>
		<row> train/prediction: 0.93085877253543/[0.46285763] </row>
		<row> train/prediction: 0.9309350615334324/[0.46337447] </row>
		<row> train/prediction: 0.9310113505314348/[0.46366614] </row>
		<row> train/prediction: 0.9310876395293803/[0.46379542] </row>
		<row> train/prediction: 0.9311639285273827/[0.46418226] </row>
		<row> train/prediction: 0.9312402175253283/[0.46460977] </row>
		<row> train/prediction: 0.9313165065233306/[0.46543023] </row>
		<row> train/prediction: 0.931392795521333/[0.46547103] </row>
		<row> train/prediction: 0.9314690845192786/[0.46543342] </row>
		<row> train/prediction: 0.931545373517281/[0.46665022] </row>
		<row> train/prediction: 0.9316216625152833/[0.46690884] </row>
		<row> train/prediction: 0.9316979515132289/[0.46702614] </row>
		<row> train/prediction: 0.9317742405112313/[0.46674258] </row>
		<row> train/prediction: 0.9318505295092336/[0.46705517] </row>
		<row> train/prediction: 0.9319268185071792/[0.46771875] </row>
		<row> train/prediction: 0.9320031075051816/[0.46808997] </row>
		<row> train/prediction: 0.9320793965031839/[0.46757895] </row>
		<row> train/prediction: 0.9321556855011295/[0.4666927] </row>
		<row> train/prediction: 0.9322319744991319/[0.4657953] </row>
		<row> train/prediction: 0.9323082634971342/[0.46447775] </row>
		<row> train/prediction: 0.9323845524950798/[0.46351925] </row>
		<row> train/prediction: 0.9324608414930822/[0.46192566] </row>
		<row> train/prediction: 0.9325371304910277/[0.46096474] </row>
		<row> train/prediction: 0.9326134194890301/[0.4601463] </row>
		<row> train/prediction: 0.9326897084870325/[0.45903036] </row>
		<row> train/prediction: 0.932765997484978/[0.45773777] </row>
		<row> train/prediction: 0.9328422864829804/[0.45645759] </row>
		<row> train/prediction: 0.9329185754809828/[0.45491648] </row>
		<row> train/prediction: 0.9329948644789283/[0.45367536] </row>
		<row> train/prediction: 0.9330711534769307/[0.4532237] </row>
		<row> train/prediction: 0.9331474424749331/[0.45194513] </row>
		<row> train/prediction: 0.9332237314728786/[0.45103836] </row>
		<row> train/prediction: 0.933300020470881/[0.4496352] </row>
		<row> train/prediction: 0.9333763094688834/[0.44850007] </row>
		<row> train/prediction: 0.9334525984668289/[0.44788045] </row>
		<row> train/prediction: 0.9335288874648313/[0.4473839] </row>
		<row> train/prediction: 0.9336051764627769/[0.44521195] </row>
		<row> train/prediction: 0.9336814654607792/[0.44328147] </row>
		<row> train/prediction: 0.9337577544587816/[0.44154307] </row>
		<row> train/prediction: 0.9338340434567272/[0.4394882] </row>
		<row> train/prediction: 0.9339103324547295/[0.43769825] </row>
		<row> train/prediction: 0.9339866214527319/[0.4358302] </row>
		<row> train/prediction: 0.9340629104506775/[0.43401867] </row>
		<row> train/prediction: 0.9341391994486798/[0.43223256] </row>
		<row> train/prediction: 0.9342154884466822/[0.4304836] </row>
		<row> train/prediction: 0.9342917774446278/[0.4284998] </row>
		<row> train/prediction: 0.9343680664426302/[0.42638227] </row>
		<row> train/prediction: 0.9344443554406325/[0.42467374] </row>
		<row> train/prediction: 0.9345208987352294/[0.4229355] </row>
		<row> train/prediction: 0.9345971877332317/[0.42099532] </row>
		<row> train/prediction: 0.9346734767312341/[0.41927448] </row>
		<row> train/prediction: 0.9347497657291797/[0.41764233] </row>
		<row> train/prediction: 0.934826054727182/[0.41636223] </row>
		<row> train/prediction: 0.9349023437251844/[0.4150713] </row>
		<row> train/prediction: 0.93497863272313/[0.41361025] </row>
		<row> train/prediction: 0.9350549217211324/[0.41262418] </row>
		<row> train/prediction: 0.9351312107190779/[0.41163602] </row>
		<row> train/prediction: 0.9352074997170803/[0.41015708] </row>
		<row> train/prediction: 0.9352837887150827/[0.40902174] </row>
		<row> train/prediction: 0.9353600777130282/[0.40820703] </row>
		<row> train/prediction: 0.9354363667110306/[0.40749794] </row>
		<row> train/prediction: 0.935512655709033/[0.40686136] </row>
		<row> train/prediction: 0.9355889447069785/[0.40611988] </row>
		<row> train/prediction: 0.9356652337049809/[0.40569434] </row>
		<row> train/prediction: 0.9357415227029833/[0.4055409] </row>
		<row> train/prediction: 0.9358178117009288/[0.40485874] </row>
		<row> train/prediction: 0.9358941006989312/[0.40450135] </row>
		<row> train/prediction: 0.9359703896969336/[0.40383732] </row>
		<row> train/prediction: 0.9360466786948791/[0.40361086] </row>
		<row> train/prediction: 0.9361229676928815/[0.40330425] </row>
		<row> train/prediction: 0.9361992566908839/[0.4035563] </row>
		<row> train/prediction: 0.9362755456888294/[0.40334162] </row>
		<row> train/prediction: 0.9363518346868318/[0.40323058] </row>
		<row> train/prediction: 0.9364281236847773/[0.40354228] </row>
		<row> train/prediction: 0.9365044126827797/[0.40409517] </row>
		<row> train/prediction: 0.9365807016807821/[0.40423945] </row>
		<row> train/prediction: 0.9366569906787277/[0.40451872] </row>
		<row> train/prediction: 0.93673327967673/[0.40503916] </row>
		<row> train/prediction: 0.9368095686747324/[0.40555155] </row>
		<row> train/prediction: 0.936885857672678/[0.40612826] </row>
		<row> train/prediction: 0.9369621466706803/[0.4067365] </row>
		<row> train/prediction: 0.9370384356686827/[0.40792537] </row>
		<row> train/prediction: 0.9371147246666283/[0.4088615] </row>
		<row> train/prediction: 0.9371910136646306/[0.41003993] </row>
		<row> train/prediction: 0.937267302662633/[0.41127783] </row>
		<row> train/prediction: 0.9373435916605786/[0.4119951] </row>
		<row> train/prediction: 0.937419880658581/[0.41282123] </row>
		<row> train/prediction: 0.9374961696565265/[0.41372105] </row>
		<row> train/prediction: 0.9375724586545289/[0.41464272] </row>
		<row> train/prediction: 0.9376487476525313/[0.41553387] </row>
		<row> train/prediction: 0.9377250366504768/[0.41646692] </row>
		<row> train/prediction: 0.9378013256484792/[0.41733742] </row>
		<row> train/prediction: 0.9378776146464816/[0.41869563] </row>
		<row> train/prediction: 0.9379539036444271/[0.4198025] </row>
		<row> train/prediction: 0.9380301926424295/[0.42083737] </row>
		<row> train/prediction: 0.9381064816404319/[0.42190602] </row>
		<row> train/prediction: 0.9381827706383774/[0.42294088] </row>
		<row> train/prediction: 0.9382590596363798/[0.4239165] </row>
		<row> train/prediction: 0.9383353486343822/[0.4251533] </row>
		<row> train/prediction: 0.9384116376323277/[0.42680705] </row>
		<row> train/prediction: 0.9384879266303301/[0.42910856] </row>
		<row> train/prediction: 0.9385642156282756/[0.431186] </row>
		<row> train/prediction: 0.938640504626278/[0.43330204] </row>
		<row> train/prediction: 0.9387167936242804/[0.43530065] </row>
		<row> train/prediction: 0.9387930826222259/[0.43712068] </row>
		<row> train/prediction: 0.9388693716202283/[0.4391394] </row>
		<row> train/prediction: 0.9389456606182307/[0.4407668] </row>
		<row> train/prediction: 0.9390219496161762/[0.44238746] </row>
		<row> train/prediction: 0.9390982386141786/[0.444156] </row>
		<row> train/prediction: 0.939174527612181/[0.44604635] </row>
		<row> train/prediction: 0.9392508166101265/[0.447685] </row>
		<row> train/prediction: 0.9393271056081289/[0.44903642] </row>
		<row> train/prediction: 0.9394033946061313/[0.45020902] </row>
		<row> train/prediction: 0.9394796836040769/[0.45124334] </row>
		<row> train/prediction: 0.9395559726020792/[0.45196655] </row>
		<row> train/prediction: 0.9396322616000248/[0.45279393] </row>
		<row> train/prediction: 0.9397085505980272/[0.45402062] </row>
		<row> train/prediction: 0.9397848395960295/[0.45496503] </row>
		<row> train/prediction: 0.9398611285939751/[0.45592692] </row>
		<row> train/prediction: 0.9399374175919775/[0.45685577] </row>
		<row> train/prediction: 0.9400139608866311/[0.4579854] </row>
		<row> train/prediction: 0.9400902498846335/[0.45861268] </row>
		<row> train/prediction: 0.9401665388825791/[0.45950004] </row>
		<row> train/prediction: 0.9402428278805814/[0.45994273] </row>
		<row> train/prediction: 0.940319116878527/[0.4605359] </row>
		<row> train/prediction: 0.9403954058765294/[0.46122462] </row>
		<row> train/prediction: 0.9404716948745317/[0.46232054] </row>
		<row> train/prediction: 0.9405479838724773/[0.4632886] </row>
		<row> train/prediction: 0.9406242728704797/[0.46424836] </row>
		<row> train/prediction: 0.940700561868482/[0.4653976] </row>
		<row> train/prediction: 0.9407768508664276/[0.46655974] </row>
		<row> train/prediction: 0.94085313986443/[0.46782023] </row>
		<row> train/prediction: 0.9409294288624324/[0.4684929] </row>
		<row> train/prediction: 0.9410057178603779/[0.46973655] </row>
		<row> train/prediction: 0.9410820068583803/[0.4712916] </row>
		<row> train/prediction: 0.9411582958563827/[0.47289425] </row>
		<row> train/prediction: 0.9412345848543282/[0.47412723] </row>
		<row> train/prediction: 0.9413108738523306/[0.475629] </row>
		<row> train/prediction: 0.9413871628502761/[0.4770662] </row>
		<row> train/prediction: 0.9414634518482785/[0.47824326] </row>
		<row> train/prediction: 0.9415397408462809/[0.48004368] </row>
		<row> train/prediction: 0.9416160298442264/[0.48111227] </row>
		<row> train/prediction: 0.9416923188422288/[0.48288807] </row>
		<row> train/prediction: 0.9417686078402312/[0.48441845] </row>
		<row> train/prediction: 0.9418448968381767/[0.4860353] </row>
		<row> train/prediction: 0.9419211858361791/[0.4884168] </row>
		<row> train/prediction: 0.9419974748341815/[0.490355] </row>
		<row> train/prediction: 0.942073763832127/[0.49221337] </row>
		<row> train/prediction: 0.9421500528301294/[0.49402288] </row>
		<row> train/prediction: 0.9422263418281318/[0.49627832] </row>
		<row> train/prediction: 0.9423026308260773/[0.49894053] </row>
		<row> train/prediction: 0.9423789198240797/[0.50183856] </row>
		<row> train/prediction: 0.9424552088220253/[0.50396264] </row>
		<row> train/prediction: 0.9425314978200277/[0.50599927] </row>
		<row> train/prediction: 0.94260778681803/[0.50726336] </row>
		<row> train/prediction: 0.9426840758159756/[0.50821006] </row>
		<row> train/prediction: 0.942760364813978/[0.50970775] </row>
		<row> train/prediction: 0.9428366538119803/[0.5106641] </row>
		<row> train/prediction: 0.9429129428099259/[0.5123801] </row>
		<row> train/prediction: 0.9429892318079283/[0.5134145] </row>
		<row> train/prediction: 0.9430655208059306/[0.514184] </row>
		<row> train/prediction: 0.9431418098038762/[0.5144943] </row>
		<row> train/prediction: 0.9432180988018786/[0.51443475] </row>
		<row> train/prediction: 0.943294387799881/[0.51492727] </row>
		<row> train/prediction: 0.9433706767978265/[0.51565784] </row>
		<row> train/prediction: 0.9434469657958289/[0.51690984] </row>
		<row> train/prediction: 0.9435232547938313/[0.5178152] </row>
		<row> train/prediction: 0.9435995437917768/[0.51907545] </row>
		<row> train/prediction: 0.9436758327897792/[0.51970744] </row>
		<row> train/prediction: 0.9437521217877247/[0.52060676] </row>
		<row> train/prediction: 0.9438284107857271/[0.52086025] </row>
		<row> train/prediction: 0.9439046997837295/[0.52127695] </row>
		<row> train/prediction: 0.943980988781675/[0.5213998] </row>
		<row> train/prediction: 0.9440572777796774/[0.521822] </row>
		<row> train/prediction: 0.9441335667776798/[0.5223871] </row>
		<row> train/prediction: 0.9442098557756253/[0.522819] </row>
		<row> train/prediction: 0.9442861447736277/[0.52384657] </row>
		<row> train/prediction: 0.9443624337716301/[0.524417] </row>
		<row> train/prediction: 0.9444387227695756/[0.52442247] </row>
		<row> train/prediction: 0.944515011767578/[0.52445877] </row>
		<row> train/prediction: 0.9445913007655804/[0.52444804] </row>
		<row> train/prediction: 0.9446675897635259/[0.5241175] </row>
		<row> train/prediction: 0.9447438787615283/[0.52376294] </row>
		<row> train/prediction: 0.9448201677594739/[0.523154] </row>
		<row> train/prediction: 0.9448964567574762/[0.52244824] </row>
		<row> train/prediction: 0.9449727457554786/[0.5220109] </row>
		<row> train/prediction: 0.9450490347534242/[0.5215002] </row>
		<row> train/prediction: 0.9451253237514265/[0.52043724] </row>
		<row> train/prediction: 0.9452016127494289/[0.51849896] </row>
		<row> train/prediction: 0.9452779017473745/[0.5158015] </row>
		<row> train/prediction: 0.9453541907453769/[0.5137092] </row>
		<row> train/prediction: 0.9454304797433792/[0.51205504] </row>
		<row> train/prediction: 0.9455070230379761/[0.510853] </row>
		<row> train/prediction: 0.9455833120359785/[0.5099001] </row>
		<row> train/prediction: 0.9456596010339808/[0.50832105] </row>
		<row> train/prediction: 0.9457358900319264/[0.5068175] </row>
		<row> train/prediction: 0.9458121790299288/[0.5049453] </row>
		<row> train/prediction: 0.9458884680279311/[0.5030708] </row>
		<row> train/prediction: 0.9459647570258767/[0.501469] </row>
		<row> train/prediction: 0.9460410460238791/[0.49975356] </row>
		<row> train/prediction: 0.9461173350218814/[0.4977014] </row>
		<row> train/prediction: 0.946193624019827/[0.49593645] </row>
		<row> train/prediction: 0.9462699130178294/[0.49410862] </row>
		<row> train/prediction: 0.9463462020157749/[0.49222082] </row>
		<row> train/prediction: 0.9464224910137773/[0.4902258] </row>
		<row> train/prediction: 0.9464987800117797/[0.48806816] </row>
		<row> train/prediction: 0.9465750690097252/[0.48634198] </row>
		<row> train/prediction: 0.9466513580077276/[0.4843935] </row>
		<row> train/prediction: 0.94672764700573/[0.4826923] </row>
		<row> train/prediction: 0.9468039360036755/[0.4814397] </row>
		<row> train/prediction: 0.9468802250016779/[0.4803589] </row>
		<row> train/prediction: 0.9469565139996803/[0.47951803] </row>
		<row> train/prediction: 0.9470328029976258/[0.47863764] </row>
		<row> train/prediction: 0.9471090919956282/[0.4775327] </row>
		<row> train/prediction: 0.9471853809936306/[0.4773876] </row>
		<row> train/prediction: 0.9472616699915761/[0.47638395] </row>
		<row> train/prediction: 0.9473379589895785/[0.4757143] </row>
		<row> train/prediction: 0.9474142479875809/[0.47502506] </row>
		<row> train/prediction: 0.9474905369855264/[0.47381654] </row>
		<row> train/prediction: 0.9475668259835288/[0.47224805] </row>
		<row> train/prediction: 0.9476431149814744/[0.47079095] </row>
		<row> train/prediction: 0.9477194039794767/[0.46911374] </row>
		<row> train/prediction: 0.9477956929774791/[0.4674184] </row>
		<row> train/prediction: 0.9478719819754247/[0.46565586] </row>
		<row> train/prediction: 0.947948270973427/[0.46376753] </row>
		<row> train/prediction: 0.9480245599714294/[0.46239638] </row>
		<row> train/prediction: 0.948100848969375/[0.46027127] </row>
		<row> train/prediction: 0.9481771379673773/[0.45834607] </row>
		<row> train/prediction: 0.9482534269653797/[0.45626926] </row>
		<row> train/prediction: 0.9483297159633253/[0.4540753] </row>
		<row> train/prediction: 0.9484060049613277/[0.45143268] </row>
		<row> train/prediction: 0.94848229395933/[0.44952354] </row>
		<row> train/prediction: 0.9485585829572756/[0.44790867] </row>
		<row> train/prediction: 0.948634871955278/[0.44640908] </row>
		<row> train/prediction: 0.9487111609532235/[0.4454378] </row>
		<row> train/prediction: 0.9487874499512259/[0.4438544] </row>
		<row> train/prediction: 0.9488637389492283/[0.44229773] </row>
		<row> train/prediction: 0.9489400279471738/[0.44068748] </row>
		<row> train/prediction: 0.9490163169451762/[0.4395292] </row>
		<row> train/prediction: 0.9490926059431786/[0.43850493] </row>
		<row> train/prediction: 0.9491688949411241/[0.43790218] </row>
		<row> train/prediction: 0.9492451839391265/[0.4370837] </row>
		<row> train/prediction: 0.9493214729371289/[0.43657678] </row>
		<row> train/prediction: 0.9493977619350744/[0.43650493] </row>
		<row> train/prediction: 0.9494740509330768/[0.43669194] </row>
		<row> train/prediction: 0.9495503399310792/[0.43697622] </row>
		<row> train/prediction: 0.9496266289290247/[0.43668917] </row>
		<row> train/prediction: 0.9497029179270271/[0.43616357] </row>
		<row> train/prediction: 0.9497792069249726/[0.43584397] </row>
		<row> train/prediction: 0.949855495922975/[0.4350572] </row>
		<row> train/prediction: 0.9499317849209774/[0.43435153] </row>
		<row> train/prediction: 0.950008073918923/[0.43399394] </row>
		<row> train/prediction: 0.9500843629169253/[0.4331009] </row>
		<row> train/prediction: 0.9501606519149277/[0.43288007] </row>
		<row> train/prediction: 0.9502369409128733/[0.43188223] </row>
		<row> train/prediction: 0.9503132299108756/[0.4311755] </row>
		<row> train/prediction: 0.950389518908878/[0.42961216] </row>
		<row> train/prediction: 0.9504658079068236/[0.42899758] </row>
		<row> train/prediction: 0.9505420969048259/[0.4273902] </row>
		<row> train/prediction: 0.9506183859028283/[0.42627493] </row>
		<row> train/prediction: 0.9506946749007739/[0.4251322] </row>
		<row> train/prediction: 0.9507709638987762/[0.42414996] </row>
		<row> train/prediction: 0.9508472528967218/[0.42306757] </row>
		<row> train/prediction: 0.9509235418947242/[0.42154235] </row>
		<row> train/prediction: 0.9510003394860291/[0.41995263] </row>
		<row> train/prediction: 0.9510766284840315/[0.41783676] </row>
		<row> train/prediction: 0.9511529174819771/[0.41595942] </row>
		<row> train/prediction: 0.9512292064799794/[0.4132454] </row>
		<row> train/prediction: 0.9513054954779818/[0.41072807] </row>
		<row> train/prediction: 0.9513817844759274/[0.40784478] </row>
		<row> train/prediction: 0.9514580734739297/[0.40561137] </row>
		<row> train/prediction: 0.9515343624719321/[0.40305227] </row>
		<row> train/prediction: 0.9516106514698777/[0.40047038] </row>
		<row> train/prediction: 0.95168694046788/[0.3985312] </row>
		<row> train/prediction: 0.9517632294658824/[0.3965171] </row>
		<row> train/prediction: 0.951839518463828/[0.39476115] </row>
		<row> train/prediction: 0.9519158074618304/[0.3925896] </row>
		<row> train/prediction: 0.9519920964597759/[0.39105558] </row>
		<row> train/prediction: 0.9520683854577783/[0.38926777] </row>
		<row> train/prediction: 0.9521446744557807/[0.3884583] </row>
		<row> train/prediction: 0.9522209634537262/[0.38746536] </row>
		<row> train/prediction: 0.9522972524517286/[0.38684717] </row>
		<row> train/prediction: 0.952373541449731/[0.38620713] </row>
		<row> train/prediction: 0.9524498304476765/[0.38565302] </row>
		<row> train/prediction: 0.9525261194456789/[0.3855567] </row>
		<row> train/prediction: 0.9526024084436813/[0.3854893] </row>
		<row> train/prediction: 0.9526786974416268/[0.38572505] </row>
		<row> train/prediction: 0.9527549864396292/[0.38594002] </row>
		<row> train/prediction: 0.9528312754376316/[0.3863906] </row>
		<row> train/prediction: 0.9529075644355771/[0.38711485] </row>
		<row> train/prediction: 0.9529838534335795/[0.38782638] </row>
		<row> train/prediction: 0.953060142431525/[0.38850662] </row>
		<row> train/prediction: 0.9531364314295274/[0.38934416] </row>
		<row> train/prediction: 0.9532127204275298/[0.38970613] </row>
		<row> train/prediction: 0.9532890094254753/[0.39060065] </row>
		<row> train/prediction: 0.9533652984234777/[0.39131853] </row>
		<row> train/prediction: 0.9534415874214801/[0.39220074] </row>
		<row> train/prediction: 0.9535178764194256/[0.39261025] </row>
		<row> train/prediction: 0.953594165417428/[0.3930291] </row>
		<row> train/prediction: 0.9536704544154304/[0.39361382] </row>
		<row> train/prediction: 0.953746743413376/[0.393968] </row>
		<row> train/prediction: 0.9538230324113783/[0.39403537] </row>
		<row> train/prediction: 0.9538993214093807/[0.39417508] </row>
		<row> train/prediction: 0.9539756104073263/[0.39481297] </row>
		<row> train/prediction: 0.9540518994053286/[0.39532933] </row>
		<row> train/prediction: 0.9541281884032742/[0.39556038] </row>
		<row> train/prediction: 0.9542044774012766/[0.39540762] </row>
		<row> train/prediction: 0.954280766399279/[0.39566085] </row>
		<row> train/prediction: 0.9543570553972245/[0.3954795] </row>
		<row> train/prediction: 0.9544333443952269/[0.39567912] </row>
		<row> train/prediction: 0.9545096333932293/[0.39567718] </row>
		<row> train/prediction: 0.9545859223911748/[0.39537188] </row>
		<row> train/prediction: 0.9546622113891772/[0.39525095] </row>
		<row> train/prediction: 0.9547385003871796/[0.39517146] </row>
		<row> train/prediction: 0.9548147893851251/[0.39499596] </row>
		<row> train/prediction: 0.9548910783831275/[0.39487332] </row>
		<row> train/prediction: 0.9549673673811299/[0.3943867] </row>
		<row> train/prediction: 0.9550436563790754/[0.39414233] </row>
		<row> train/prediction: 0.9551199453770778/[0.39409065] </row>
		<row> train/prediction: 0.9551962343750802/[0.39432293] </row>
		<row> train/prediction: 0.9552725233730257/[0.3946366] </row>
		<row> train/prediction: 0.9553488123710281/[0.39486143] </row>
		<row> train/prediction: 0.9554251013689736/[0.3952188] </row>
		<row> train/prediction: 0.955501390366976/[0.3959042] </row>
		<row> train/prediction: 0.9555776793649784/[0.3963498] </row>
		<row> train/prediction: 0.9556539683629239/[0.39719993] </row>
		<row> train/prediction: 0.9557302573609263/[0.39766046] </row>
		<row> train/prediction: 0.9558065463589287/[0.39805192] </row>
		<row> train/prediction: 0.9558828353568742/[0.39819247] </row>
		<row> train/prediction: 0.9559591243548766/[0.39806715] </row>
		<row> train/prediction: 0.956035413352879/[0.39767218] </row>
		<row> train/prediction: 0.9561117023508245/[0.3973836] </row>
		<row> train/prediction: 0.9561879913488269/[0.3969407] </row>
		<row> train/prediction: 0.9562642803468293/[0.39651063] </row>
		<row> train/prediction: 0.9563405693447748/[0.39629725] </row>
		<row> train/prediction: 0.9564168583427772/[0.39616892] </row>
		<row> train/prediction: 0.9564934016374309/[0.39598382] </row>
		<row> train/prediction: 0.9565696906353764/[0.3960956] </row>
		<row> train/prediction: 0.9566459796333788/[0.3965659] </row>
		<row> train/prediction: 0.9567222686313812/[0.3977282] </row>
		<row> train/prediction: 0.9567985576293268/[0.3980677] </row>
		<row> train/prediction: 0.9568748466273291/[0.39846805] </row>
		<row> train/prediction: 0.9569511356252747/[0.3986192] </row>
		<row> train/prediction: 0.9570274246232771/[0.39926857] </row>
		<row> train/prediction: 0.9571037136212794/[0.4004005] </row>
		<row> train/prediction: 0.957180002619225/[0.4018493] </row>
		<row> train/prediction: 0.9572562916172274/[0.4027568] </row>
		<row> train/prediction: 0.9573325806152297/[0.4033682] </row>
		<row> train/prediction: 0.9574088696131753/[0.40392566] </row>
		<row> train/prediction: 0.9574851586111777/[0.4043554] </row>
		<row> train/prediction: 0.95756144760918/[0.4046176] </row>
		<row> train/prediction: 0.9576377366071256/[0.40437847] </row>
		<row> train/prediction: 0.957714025605128/[0.40481713] </row>
		<row> train/prediction: 0.9577903146031304/[0.40478542] </row>
		<row> train/prediction: 0.9578666036010759/[0.40477946] </row>
		<row> train/prediction: 0.9579428925990783/[0.4047173] </row>
		<row> train/prediction: 0.9580191815970807/[0.40439156] </row>
		<row> train/prediction: 0.9580954705950262/[0.40432224] </row>
		<row> train/prediction: 0.9581717595930286/[0.40336454] </row>
		<row> train/prediction: 0.9582480485909741/[0.40301585] </row>
		<row> train/prediction: 0.9583243375889765/[0.40244618] </row>
		<row> train/prediction: 0.9584006265869789/[0.40191382] </row>
		<row> train/prediction: 0.9584769155849244/[0.40208614] </row>
		<row> train/prediction: 0.9585532045829268/[0.40215307] </row>
		<row> train/prediction: 0.9586294935809292/[0.40243536] </row>
		<row> train/prediction: 0.9587057825788747/[0.40263885] </row>
		<row> train/prediction: 0.9587820715768771/[0.4029132] </row>
		<row> train/prediction: 0.9588583605748795/[0.40351215] </row>
		<row> train/prediction: 0.958934649572825/[0.4035915] </row>
		<row> train/prediction: 0.9590109385708274/[0.4039648] </row>
		<row> train/prediction: 0.9590872275688298/[0.40454865] </row>
		<row> train/prediction: 0.9591635165667753/[0.40538535] </row>
		<row> train/prediction: 0.9592398055647777/[0.40578148] </row>
		<row> train/prediction: 0.9593160945627233/[0.40603036] </row>
		<row> train/prediction: 0.9593923835607256/[0.40574852] </row>
		<row> train/prediction: 0.959468672558728/[0.40593752] </row>
		<row> train/prediction: 0.9595449615566736/[0.40541604] </row>
		<row> train/prediction: 0.959621250554676/[0.40433043] </row>
		<row> train/prediction: 0.9596975395526783/[0.40350246] </row>
		<row> train/prediction: 0.9597738285506239/[0.40228304] </row>
		<row> train/prediction: 0.9598501175486263/[0.40125397] </row>
		<row> train/prediction: 0.9599264065466286/[0.40016633] </row>
		<row> train/prediction: 0.9600026955445742/[0.3991319] </row>
		<row> train/prediction: 0.9600789845425766/[0.39790085] </row>
		<row> train/prediction: 0.960155273540579/[0.3979999] </row>
		<row> train/prediction: 0.9602315625385245/[0.39795578] </row>
		<row> train/prediction: 0.9603078515365269/[0.39755136] </row>
		<row> train/prediction: 0.9603841405344724/[0.39650524] </row>
		<row> train/prediction: 0.9604604295324748/[0.39567855] </row>
		<row> train/prediction: 0.9605367185304772/[0.39521825] </row>
		<row> train/prediction: 0.9606130075284227/[0.3948091] </row>
		<row> train/prediction: 0.9606892965264251/[0.3942255] </row>
		<row> train/prediction: 0.9607655855244275/[0.39370045] </row>
		<row> train/prediction: 0.960841874522373/[0.3938213] </row>
		<row> train/prediction: 0.9609181635203754/[0.39360335] </row>
		<row> train/prediction: 0.9609944525183778/[0.39330643] </row>
		<row> train/prediction: 0.9610707415163233/[0.39274427] </row>
		<row> train/prediction: 0.9611470305143257/[0.39259368] </row>
		<row> train/prediction: 0.9612233195123281/[0.39275602] </row>
		<row> train/prediction: 0.9612996085102736/[0.39283863] </row>
		<row> train/prediction: 0.961375897508276/[0.39323723] </row>
		<row> train/prediction: 0.9614521865062216/[0.39370283] </row>
		<row> train/prediction: 0.9615284755042239/[0.39446363] </row>
		<row> train/prediction: 0.9616047645022263/[0.39628762] </row>
		<row> train/prediction: 0.9616810535001719/[0.39767566] </row>
		<row> train/prediction: 0.9617573424981742/[0.39886338] </row>
		<row> train/prediction: 0.9618336314961766/[0.40037963] </row>
		<row> train/prediction: 0.9619099204941222/[0.40168816] </row>
		<row> train/prediction: 0.9619864637887758/[0.40276006] </row>
		<row> train/prediction: 0.9620627527867782/[0.40342957] </row>
		<row> train/prediction: 0.9621390417847238/[0.4044354] </row>
		<row> train/prediction: 0.9622153307827261/[0.4055172] </row>
		<row> train/prediction: 0.9622916197807285/[0.40714088] </row>
		<row> train/prediction: 0.9623679087786741/[0.40884513] </row>
		<row> train/prediction: 0.9624441977766764/[0.41115963] </row>
		<row> train/prediction: 0.9625204867746788/[0.41314295] </row>
		<row> train/prediction: 0.9625967757726244/[0.41506332] </row>
		<row> train/prediction: 0.9626730647706268/[0.4162752] </row>
		<row> train/prediction: 0.9627493537686291/[0.41769075] </row>
		<row> train/prediction: 0.9628256427665747/[0.41880167] </row>
		<row> train/prediction: 0.9629019317645771/[0.41977212] </row>
		<row> train/prediction: 0.9629782207625794/[0.42123163] </row>
		<row> train/prediction: 0.963054509760525/[0.42213684] </row>
		<row> train/prediction: 0.9631307987585274/[0.42236093] </row>
		<row> train/prediction: 0.9632070877564729/[0.42231086] </row>
		<row> train/prediction: 0.9632833767544753/[0.4232055] </row>
		<row> train/prediction: 0.9633596657524777/[0.42328686] </row>
		<row> train/prediction: 0.9634359547504232/[0.42374697] </row>
		<row> train/prediction: 0.9635122437484256/[0.4240463] </row>
		<row> train/prediction: 0.963588532746428/[0.42437926] </row>
		<row> train/prediction: 0.9636648217443735/[0.42458645] </row>
		<row> train/prediction: 0.9637411107423759/[0.42555925] </row>
		<row> train/prediction: 0.9638173997403783/[0.42643532] </row>
		<row> train/prediction: 0.9638936887383238/[0.42779434] </row>
		<row> train/prediction: 0.9639699777363262/[0.4295169] </row>
		<row> train/prediction: 0.9640462667343286/[0.43094683] </row>
		<row> train/prediction: 0.9641225557322741/[0.43221214] </row>
		<row> train/prediction: 0.9641988447302765/[0.43194684] </row>
		<row> train/prediction: 0.964275133728222/[0.43209714] </row>
		<row> train/prediction: 0.9643514227262244/[0.43227845] </row>
		<row> train/prediction: 0.9644277117242268/[0.43346772] </row>
		<row> train/prediction: 0.9645040007221723/[0.4345384] </row>
		<row> train/prediction: 0.9645802897201747/[0.43534473] </row>
		<row> train/prediction: 0.9646565787181771/[0.43665525] </row>
		<row> train/prediction: 0.9647328677161227/[0.43782493] </row>
		<row> train/prediction: 0.964809156714125/[0.4385634] </row>
		<row> train/prediction: 0.9648854457121274/[0.43943253] </row>
		<row> train/prediction: 0.964961734710073/[0.4404199] </row>
		<row> train/prediction: 0.9650380237080753/[0.44068575] </row>
		<row> train/prediction: 0.9651143127060777/[0.44234154] </row>
		<row> train/prediction: 0.9651906017040233/[0.4444957] </row>
		<row> train/prediction: 0.9652668907020256/[0.44632643] </row>
		<row> train/prediction: 0.9653431796999712/[0.44845268] </row>
		<row> train/prediction: 0.9654194686979736/[0.4498747] </row>
		<row> train/prediction: 0.965495757695976/[0.4517365] </row>
		<row> train/prediction: 0.9655720466939215/[0.45367715] </row>
		<row> train/prediction: 0.9656483356919239/[0.4555227] </row>
		<row> train/prediction: 0.9657246246899263/[0.45667565] </row>
		<row> train/prediction: 0.9658009136878718/[0.45725212] </row>
		<row> train/prediction: 0.9658772026858742/[0.45807683] </row>
		<row> train/prediction: 0.9659534916838766/[0.4580518] </row>
		<row> train/prediction: 0.9660297806818221/[0.45902863] </row>
		<row> train/prediction: 0.9661060696798245/[0.4593861] </row>
		<row> train/prediction: 0.9661823586778269/[0.4598441] </row>
		<row> train/prediction: 0.9662586476757724/[0.46112442] </row>
		<row> train/prediction: 0.9663349366737748/[0.46204403] </row>
		<row> train/prediction: 0.9664112256717772/[0.46169794] </row>
		<row> train/prediction: 0.9664875146697227/[0.46044442] </row>
		<row> train/prediction: 0.9665638036677251/[0.45941484] </row>
		<row> train/prediction: 0.9666400926656706/[0.45868522] </row>
		<row> train/prediction: 0.966716381663673/[0.45806727] </row>
		<row> train/prediction: 0.9667926706616754/[0.4576118] </row>
		<row> train/prediction: 0.9668689596596209/[0.45735452] </row>
		<row> train/prediction: 0.9669452486576233/[0.45723963] </row>
		<row> train/prediction: 0.9670215376556257/[0.4578133] </row>
		<row> train/prediction: 0.9670978266535712/[0.4584239] </row>
		<row> train/prediction: 0.9671741156515736/[0.45846227] </row>
		<row> train/prediction: 0.967250404649576/[0.4585525] </row>
		<row> train/prediction: 0.9673266936475216/[0.4594394] </row>
		<row> train/prediction: 0.9674029826455239/[0.46077168] </row>
		<row> train/prediction: 0.9674792716435263/[0.461859] </row>
		<row> train/prediction: 0.9675555606414719/[0.4644168] </row>
		<row> train/prediction: 0.9676318496394742/[0.46573484] </row>
		<row> train/prediction: 0.9677081386374198/[0.46816263] </row>
		<row> train/prediction: 0.9677844276354222/[0.46937588] </row>
		<row> train/prediction: 0.9678607166334245/[0.47075415] </row>
		<row> train/prediction: 0.9679370056313701/[0.4727834] </row>
		<row> train/prediction: 0.9680132946293725/[0.47356823] </row>
		<row> train/prediction: 0.9680895836273749/[0.47332224] </row>
		<row> train/prediction: 0.9681658726253204/[0.47440246] </row>
		<row> train/prediction: 0.9682421616233228/[0.47616753] </row>
		<row> train/prediction: 0.9683184506213252/[0.47794557] </row>
		<row> train/prediction: 0.9683947396192707/[0.47965208] </row>
		<row> train/prediction: 0.9684710286172731/[0.48110765] </row>
		<row> train/prediction: 0.9685473176152755/[0.4823692] </row>
		<row> train/prediction: 0.968623606613221/[0.48271337] </row>
		<row> train/prediction: 0.9686998956112234/[0.48294577] </row>
		<row> train/prediction: 0.9687761846091689/[0.4832155] </row>
		<row> train/prediction: 0.9688524736071713/[0.48325187] </row>
		<row> train/prediction: 0.9689287626051737/[0.48403013] </row>
		<row> train/prediction: 0.9690050516031192/[0.4842421] </row>
		<row> train/prediction: 0.9690813406011216/[0.48442674] </row>
		<row> train/prediction: 0.969157629599124/[0.48384592] </row>
		<row> train/prediction: 0.9692339185970695/[0.4838551] </row>
		<row> train/prediction: 0.9693102075950719/[0.48430258] </row>
		<row> train/prediction: 0.9693864965930743/[0.48445317] </row>
		<row> train/prediction: 0.9694627855910198/[0.48279274] </row>
		<row> train/prediction: 0.9695390745890222/[0.4820146] </row>
		<row> train/prediction: 0.9696153635870246/[0.48164234] </row>
		<row> train/prediction: 0.9696916525849701/[0.48120537] </row>
		<row> train/prediction: 0.9697679415829725/[0.48048666] </row>
		<row> train/prediction: 0.9698442305809181/[0.48037326] </row>
		<row> train/prediction: 0.9699205195789204/[0.4808927] </row>
		<row> train/prediction: 0.9699968085769228/[0.48135883] </row>
		<row> train/prediction: 0.9700730975748684/[0.48170316] </row>
		<row> train/prediction: 0.9701493865728708/[0.48221034] </row>
		<row> train/prediction: 0.9702256755708731/[0.4816277] </row>
		<row> train/prediction: 0.9703019645688187/[0.48165208] </row>
		<row> train/prediction: 0.9703782535668211/[0.48199633] </row>
		<row> train/prediction: 0.9704545425648234/[0.48200864] </row>
		<row> train/prediction: 0.970530831562769/[0.48243582] </row>
		<row> train/prediction: 0.9706071205607714/[0.48344058] </row>
		<row> train/prediction: 0.9706834095587737/[0.48455724] </row>
		<row> train/prediction: 0.9707596985567193/[0.48609897] </row>
		<row> train/prediction: 0.9708359875547217/[0.48708004] </row>
		<row> train/prediction: 0.970912276552724/[0.48777187] </row>
		<row> train/prediction: 0.9709885655506696/[0.48903626] </row>
		<row> train/prediction: 0.971064854548672/[0.48998824] </row>
		<row> train/prediction: 0.9711411435466175/[0.48928398] </row>
		<row> train/prediction: 0.9712174325446199/[0.4901957] </row>
		<row> train/prediction: 0.9712937215426223/[0.49152803] </row>
		<row> train/prediction: 0.9713700105405678/[0.492262] </row>
		<row> train/prediction: 0.9714462995385702/[0.49204347] </row>
		<row> train/prediction: 0.9715988775345181/[0.49230167] </row>
		<row> train/prediction: 0.9716751665325205/[0.49178833] </row>
		<row> train/prediction: 0.9717514555305229/[0.48992506] </row>
		<row> train/prediction: 0.9718277445284684/[0.4883158] </row>
		<row> train/prediction: 0.9719040335264708/[0.48559] </row>
		<row> train/prediction: 0.9719803225244732/[0.48327765] </row>
		<row> train/prediction: 0.9720566115224187/[0.4813176] </row>
		<row> train/prediction: 0.9721329005204211/[0.47794673] </row>
		<row> train/prediction: 0.9722091895183667/[0.47419566] </row>
		<row> train/prediction: 0.972285478516369/[0.47071254] </row>
		<row> train/prediction: 0.9723617675143714/[0.46808624] </row>
		<row> train/prediction: 0.972438056512317/[0.4664264] </row>
		<row> train/prediction: 0.9725143455103193/[0.46366802] </row>
		<row> train/prediction: 0.9725906345083217/[0.4606191] </row>
		<row> train/prediction: 0.9726669235062673/[0.45920682] </row>
		<row> train/prediction: 0.9727432125042696/[0.45769316] </row>
		<row> train/prediction: 0.972819501502272/[0.45616156] </row>
		<row> train/prediction: 0.9728957905002176/[0.45440862] </row>
		<row> train/prediction: 0.9729723337948712/[0.45392758] </row>
		<row> train/prediction: 0.9730486227928736/[0.4537018] </row>
		<row> train/prediction: 0.9731249117908192/[0.45447442] </row>
		<row> train/prediction: 0.9732012007888216/[0.45544124] </row>
		<row> train/prediction: 0.9732774897868239/[0.45634308] </row>
		<row> train/prediction: 0.9733537787847695/[0.45753443] </row>
		<row> train/prediction: 0.9734300677827719/[0.4590945] </row>
		<row> train/prediction: 0.9735063567807742/[0.46072894] </row>
		<row> train/prediction: 0.9735826457787198/[0.46225527] </row>
		<row> train/prediction: 0.9736589347767222/[0.46385163] </row>
		<row> train/prediction: 0.9737352237747245/[0.465762] </row>
		<row> train/prediction: 0.9738115127726701/[0.46711996] </row>
		<row> train/prediction: 0.9738878017706725/[0.46876428] </row>
		<row> train/prediction: 0.973964090768618/[0.4700083] </row>
		<row> train/prediction: 0.9740403797666204/[0.4707568] </row>
		<row> train/prediction: 0.9741166687646228/[0.47184128] </row>
		<row> train/prediction: 0.9741929577625683/[0.4726772] </row>
		<row> train/prediction: 0.9742692467605707/[0.47306696] </row>
		<row> train/prediction: 0.9743455357585731/[0.47388175] </row>
		<row> train/prediction: 0.9744218247565186/[0.47416255] </row>
		<row> train/prediction: 0.974498113754521/[0.4747645] </row>
		<row> train/prediction: 0.9745744027525234/[0.4749845] </row>
		<row> train/prediction: 0.9843594839303478/[0.476099] </row>
		<row> train/prediction: 0.9844357729283502/[0.47615978] </row>
		<row> train/prediction: 0.9845120619262957/[0.4761161] </row>
		<row> train/prediction: 0.9845883509242981/[0.47660497] </row>
		<row> train/prediction: 0.9846646399223005/[0.47725904] </row>
		<row> train/prediction: 0.984740928920246/[0.477472] </row>
		<row> train/prediction: 0.9848172179182484/[0.4780707] </row>
		<row> train/prediction: 0.9848935069162508/[0.478401] </row>
		<row> train/prediction: 0.9849697959141963/[0.47887897] </row>
		<row> train/prediction: 0.9850460849121987/[0.4794717] </row>
		<row> train/prediction: 0.9851223739102011/[0.4802112] </row>
		<row> train/prediction: 0.9851986629081466/[0.48073074] </row>
		<row> train/prediction: 0.985274951906149/[0.48081708] </row>
		<row> train/prediction: 0.9853512409040945/[0.4811461] </row>
		<row> train/prediction: 0.9854275299020969/[0.481299] </row>
		<row> train/prediction: 0.9855038189000993/[0.48218983] </row>
		<row> train/prediction: 0.9855801078980448/[0.48292363] </row>
		<row> train/prediction: 0.9856563968960472/[0.48386618] </row>
		<row> train/prediction: 0.9857326858940496/[0.48502952] </row>
		<row> train/prediction: 0.9858089748919951/[0.48645973] </row>
		<row> train/prediction: 0.9858852638899975/[0.488744] </row>
		<row> train/prediction: 0.9859615528879999/[0.4914729] </row>
		<row> train/prediction: 0.9860378418859455/[0.49439907] </row>
		<row> train/prediction: 0.9861141308839478/[0.4972463] </row>
		<row> train/prediction: 0.9861904198819502/[0.5009896] </row>
		<row> train/prediction: 0.9862667088798958/[0.5049753] </row>
		<row> train/prediction: 0.9863429978778981/[0.50875455] </row>
		<row> train/prediction: 0.9864192868758437/[0.51303124] </row>
		<row> train/prediction: 0.9864955758738461/[0.516992] </row>
		<row> train/prediction: 0.9865718648718484/[0.5215765] </row>
		<row> train/prediction: 0.986648153869794/[0.5258016] </row>
		<row> train/prediction: 0.9867244428677964/[0.52989453] </row>
		<row> train/prediction: 0.9868007318657988/[0.53309524] </row>
		<row> train/prediction: 0.9868770208637443/[0.53697234] </row>
		<row> train/prediction: 0.9869533098617467/[0.5403961] </row>
		<row> train/prediction: 0.9870295988597491/[0.5430667] </row>
		<row> train/prediction: 0.9871058878576946/[0.54574454] </row>
		<row> train/prediction: 0.987182176855697/[0.548181] </row>
		<row> train/prediction: 0.9872584658536994/[0.5502128] </row>
		<row> train/prediction: 0.9873347548516449/[0.5518457] </row>
		<row> train/prediction: 0.9874110438496473/[0.55376697] </row>
		<row> train/prediction: 0.9874873328475928/[0.5554214] </row>
		<row> train/prediction: 0.9875636218455952/[0.5574656] </row>
		<row> train/prediction: 0.9876399108435976/[0.5599051] </row>
		<row> train/prediction: 0.9877161998415431/[0.5616178] </row>
		<row> train/prediction: 0.9877932517295562/[0.56401867] </row>
		<row> train/prediction: 0.9878695407275018/[0.5661826] </row>
		<row> train/prediction: 0.9879458297255042/[0.5681651] </row>
		<row> train/prediction: 0.9880221187234497/[0.57010704] </row>
		<row> train/prediction: 0.9880984077214521/[0.57233286] </row>
		<row> train/prediction: 0.9881746967194545/[0.5748912] </row>
		<row> train/prediction: 0.9882509857174/[0.5777186] </row>
		<row> train/prediction: 0.9883272747154024/[0.57983196] </row>
		<row> train/prediction: 0.9884035637134048/[0.5811416] </row>
		<row> train/prediction: 0.9884798527113503/[0.58288] </row>
		<row> train/prediction: 0.9885561417093527/[0.5850732] </row>
		<row> train/prediction: 0.9886324307073551/[0.58712214] </row>
		<row> train/prediction: 0.9887087197053006/[0.5890493] </row>
		<row> train/prediction: 0.988785008703303/[0.59127945] </row>
		<row> train/prediction: 0.9888612977013054/[0.5936333] </row>
		<row> train/prediction: 0.9889375866992509/[0.5957686] </row>
		<row> train/prediction: 0.9890138756972533/[0.59823924] </row>
		<row> train/prediction: 0.9890901646951988/[0.6013517] </row>
		<row> train/prediction: 0.9891664536932012/[0.6046083] </row>
		<row> train/prediction: 0.9892427426912036/[0.6087234] </row>
		<row> train/prediction: 0.9893190316891491/[0.613511] </row>
		<row> train/prediction: 0.9893953206871515/[0.6172285] </row>
		<row> train/prediction: 0.9894716096851539/[0.6208747] </row>
		<row> train/prediction: 0.9895478986830994/[0.62493473] </row>
		<row> train/prediction: 0.9896241876811018/[0.6295601] </row>
		<row> train/prediction: 0.9897004766791042/[0.6331902] </row>
		<row> train/prediction: 0.9897767656770498/[0.6362503] </row>
		<row> train/prediction: 0.9898530546750521/[0.6396085] </row>
		<row> train/prediction: 0.9899293436730545/[0.6423262] </row>
		<row> train/prediction: 0.9900056326710001/[0.64482737] </row>
		<row> train/prediction: 0.9900819216690024/[0.6468697] </row>
		<row> train/prediction: 0.990158210666948/[0.6485386] </row>
		<row> train/prediction: 0.9902344996649504/[0.6501328] </row>
		<row> train/prediction: 0.9903107886629527/[0.6514649] </row>
		<row> train/prediction: 0.9903870776608983/[0.65271294] </row>
		<row> train/prediction: 0.9904633666589007/[0.6542096] </row>
		<row> train/prediction: 0.990539655656903/[0.65447825] </row>
		<row> train/prediction: 0.9906159446548486/[0.65465796] </row>
		<row> train/prediction: 0.990692233652851/[0.65596867] </row>
		<row> train/prediction: 0.9907685226508534/[0.65765506] </row>
	</data>
</root>
