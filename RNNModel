<?xml version="1.0" ?>
<root>
	<model>
		Model details:
		<layers>
			<layer>1 name:input_1 shape:[(None, 1, 120)] </layer>
			<layer>2 name:lstm units:256  return_sequences:False </layer>
			<layer>3 name:dense units:32 </layer>
			<layer>4 name:dropout units:0.05 </layer>
			<layer>5 name:dense_1 units:10 </layer>
			<layer>6 name:dense_2 units:1 </layer>
		</layers>
		<history>
			<loss> epoch:0 value:[0.01756279170513153, 0.05602357164025307, 0.04277167096734047, 0.055772796273231506, 0.056394822895526886, 0.0715702697634697, 0.06715452671051025, 0.06378428637981415] </loss>
			<loss> epoch:1 value:[0.01756279170513153, 0.05602357164025307, 0.04277167096734047, 0.055772796273231506, 0.056394822895526886, 0.0715702697634697, 0.06715452671051025, 0.06378428637981415] </loss>
			<loss> epoch:2 value:[0.01756279170513153, 0.05602357164025307, 0.04277167096734047, 0.055772796273231506, 0.056394822895526886, 0.0715702697634697, 0.06715452671051025, 0.06378428637981415] </loss>
			<loss> epoch:3 value:[0.01756279170513153, 0.05602357164025307, 0.04277167096734047, 0.055772796273231506, 0.056394822895526886, 0.0715702697634697, 0.06715452671051025, 0.06378428637981415] </loss>
			<loss> epoch:4 value:[0.01756279170513153, 0.05602357164025307, 0.04277167096734047, 0.055772796273231506, 0.056394822895526886, 0.0715702697634697, 0.06715452671051025, 0.06378428637981415] </loss>
			<loss> epoch:5 value:[0.01756279170513153, 0.05602357164025307, 0.04277167096734047, 0.055772796273231506, 0.056394822895526886, 0.0715702697634697, 0.06715452671051025, 0.06378428637981415] </loss>
			<loss> epoch:6 value:[0.01756279170513153, 0.05602357164025307, 0.04277167096734047, 0.055772796273231506, 0.056394822895526886, 0.0715702697634697, 0.06715452671051025, 0.06378428637981415] </loss>
			<loss> epoch:7 value:[0.01756279170513153, 0.05602357164025307, 0.04277167096734047, 0.055772796273231506, 0.056394822895526886, 0.0715702697634697, 0.06715452671051025, 0.06378428637981415] </loss>
		</history>
	</model>
	<data>
		<row> train/prediction: 0.7791817496373028/[0.47148743] </row>
		<row> train/prediction: 0.7792580386353052/[0.47148743] </row>
		<row> train/prediction: 0.7793343276332507/[0.47148743] </row>
		<row> train/prediction: 0.7794106166312531/[0.47148743] </row>
		<row> train/prediction: 0.7794869056292555/[0.47148743] </row>
		<row> train/prediction: 0.779563194627201/[0.47148743] </row>
		<row> train/prediction: 0.7796394836252034/[0.47148743] </row>
		<row> train/prediction: 0.7797157726232058/[0.47148743] </row>
		<row> train/prediction: 0.7797920616211513/[0.47148743] </row>
		<row> train/prediction: 0.7798683506191537/[0.47148743] </row>
		<row> train/prediction: 0.7799446396170993/[0.47148743] </row>
		<row> train/prediction: 0.7800209286151016/[0.47148743] </row>
		<row> train/prediction: 0.780097217613104/[0.47148743] </row>
		<row> train/prediction: 0.7801735066110496/[0.47148743] </row>
		<row> train/prediction: 0.7802497956090519/[0.47148743] </row>
		<row> train/prediction: 0.7803260846070543/[0.47148743] </row>
		<row> train/prediction: 0.7804023736049999/[0.47148743] </row>
		<row> train/prediction: 0.7804786626030022/[0.47148743] </row>
		<row> train/prediction: 0.7844456904980461/[0.47148743] </row>
		<row> train/prediction: 0.7845219794960485/[0.47148743] </row>
		<row> train/prediction: 0.7845982684940509/[0.47148743] </row>
		<row> train/prediction: 0.7846745574919964/[0.47148743] </row>
		<row> train/prediction: 0.7847508464899988/[0.47148743] </row>
		<row> train/prediction: 0.7848271354880012/[0.47148743] </row>
		<row> train/prediction: 0.784903678782598/[0.47148743] </row>
		<row> train/prediction: 0.7849799677806004/[0.47148743] </row>
		<row> train/prediction: 0.7850562567786028/[0.47148743] </row>
		<row> train/prediction: 0.7851325457765483/[0.47148743] </row>
		<row> train/prediction: 0.7852088347745507/[0.47148743] </row>
		<row> train/prediction: 0.7852851237725531/[0.47148743] </row>
		<row> train/prediction: 0.7853614127704986/[0.47148743] </row>
		<row> train/prediction: 0.785437701768501/[0.47148743] </row>
		<row> train/prediction: 0.7855139907665034/[0.47148743] </row>
		<row> train/prediction: 0.785590279764449/[0.47148743] </row>
		<row> train/prediction: 0.7856665687624513/[0.47148743] </row>
		<row> train/prediction: 0.7857428577604537/[0.47148743] </row>
		<row> train/prediction: 0.7858191467583993/[0.47148743] </row>
		<row> train/prediction: 0.7858954357564016/[0.47148743] </row>
		<row> train/prediction: 0.7859717247543472/[0.47148743] </row>
		<row> train/prediction: 0.7860480137523496/[0.47148743] </row>
		<row> train/prediction: 0.7861243027503519/[0.47148743] </row>
		<row> train/prediction: 0.7862005917482975/[0.47148743] </row>
		<row> train/prediction: 0.7862768807462999/[0.47148743] </row>
		<row> train/prediction: 0.7863531697443022/[0.47148743] </row>
		<row> train/prediction: 0.7864294587422478/[0.47148743] </row>
		<row> train/prediction: 0.7865057477402502/[0.47148743] </row>
		<row> train/prediction: 0.7865820367382526/[0.47148743] </row>
		<row> train/prediction: 0.7866583257361981/[0.47148743] </row>
		<row> train/prediction: 0.7867346147342005/[0.47148743] </row>
		<row> train/prediction: 0.7868109037322029/[0.47148743] </row>
		<row> train/prediction: 0.7868871927301484/[0.47148743] </row>
		<row> train/prediction: 0.7869634817281508/[0.47148743] </row>
		<row> train/prediction: 0.7870397707260963/[0.47148743] </row>
		<row> train/prediction: 0.7871160597240987/[0.47148743] </row>
		<row> train/prediction: 0.7871923487221011/[0.47148743] </row>
		<row> train/prediction: 0.7872686377200466/[0.47148743] </row>
		<row> train/prediction: 0.787344926718049/[0.47148743] </row>
		<row> train/prediction: 0.7874212157160514/[0.47148743] </row>
		<row> train/prediction: 0.7874975047139969/[0.47148743] </row>
		<row> train/prediction: 0.7875737937119993/[0.47148743] </row>
		<row> train/prediction: 0.7876500827100017/[0.47148743] </row>
		<row> train/prediction: 0.7877263717079472/[0.47148743] </row>
		<row> train/prediction: 0.7878026607059496/[0.47148743] </row>
		<row> train/prediction: 0.787878949703952/[0.47148743] </row>
		<row> train/prediction: 0.7879552387018975/[0.47148743] </row>
		<row> train/prediction: 0.7880315276998999/[0.47148743] </row>
		<row> train/prediction: 0.7881078166979023/[0.47148743] </row>
		<row> train/prediction: 0.7881841056958478/[0.47148743] </row>
		<row> train/prediction: 0.7882603946938502/[0.47148743] </row>
		<row> train/prediction: 0.7883366836917958/[0.47148743] </row>
		<row> train/prediction: 0.7884129726897982/[0.47148743] </row>
		<row> train/prediction: 0.7884892616878005/[0.47148743] </row>
		<row> train/prediction: 0.7885655506857461/[0.47148743] </row>
		<row> train/prediction: 0.7886418396837485/[0.47148743] </row>
		<row> train/prediction: 0.7887181286817508/[0.47148743] </row>
		<row> train/prediction: 0.7887944176796964/[0.47148743] </row>
		<row> train/prediction: 0.7888707066776988/[0.47148743] </row>
		<row> train/prediction: 0.7889469956757011/[0.47148743] </row>
		<row> train/prediction: 0.7890232846736467/[0.47148743] </row>
		<row> train/prediction: 0.7890995736716491/[0.47148743] </row>
		<row> train/prediction: 0.7891758626696515/[0.47148743] </row>
		<row> train/prediction: 0.789252151667597/[0.47148743] </row>
		<row> train/prediction: 0.7893284406655994/[0.47148743] </row>
		<row> train/prediction: 0.7894047296635449/[0.47148743] </row>
		<row> train/prediction: 0.7894810186615473/[0.47148743] </row>
		<row> train/prediction: 0.7895573076595497/[0.47148743] </row>
		<row> train/prediction: 0.7896335966574952/[0.47148743] </row>
		<row> train/prediction: 0.7897098856554976/[0.47148743] </row>
		<row> train/prediction: 0.7897861746535/[0.47148743] </row>
		<row> train/prediction: 0.7898624636514455/[0.47148743] </row>
		<row> train/prediction: 0.7899387526494479/[0.47148743] </row>
		<row> train/prediction: 0.7900150416474503/[0.47148743] </row>
		<row> train/prediction: 0.7900913306453958/[0.47148743] </row>
		<row> train/prediction: 0.7901676196433982/[0.47148743] </row>
		<row> train/prediction: 0.7902439086414006/[0.47148743] </row>
		<row> train/prediction: 0.7903201976393461/[0.47148743] </row>
		<row> train/prediction: 0.7903967409339998/[0.47148743] </row>
		<row> train/prediction: 0.7904730299320022/[0.47148743] </row>
		<row> train/prediction: 0.7905493189299477/[0.47148743] </row>
		<row> train/prediction: 0.7906256079279501/[0.47148743] </row>
		<row> train/prediction: 0.7907018969259525/[0.47148743] </row>
		<row> train/prediction: 0.790778185923898/[0.47148743] </row>
		<row> train/prediction: 0.7908544749219004/[0.47148743] </row>
		<row> train/prediction: 0.790930763919846/[0.47148743] </row>
		<row> train/prediction: 0.7910070529178483/[0.47148743] </row>
		<row> train/prediction: 0.7910833419158507/[0.47148743] </row>
		<row> train/prediction: 0.7911596309137963/[0.47148743] </row>
		<row> train/prediction: 0.7912359199117986/[0.47148743] </row>
		<row> train/prediction: 0.791312208909801/[0.47148743] </row>
		<row> train/prediction: 0.7913884979077466/[0.47148743] </row>
		<row> train/prediction: 0.791464786905749/[0.47148743] </row>
		<row> train/prediction: 0.7915410759037513/[0.47148743] </row>
		<row> train/prediction: 0.7916173649016969/[0.47148743] </row>
		<row> train/prediction: 0.7916936538996993/[0.47148743] </row>
		<row> train/prediction: 0.7917699428977016/[0.47148743] </row>
		<row> train/prediction: 0.7918462318956472/[0.47148743] </row>
		<row> train/prediction: 0.7919225208936496/[0.47148743] </row>
		<row> train/prediction: 0.791998809891652/[0.47148743] </row>
		<row> train/prediction: 0.7920750988895975/[0.47148743] </row>
		<row> train/prediction: 0.7921513878875999/[0.47148743] </row>
		<row> train/prediction: 0.7922276768855454/[0.47148743] </row>
		<row> train/prediction: 0.7923039658835478/[0.47148743] </row>
		<row> train/prediction: 0.7923802548815502/[0.47148743] </row>
		<row> train/prediction: 0.7924565438794957/[0.47148743] </row>
		<row> train/prediction: 0.7925328328774981/[0.47148743] </row>
		<row> train/prediction: 0.7926091218755005/[0.47148743] </row>
		<row> train/prediction: 0.792685410873446/[0.47148743] </row>
		<row> train/prediction: 0.7927616998714484/[0.47148743] </row>
		<row> train/prediction: 0.7928379888694508/[0.47148743] </row>
		<row> train/prediction: 0.7929142778673963/[0.47148743] </row>
		<row> train/prediction: 0.7929905668653987/[0.47148743] </row>
		<row> train/prediction: 0.7930668558634011/[0.47148743] </row>
		<row> train/prediction: 0.7931431448613466/[0.47148743] </row>
		<row> train/prediction: 0.793219433859349/[0.47148743] </row>
		<row> train/prediction: 0.7932957228572945/[0.47148743] </row>
		<row> train/prediction: 0.7933720118552969/[0.47148743] </row>
		<row> train/prediction: 0.7934483008532993/[0.47148743] </row>
		<row> train/prediction: 0.7935245898512449/[0.47148743] </row>
		<row> train/prediction: 0.7936008788492472/[0.47148743] </row>
		<row> train/prediction: 0.7936771678472496/[0.47148743] </row>
		<row> train/prediction: 0.7937534568451952/[0.47148743] </row>
		<row> train/prediction: 0.7938297458431975/[0.47148743] </row>
		<row> train/prediction: 0.7939060348411999/[0.47148743] </row>
		<row> train/prediction: 0.7939823238391455/[0.47148743] </row>
		<row> train/prediction: 0.7940586128371478/[0.47148743] </row>
		<row> train/prediction: 0.7941349018351502/[0.47148743] </row>
		<row> train/prediction: 0.7942111908330958/[0.47148743] </row>
		<row> train/prediction: 0.7942874798310982/[0.47148743] </row>
		<row> train/prediction: 0.7943637688290437/[0.47148743] </row>
		<row> train/prediction: 0.7944400578270461/[0.47148743] </row>
		<row> train/prediction: 0.7945163468250485/[0.47148743] </row>
		<row> train/prediction: 0.794592635822994/[0.47148743] </row>
		<row> train/prediction: 0.7946689248209964/[0.47148743] </row>
		<row> train/prediction: 0.7947452138189988/[0.47148743] </row>
		<row> train/prediction: 0.7948215028169443/[0.47148743] </row>
		<row> train/prediction: 0.7948977918149467/[0.47148743] </row>
		<row> train/prediction: 0.7949740808129491/[0.47148743] </row>
		<row> train/prediction: 0.7950503698108946/[0.47148743] </row>
		<row> train/prediction: 0.795126658808897/[0.47148743] </row>
		<row> train/prediction: 0.7952029478068994/[0.47148743] </row>
		<row> train/prediction: 0.7955843927967976/[0.47148743] </row>
		<row> train/prediction: 0.7956606817947431/[0.47148743] </row>
		<row> train/prediction: 0.7957369707927455/[0.47148743] </row>
		<row> train/prediction: 0.7958132597907479/[0.47148743] </row>
		<row> train/prediction: 0.7958900573820529/[0.47148743] </row>
		<row> train/prediction: 0.7959663463799984/[0.47148743] </row>
		<row> train/prediction: 0.7960426353780008/[0.47148743] </row>
		<row> train/prediction: 0.7961189243760032/[0.47148743] </row>
		<row> train/prediction: 0.7961952133739487/[0.47148743] </row>
		<row> train/prediction: 0.7962715023719511/[0.47148743] </row>
		<row> train/prediction: 0.7963477913699535/[0.47148743] </row>
		<row> train/prediction: 0.796424080367899/[0.47148743] </row>
		<row> train/prediction: 0.7965003693659014/[0.47148743] </row>
		<row> train/prediction: 0.796576658363847/[0.47148743] </row>
		<row> train/prediction: 0.7966529473618493/[0.47148743] </row>
		<row> train/prediction: 0.7967292363598517/[0.47148743] </row>
		<row> train/prediction: 0.7968055253577973/[0.47148743] </row>
		<row> train/prediction: 0.7968818143557996/[0.47148743] </row>
		<row> train/prediction: 0.796958103353802/[0.47148743] </row>
		<row> train/prediction: 0.7970343923517476/[0.47148743] </row>
		<row> train/prediction: 0.7971106813497499/[0.47148743] </row>
		<row> train/prediction: 0.7971869703477523/[0.47148743] </row>
		<row> train/prediction: 0.7972632593456979/[0.47148743] </row>
		<row> train/prediction: 0.7973395483437002/[0.47148743] </row>
		<row> train/prediction: 0.7974158373417026/[0.47148743] </row>
		<row> train/prediction: 0.7974921263396482/[0.47148743] </row>
		<row> train/prediction: 0.7975684153376505/[0.47148743] </row>
		<row> train/prediction: 0.7976447043355961/[0.47148743] </row>
		<row> train/prediction: 0.7977209933335985/[0.47148743] </row>
		<row> train/prediction: 0.7977972823316009/[0.47148743] </row>
		<row> train/prediction: 0.7978735713295464/[0.47148743] </row>
		<row> train/prediction: 0.7979498603275488/[0.47148743] </row>
		<row> train/prediction: 0.7980261493255512/[0.47148743] </row>
		<row> train/prediction: 0.7981024383234967/[0.47148743] </row>
		<row> train/prediction: 0.7981787273214991/[0.47148743] </row>
		<row> train/prediction: 0.7982550163195015/[0.47148743] </row>
		<row> train/prediction: 0.798331305317447/[0.47148743] </row>
		<row> train/prediction: 0.7984075943154494/[0.47148743] </row>
		<row> train/prediction: 0.7984838833134518/[0.47148743] </row>
		<row> train/prediction: 0.7985601723113973/[0.47148743] </row>
		<row> train/prediction: 0.7986364613093997/[0.47148743] </row>
		<row> train/prediction: 0.7987127503074021/[0.47148743] </row>
		<row> train/prediction: 0.7987890393053476/[0.47148743] </row>
		<row> train/prediction: 0.79886532830335/[0.47148743] </row>
		<row> train/prediction: 0.7989416173012955/[0.47148743] </row>
		<row> train/prediction: 0.7990179062992979/[0.47148743] </row>
		<row> train/prediction: 0.7990941952973003/[0.47148743] </row>
		<row> train/prediction: 0.7991704842952458/[0.47148743] </row>
		<row> train/prediction: 0.7992467732932482/[0.47148743] </row>
		<row> train/prediction: 0.7993230622912506/[0.47148743] </row>
		<row> train/prediction: 0.7993993512891961/[0.47148743] </row>
		<row> train/prediction: 0.7994756402871985/[0.47148743] </row>
		<row> train/prediction: 0.7995519292852009/[0.47148743] </row>
		<row> train/prediction: 0.7996282182831465/[0.47148743] </row>
		<row> train/prediction: 0.7997045072811488/[0.47148743] </row>
		<row> train/prediction: 0.7997807962791512/[0.47148743] </row>
		<row> train/prediction: 0.7998570852770968/[0.47148743] </row>
		<row> train/prediction: 0.7999333742750991/[0.47148743] </row>
		<row> train/prediction: 0.8000096632730447/[0.47148743] </row>
		<row> train/prediction: 0.8000859522710471/[0.47148743] </row>
		<row> train/prediction: 0.8001622412690494/[0.47148743] </row>
		<row> train/prediction: 0.800238530266995/[0.47148743] </row>
		<row> train/prediction: 0.8003148192649974/[0.47148743] </row>
		<row> train/prediction: 0.8003911082629998/[0.47148743] </row>
		<row> train/prediction: 0.8004673972609453/[0.47148743] </row>
		<row> train/prediction: 0.8005436862589477/[0.47148743] </row>
		<row> train/prediction: 0.8006199752569501/[0.47148743] </row>
		<row> train/prediction: 0.8006962642548956/[0.47148743] </row>
		<row> train/prediction: 0.800772553252898/[0.47148743] </row>
		<row> train/prediction: 0.8008488422509004/[0.47148743] </row>
		<row> train/prediction: 0.8009251312488459/[0.47148743] </row>
		<row> train/prediction: 0.8010014202468483/[0.47148743] </row>
		<row> train/prediction: 0.8010777092447938/[0.47148743] </row>
		<row> train/prediction: 0.8011539982427962/[0.47148743] </row>
		<row> train/prediction: 0.8012302872407986/[0.47148743] </row>
		<row> train/prediction: 0.8013065762387441/[0.47148743] </row>
		<row> train/prediction: 0.8013831195333978/[0.47148743] </row>
		<row> train/prediction: 0.8014594085314002/[0.47148743] </row>
		<row> train/prediction: 0.8015356975293457/[0.47148743] </row>
		<row> train/prediction: 0.8016119865273481/[0.47148743] </row>
		<row> train/prediction: 0.8016882755253505/[0.47148743] </row>
		<row> train/prediction: 0.801764564523296/[0.47148743] </row>
		<row> train/prediction: 0.8018408535212984/[0.47148743] </row>
		<row> train/prediction: 0.8019171425193008/[0.47148743] </row>
		<row> train/prediction: 0.8019934315172463/[0.47148743] </row>
		<row> train/prediction: 0.8020697205152487/[0.47148743] </row>
		<row> train/prediction: 0.8021460095132511/[0.47148743] </row>
		<row> train/prediction: 0.8022222985111966/[0.47148743] </row>
		<row> train/prediction: 0.802298587509199/[0.47148743] </row>
		<row> train/prediction: 0.8023748765072014/[0.47148743] </row>
		<row> train/prediction: 0.802451165505147/[0.47148743] </row>
		<row> train/prediction: 0.8025274545031493/[0.47148743] </row>
		<row> train/prediction: 0.8026037435011517/[0.47148743] </row>
		<row> train/prediction: 0.8026800324990973/[0.47148743] </row>
		<row> train/prediction: 0.8027563214970996/[0.47148743] </row>
		<row> train/prediction: 0.8028326104950452/[0.47148743] </row>
		<row> train/prediction: 0.8029088994930476/[0.47148743] </row>
		<row> train/prediction: 0.8029851884910499/[0.47148743] </row>
		<row> train/prediction: 0.8030614774889955/[0.47148743] </row>
		<row> train/prediction: 0.8031377664869979/[0.47148743] </row>
		<row> train/prediction: 0.8032140554850002/[0.47148743] </row>
		<row> train/prediction: 0.8032903444829458/[0.47148743] </row>
		<row> train/prediction: 0.8033666334809482/[0.47148743] </row>
		<row> train/prediction: 0.8034429224789505/[0.47148743] </row>
		<row> train/prediction: 0.8035192114768961/[0.47148743] </row>
		<row> train/prediction: 0.8035955004748985/[0.47148743] </row>
		<row> train/prediction: 0.8036717894729009/[0.47148743] </row>
		<row> train/prediction: 0.8037480784708464/[0.47148743] </row>
		<row> train/prediction: 0.8038243674688488/[0.47148743] </row>
		<row> train/prediction: 0.8039006564667943/[0.47148743] </row>
		<row> train/prediction: 0.8039769454647967/[0.47148743] </row>
		<row> train/prediction: 0.8040532344627991/[0.47148743] </row>
		<row> train/prediction: 0.8041295234607446/[0.47148743] </row>
		<row> train/prediction: 0.804205812458747/[0.47148743] </row>
		<row> train/prediction: 0.8042821014567494/[0.47148743] </row>
		<row> train/prediction: 0.8043583904546949/[0.47148743] </row>
		<row> train/prediction: 0.8044346794526973/[0.47148743] </row>
		<row> train/prediction: 0.8045109684506997/[0.47148743] </row>
		<row> train/prediction: 0.8045872574486452/[0.47148743] </row>
		<row> train/prediction: 0.8046635464466476/[0.47148743] </row>
		<row> train/prediction: 0.80473983544465/[0.47148743] </row>
		<row> train/prediction: 0.8048161244425955/[0.47148743] </row>
		<row> train/prediction: 0.8048924134405979/[0.47148743] </row>
		<row> train/prediction: 0.8049687024385435/[0.47148743] </row>
		<row> train/prediction: 0.8050449914365458/[0.47148743] </row>
		<row> train/prediction: 0.8051212804345482/[0.47148743] </row>
		<row> train/prediction: 0.8051975694324938/[0.47148743] </row>
		<row> train/prediction: 0.8052738584304961/[0.47148743] </row>
		<row> train/prediction: 0.8053501474284985/[0.47148743] </row>
		<row> train/prediction: 0.8054264364264441/[0.47148743] </row>
		<row> train/prediction: 0.8055027254244465/[0.47148743] </row>
		<row> train/prediction: 0.8055790144224488/[0.47148743] </row>
		<row> train/prediction: 0.8056553034203944/[0.47148743] </row>
		<row> train/prediction: 0.8057315924183968/[0.47148743] </row>
		<row> train/prediction: 0.8058078814163991/[0.47148743] </row>
		<row> train/prediction: 0.8058841704143447/[0.47148743] </row>
		<row> train/prediction: 0.8059604594123471/[0.47148743] </row>
		<row> train/prediction: 0.8060367484102926/[0.47148743] </row>
		<row> train/prediction: 0.806113037408295/[0.47148743] </row>
		<row> train/prediction: 0.8061893264062974/[0.47148743] </row>
		<row> train/prediction: 0.8062656154042429/[0.47148743] </row>
		<row> train/prediction: 0.8063419044022453/[0.47148743] </row>
		<row> train/prediction: 0.8064181934002477/[0.47148743] </row>
		<row> train/prediction: 0.8064944823981932/[0.47148743] </row>
		<row> train/prediction: 0.8065707713961956/[0.47148743] </row>
		<row> train/prediction: 0.806647060394198/[0.47148743] </row>
		<row> train/prediction: 0.8067233493921435/[0.47148743] </row>
		<row> train/prediction: 0.8067996383901459/[0.47148743] </row>
		<row> train/prediction: 0.8068761816847996/[0.47148743] </row>
		<row> train/prediction: 0.8069524706827451/[0.47148743] </row>
		<row> train/prediction: 0.8070287596807475/[0.47148743] </row>
		<row> train/prediction: 0.8071050486787499/[0.47148743] </row>
		<row> train/prediction: 0.8071813376766954/[0.4714951] </row>
		<row> train/prediction: 0.8072576266746978/[0.47150642] </row>
		<row> train/prediction: 0.8073339156727002/[0.47151092] </row>
		<row> train/prediction: 0.8074102046706457/[0.47148743] </row>
		<row> train/prediction: 0.8074864936686481/[0.47148743] </row>
		<row> train/prediction: 0.8075627826666505/[0.47148743] </row>
		<row> train/prediction: 0.807639071664596/[0.47148743] </row>
		<row> train/prediction: 0.8077153606625984/[0.47148743] </row>
		<row> train/prediction: 0.807791649660544/[0.47148743] </row>
		<row> train/prediction: 0.8078679386585463/[0.47148743] </row>
		<row> train/prediction: 0.8079442276565487/[0.47148743] </row>
		<row> train/prediction: 0.8080205166544943/[0.47148743] </row>
		<row> train/prediction: 0.8080968056524966/[0.47148743] </row>
		<row> train/prediction: 0.808173094650499/[0.47148743] </row>
		<row> train/prediction: 0.8082493836484446/[0.47148743] </row>
		<row> train/prediction: 0.808325672646447/[0.47148743] </row>
		<row> train/prediction: 0.8084019616444493/[0.47148743] </row>
		<row> train/prediction: 0.8084782506423949/[0.47148743] </row>
		<row> train/prediction: 0.8085545396403973/[0.47148743] </row>
		<row> train/prediction: 0.8086308286383996/[0.47148743] </row>
		<row> train/prediction: 0.8087071176363452/[0.47148743] </row>
		<row> train/prediction: 0.8087834066343476/[0.47148743] </row>
		<row> train/prediction: 0.8088596956322931/[0.47148743] </row>
		<row> train/prediction: 0.8089359846302955/[0.47148743] </row>
		<row> train/prediction: 0.8090122736282979/[0.47148743] </row>
		<row> train/prediction: 0.8090885626262434/[0.47148743] </row>
		<row> train/prediction: 0.8091648516242458/[0.47148743] </row>
		<row> train/prediction: 0.8092411406222482/[0.47148743] </row>
		<row> train/prediction: 0.8093174296201937/[0.47148743] </row>
		<row> train/prediction: 0.8093937186181961/[0.47148743] </row>
		<row> train/prediction: 0.8094700076161985/[0.47148743] </row>
		<row> train/prediction: 0.809546296614144/[0.47148743] </row>
		<row> train/prediction: 0.8096225856121464/[0.47148743] </row>
		<row> train/prediction: 0.8096988746101488/[0.47148743] </row>
		<row> train/prediction: 0.8097751636080943/[0.47148743] </row>
		<row> train/prediction: 0.8098514526060967/[0.47148743] </row>
		<row> train/prediction: 0.8099277416040991/[0.47148743] </row>
		<row> train/prediction: 0.8100040306020446/[0.47146755] </row>
		<row> train/prediction: 0.810080319600047/[0.47145098] </row>
		<row> train/prediction: 0.8101566085979925/[0.47147033] </row>
		<row> train/prediction: 0.8102328975959949/[0.4714864] </row>
		<row> train/prediction: 0.8103091865939973/[0.47148743] </row>
		<row> train/prediction: 0.8103854755919428/[0.47148743] </row>
		<row> train/prediction: 0.8104617645899452/[0.47148743] </row>
		<row> train/prediction: 0.8105380535879476/[0.47148743] </row>
		<row> train/prediction: 0.8106143425858932/[0.47148743] </row>
		<row> train/prediction: 0.8106906315838955/[0.47148743] </row>
		<row> train/prediction: 0.8107669205818979/[0.47148743] </row>
		<row> train/prediction: 0.8108432095798435/[0.47148743] </row>
		<row> train/prediction: 0.8109194985778458/[0.47148743] </row>
		<row> train/prediction: 0.8109957875758482/[0.47148743] </row>
		<row> train/prediction: 0.8110720765737938/[0.47148743] </row>
		<row> train/prediction: 0.8111483655717961/[0.47148743] </row>
		<row> train/prediction: 0.8112246545697417/[0.47148743] </row>
		<row> train/prediction: 0.8113009435677441/[0.47148743] </row>
		<row> train/prediction: 0.8113772325657465/[0.47148743] </row>
		<row> train/prediction: 0.811453521563692/[0.47148743] </row>
		<row> train/prediction: 0.8115298105616944/[0.47148743] </row>
		<row> train/prediction: 0.8122164115435453/[0.47148743] </row>
		<row> train/prediction: 0.8122927005414908/[0.47148743] </row>
		<row> train/prediction: 0.8123692438361445/[0.47148743] </row>
		<row> train/prediction: 0.8124455328341469/[0.47148743] </row>
		<row> train/prediction: 0.8125218218321493/[0.47148743] </row>
		<row> train/prediction: 0.8125981108300948/[0.47148743] </row>
		<row> train/prediction: 0.8126743998280972/[0.47148743] </row>
		<row> train/prediction: 0.8127506888260427/[0.47148743] </row>
		<row> train/prediction: 0.8128269778240451/[0.47148743] </row>
		<row> train/prediction: 0.8129032668220475/[0.4716236] </row>
		<row> train/prediction: 0.812979555819993/[0.47164428] </row>
		<row> train/prediction: 0.8130558448179954/[0.47158602] </row>
		<row> train/prediction: 0.8131321338159978/[0.47153774] </row>
		<row> train/prediction: 0.8132084228139433/[0.4714997] </row>
		<row> train/prediction: 0.8132847118119457/[0.47148743] </row>
		<row> train/prediction: 0.8133610008099481/[0.47148743] </row>
		<row> train/prediction: 0.8134372898078936/[0.47148743] </row>
		<row> train/prediction: 0.813513578805896/[0.47148743] </row>
		<row> train/prediction: 0.8135898678038984/[0.47148743] </row>
		<row> train/prediction: 0.813666156801844/[0.47148743] </row>
		<row> train/prediction: 0.8137424457998463/[0.47148743] </row>
		<row> train/prediction: 0.8138187347978487/[0.47148743] </row>
		<row> train/prediction: 0.8138950237957943/[0.47148743] </row>
		<row> train/prediction: 0.8139713127937966/[0.47148743] </row>
		<row> train/prediction: 0.8140476017917422/[0.47148743] </row>
		<row> train/prediction: 0.8141238907897446/[0.47148743] </row>
		<row> train/prediction: 0.814200179787747/[0.47148743] </row>
		<row> train/prediction: 0.8142764687856925/[0.47148743] </row>
		<row> train/prediction: 0.8143527577836949/[0.47148743] </row>
		<row> train/prediction: 0.8144290467816973/[0.47148743] </row>
		<row> train/prediction: 0.8145053357796428/[0.47148743] </row>
		<row> train/prediction: 0.8145816247776452/[0.47148743] </row>
		<row> train/prediction: 0.8146579137756476/[0.47148743] </row>
		<row> train/prediction: 0.8147342027735931/[0.47148743] </row>
		<row> train/prediction: 0.8148104917715955/[0.47148743] </row>
		<row> train/prediction: 0.8148867807695979/[0.47148743] </row>
		<row> train/prediction: 0.8149630697675434/[0.47148743] </row>
		<row> train/prediction: 0.8150393587655458/[0.47148743] </row>
		<row> train/prediction: 0.8151156477634913/[0.47148743] </row>
		<row> train/prediction: 0.8151919367614937/[0.47148743] </row>
		<row> train/prediction: 0.8152682257594961/[0.47148743] </row>
		<row> train/prediction: 0.8153445147574416/[0.47148743] </row>
		<row> train/prediction: 0.815420803755444/[0.47148743] </row>
		<row> train/prediction: 0.8154970927534464/[0.47148743] </row>
		<row> train/prediction: 0.8155733817513919/[0.47148743] </row>
		<row> train/prediction: 0.8156496707493943/[0.47148743] </row>
		<row> train/prediction: 0.8157259597473967/[0.47148743] </row>
		<row> train/prediction: 0.8158022487453422/[0.47148743] </row>
		<row> train/prediction: 0.8158785377433446/[0.47148743] </row>
		<row> train/prediction: 0.815954826741347/[0.47148743] </row>
		<row> train/prediction: 0.8160311157392925/[0.47148743] </row>
		<row> train/prediction: 0.8161074047372949/[0.47148743] </row>
		<row> train/prediction: 0.8161836937352405/[0.47148743] </row>
		<row> train/prediction: 0.8162599827332429/[0.47148743] </row>
		<row> train/prediction: 0.8163362717312452/[0.47148743] </row>
		<row> train/prediction: 0.8164125607291908/[0.47148743] </row>
		<row> train/prediction: 0.8164888497271932/[0.47148743] </row>
		<row> train/prediction: 0.8165651387251955/[0.47148743] </row>
		<row> train/prediction: 0.8166414277231411/[0.47148743] </row>
		<row> train/prediction: 0.8167177167211435/[0.47148743] </row>
		<row> train/prediction: 0.8167940057191458/[0.47148743] </row>
		<row> train/prediction: 0.8168702947170914/[0.47148743] </row>
		<row> train/prediction: 0.8169465837150938/[0.47148743] </row>
		<row> train/prediction: 0.8170228727130961/[0.47148743] </row>
		<row> train/prediction: 0.8170991617110417/[0.47148743] </row>
		<row> train/prediction: 0.8171754507090441/[0.47148743] </row>
		<row> train/prediction: 0.8172517397069896/[0.47148743] </row>
		<row> train/prediction: 0.817328028704992/[0.47148743] </row>
		<row> train/prediction: 0.8174043177029944/[0.47148743] </row>
		<row> train/prediction: 0.8174806067009399/[0.47148743] </row>
		<row> train/prediction: 0.8175568956989423/[0.47148743] </row>
		<row> train/prediction: 0.8176331846969447/[0.47148743] </row>
		<row> train/prediction: 0.8177094736948902/[0.47148743] </row>
		<row> train/prediction: 0.8177857626928926/[0.47148743] </row>
		<row> train/prediction: 0.8178623059875463/[0.47148743] </row>
		<row> train/prediction: 0.8179385949854918/[0.47148743] </row>
		<row> train/prediction: 0.8180148839834942/[0.47148743] </row>
		<row> train/prediction: 0.8180911729814966/[0.47148743] </row>
		<row> train/prediction: 0.8181674619794421/[0.47148743] </row>
		<row> train/prediction: 0.8182437509774445/[0.47148743] </row>
		<row> train/prediction: 0.8183200399754469/[0.47148743] </row>
		<row> train/prediction: 0.8183963289733924/[0.47148743] </row>
		<row> train/prediction: 0.8184726179713948/[0.47148743] </row>
		<row> train/prediction: 0.8185489069693972/[0.47148743] </row>
		<row> train/prediction: 0.8186251959673427/[0.47148743] </row>
		<row> train/prediction: 0.8187014849653451/[0.47152334] </row>
		<row> train/prediction: 0.8187777739633475/[0.47148743] </row>
		<row> train/prediction: 0.818854062961293/[0.4715254] </row>
		<row> train/prediction: 0.8189303519592954/[0.47150642] </row>
		<row> train/prediction: 0.819006640957241/[0.4715229] </row>
		<row> train/prediction: 0.8190829299552433/[0.47148743] </row>
		<row> train/prediction: 0.8191592189532457/[0.47148743] </row>
		<row> train/prediction: 0.8192355079511913/[0.47148743] </row>
		<row> train/prediction: 0.8193117969491936/[0.47148743] </row>
		<row> train/prediction: 0.819388085947196/[0.47148743] </row>
		<row> train/prediction: 0.8194643749451416/[0.47148743] </row>
		<row> train/prediction: 0.819540663943144/[0.47148743] </row>
		<row> train/prediction: 0.8196169529411463/[0.47148743] </row>
		<row> train/prediction: 0.8196932419390919/[0.47148743] </row>
		<row> train/prediction: 0.8197695309370943/[0.47148743] </row>
		<row> train/prediction: 0.8198458199350966/[0.47148743] </row>
		<row> train/prediction: 0.8199221089330422/[0.47149596] </row>
		<row> train/prediction: 0.8199983979310446/[0.47153375] </row>
		<row> train/prediction: 0.8200746869289901/[0.47151116] </row>
		<row> train/prediction: 0.8201509759269925/[0.47148743] </row>
		<row> train/prediction: 0.8202272649249949/[0.47148743] </row>
		<row> train/prediction: 0.8203035539229404/[0.47148743] </row>
		<row> train/prediction: 0.8203798429209428/[0.47148743] </row>
		<row> train/prediction: 0.8204561319189452/[0.47148743] </row>
		<row> train/prediction: 0.8205324209168907/[0.47148743] </row>
		<row> train/prediction: 0.8206087099148931/[0.47148743] </row>
		<row> train/prediction: 0.8206849989128955/[0.47148743] </row>
		<row> train/prediction: 0.820761287910841/[0.47148743] </row>
		<row> train/prediction: 0.8208375769088434/[0.47148743] </row>
		<row> train/prediction: 0.8209138659068458/[0.47148743] </row>
		<row> train/prediction: 0.8209901549047913/[0.47148743] </row>
		<row> train/prediction: 0.8210664439027937/[0.47148743] </row>
		<row> train/prediction: 0.8211427329007961/[0.47127202] </row>
		<row> train/prediction: 0.8212190218987416/[0.47115734] </row>
		<row> train/prediction: 0.821295310896744/[0.470755] </row>
		<row> train/prediction: 0.8213715998946896/[0.47031754] </row>
		<row> train/prediction: 0.8214478888926919/[0.470384] </row>
		<row> train/prediction: 0.8215241778906943/[0.47018966] </row>
		<row> train/prediction: 0.8216004668886399/[0.47055504] </row>
		<row> train/prediction: 0.8216767558866422/[0.47060242] </row>
		<row> train/prediction: 0.8217530448846446/[0.47128615] </row>
		<row> train/prediction: 0.8218293338825902/[0.47159296] </row>
		<row> train/prediction: 0.8219056228805925/[0.47147518] </row>
		<row> train/prediction: 0.8219819118785949/[0.47161612] </row>
		<row> train/prediction: 0.8220582008765405/[0.47165236] </row>
		<row> train/prediction: 0.8221344898745429/[0.4714687] </row>
		<row> train/prediction: 0.8222107788725452/[0.47183517] </row>
		<row> train/prediction: 0.8222870678704908/[0.47191006] </row>
		<row> train/prediction: 0.8223633568684932/[0.47216445] </row>
		<row> train/prediction: 0.8224396458664387/[0.47217575] </row>
		<row> train/prediction: 0.8225159348644411/[0.47215736] </row>
		<row> train/prediction: 0.8225922238624435/[0.4723216] </row>
		<row> train/prediction: 0.822668512860389/[0.47263974] </row>
		<row> train/prediction: 0.8227448018583914/[0.4721412] </row>
		<row> train/prediction: 0.8228210908563938/[0.47262678] </row>
		<row> train/prediction: 0.8228973798543393/[0.47240716] </row>
		<row> train/prediction: 0.8229736688523417/[0.47122738] </row>
		<row> train/prediction: 0.8232788248442944/[0.47121498] </row>
		<row> train/prediction: 0.8233553681388912/[0.47140363] </row>
		<row> train/prediction: 0.8234316571368936/[0.471406] </row>
		<row> train/prediction: 0.823507946134896/[0.47127646] </row>
		<row> train/prediction: 0.8235842351328415/[0.4715393] </row>
		<row> train/prediction: 0.8236605241308439/[0.471465] </row>
		<row> train/prediction: 0.8237368131288463/[0.47155872] </row>
		<row> train/prediction: 0.8238131021267918/[0.47150615] </row>
		<row> train/prediction: 0.8238893911247942/[0.47148743] </row>
		<row> train/prediction: 0.8239656801227397/[0.47148743] </row>
		<row> train/prediction: 0.8240419691207421/[0.47150037] </row>
		<row> train/prediction: 0.8241182581187445/[0.47153887] </row>
		<row> train/prediction: 0.82419454711669/[0.47182772] </row>
		<row> train/prediction: 0.8242708361146924/[0.471825] </row>
		<row> train/prediction: 0.8243471251126948/[0.4715956] </row>
		<row> train/prediction: 0.8244234141106404/[0.47148743] </row>
		<row> train/prediction: 0.8244997031086427/[0.47148743] </row>
		<row> train/prediction: 0.8245759921066451/[0.47148743] </row>
		<row> train/prediction: 0.8246522811045907/[0.47148743] </row>
		<row> train/prediction: 0.824728570102593/[0.47149232] </row>
		<row> train/prediction: 0.8248048591005954/[0.47148743] </row>
		<row> train/prediction: 0.824881148098541/[0.47149616] </row>
		<row> train/prediction: 0.8249574370965433/[0.47161105] </row>
		<row> train/prediction: 0.8250337260945457/[0.4716007] </row>
		<row> train/prediction: 0.8430458128147507/[0.47156233] </row>
		<row> train/prediction: 0.843122101812753/[0.47148743] </row>
		<row> train/prediction: 0.8431983908107554/[0.4715947] </row>
		<row> train/prediction: 0.843274679808701/[0.47150314] </row>
		<row> train/prediction: 0.8433509688067033/[0.47148743] </row>
		<row> train/prediction: 0.8434272578046489/[0.47149128] </row>
		<row> train/prediction: 0.8435035468026513/[0.47150132] </row>
		<row> train/prediction: 0.8435798358006537/[0.47147247] </row>
		<row> train/prediction: 0.8436561247985992/[0.47144127] </row>
		<row> train/prediction: 0.8437324137966016/[0.4714076] </row>
		<row> train/prediction: 0.843808702794604/[0.47145674] </row>
		<row> train/prediction: 0.8438849917925495/[0.4714627] </row>
		<row> train/prediction: 0.8439612807905519/[0.47139156] </row>
		<row> train/prediction: 0.8440375697885543/[0.4713446] </row>
		<row> train/prediction: 0.8441138587864998/[0.47133517] </row>
		<row> train/prediction: 0.8441901477845022/[0.47130027] </row>
		<row> train/prediction: 0.8442664367825046/[0.47133538] </row>
		<row> train/prediction: 0.8443427257804501/[0.47126782] </row>
		<row> train/prediction: 0.8444190147784525/[0.47124794] </row>
		<row> train/prediction: 0.844495303776398/[0.4713431] </row>
		<row> train/prediction: 0.8445715927744004/[0.47133625] </row>
		<row> train/prediction: 0.8446478817724028/[0.4713807] </row>
		<row> train/prediction: 0.8447241707703483/[0.47148174] </row>
		<row> train/prediction: 0.8448004597683507/[0.47148743] </row>
		<row> train/prediction: 0.8448767487663531/[0.47148743] </row>
		<row> train/prediction: 0.8449530377642986/[0.47148743] </row>
		<row> train/prediction: 0.845029326762301/[0.47148743] </row>
		<row> train/prediction: 0.8451056157603034/[0.47148743] </row>
		<row> train/prediction: 0.845181904758249/[0.47148743] </row>
		<row> train/prediction: 0.8452581937562513/[0.47148743] </row>
		<row> train/prediction: 0.8453344827542537/[0.47148743] </row>
		<row> train/prediction: 0.8454107717521993/[0.47148743] </row>
		<row> train/prediction: 0.8454870607502016/[0.47148743] </row>
		<row> train/prediction: 0.845563349748204/[0.47148743] </row>
		<row> train/prediction: 0.8456396387461496/[0.47148743] </row>
		<row> train/prediction: 0.8457159277441519/[0.47148743] </row>
		<row> train/prediction: 0.8457922167420975/[0.47148743] </row>
		<row> train/prediction: 0.8458685057400999/[0.47156957] </row>
		<row> train/prediction: 0.8459447947381022/[0.47176075] </row>
		<row> train/prediction: 0.8460210837360478/[0.47158763] </row>
		<row> train/prediction: 0.8460973727340502/[0.4715435] </row>
		<row> train/prediction: 0.8461736617320526/[0.47156617] </row>
		<row> train/prediction: 0.8462499507299981/[0.47148743] </row>
		<row> train/prediction: 0.8463262397280005/[0.47156125] </row>
		<row> train/prediction: 0.8464025287260029/[0.47176167] </row>
		<row> train/prediction: 0.8464788177239484/[0.4717119] </row>
		<row> train/prediction: 0.8465551067219508/[0.47172454] </row>
		<row> train/prediction: 0.8466313957199532/[0.47161743] </row>
		<row> train/prediction: 0.8467076847178987/[0.4714968] </row>
		<row> train/prediction: 0.8467839737159011/[0.47149572] </row>
		<row> train/prediction: 0.8468602627138466/[0.47148743] </row>
		<row> train/prediction: 0.846936551711849/[0.47148743] </row>
		<row> train/prediction: 0.8470128407098514/[0.47148743] </row>
		<row> train/prediction: 0.8470891297077969/[0.47148743] </row>
		<row> train/prediction: 0.8471654187057993/[0.47148743] </row>
		<row> train/prediction: 0.8472417077038017/[0.47148743] </row>
		<row> train/prediction: 0.8473179967017472/[0.47148743] </row>
		<row> train/prediction: 0.8473942856997496/[0.47148743] </row>
		<row> train/prediction: 0.847470574697752/[0.47148743] </row>
		<row> train/prediction: 0.8475468636956975/[0.47148743] </row>
		<row> train/prediction: 0.8476231526936999/[0.47148743] </row>
		<row> train/prediction: 0.8476994416917023/[0.47148743] </row>
		<row> train/prediction: 0.8477757306896478/[0.47148743] </row>
		<row> train/prediction: 0.8478520196876502/[0.47148743] </row>
		<row> train/prediction: 0.8479283086855958/[0.47148743] </row>
		<row> train/prediction: 0.8480045976835981/[0.47148743] </row>
		<row> train/prediction: 0.8480808866816005/[0.47148743] </row>
		<row> train/prediction: 0.8481571756795461/[0.47148743] </row>
		<row> train/prediction: 0.8482334646775485/[0.47148743] </row>
		<row> train/prediction: 0.8483097536755508/[0.47148743] </row>
		<row> train/prediction: 0.8502932676230444/[0.47148743] </row>
		<row> train/prediction: 0.8503695566210467/[0.47148743] </row>
		<row> train/prediction: 0.8504458456190491/[0.47148743] </row>
		<row> train/prediction: 0.8505221346169947/[0.47148743] </row>
		<row> train/prediction: 0.850598423614997/[0.47148743] </row>
		<row> train/prediction: 0.8506747126129994/[0.47148743] </row>
		<row> train/prediction: 0.850751001610945/[0.47150484] </row>
		<row> train/prediction: 0.8508272906089474/[0.47156125] </row>
		<row> train/prediction: 0.8509035796069497/[0.47161576] </row>
		<row> train/prediction: 0.8509798686048953/[0.47162804] </row>
		<row> train/prediction: 0.8510561576028977/[0.47165474] </row>
		<row> train/prediction: 0.8511324466009/[0.47163025] </row>
		<row> train/prediction: 0.8512087355988456/[0.47152895] </row>
		<row> train/prediction: 0.851285024596848/[0.47148743] </row>
		<row> train/prediction: 0.8513613135947935/[0.47148743] </row>
		<row> train/prediction: 0.8514376025927959/[0.47148743] </row>
		<row> train/prediction: 0.8515138915907983/[0.47148743] </row>
		<row> train/prediction: 0.8515901805887438/[0.47148743] </row>
		<row> train/prediction: 0.8516664695867462/[0.4714545] </row>
		<row> train/prediction: 0.8517427585847486/[0.47133267] </row>
		<row> train/prediction: 0.8518190475826941/[0.47145393] </row>
		<row> train/prediction: 0.8518953365806965/[0.47148743] </row>
		<row> train/prediction: 0.8519716255786989/[0.47148743] </row>
		<row> train/prediction: 0.8520479145766444/[0.47148743] </row>
		<row> train/prediction: 0.8521247121679494/[0.47148743] </row>
		<row> train/prediction: 0.8522010011659518/[0.47148797] </row>
		<row> train/prediction: 0.8522772901638973/[0.47148743] </row>
		<row> train/prediction: 0.8523535791618997/[0.47148743] </row>
		<row> train/prediction: 0.8524298681599021/[0.47148743] </row>
		<row> train/prediction: 0.8525061571578476/[0.47148743] </row>
		<row> train/prediction: 0.85258244615585/[0.47148743] </row>
		<row> train/prediction: 0.8526587351538524/[0.47148743] </row>
		<row> train/prediction: 0.8527350241517979/[0.47148678] </row>
		<row> train/prediction: 0.8528113131498003/[0.47148743] </row>
		<row> train/prediction: 0.8528876021478027/[0.47148743] </row>
		<row> train/prediction: 0.8529638911457482/[0.47148928] </row>
		<row> train/prediction: 0.8530401801437506/[0.47153017] </row>
		<row> train/prediction: 0.853116469141753/[0.47161165] </row>
		<row> train/prediction: 0.8531927581396985/[0.47165126] </row>
		<row> train/prediction: 0.8532690471377009/[0.47163758] </row>
		<row> train/prediction: 0.8533453361357033/[0.47168073] </row>
		<row> train/prediction: 0.8534216251336488/[0.47160324] </row>
		<row> train/prediction: 0.8534979141316512/[0.47158742] </row>
		<row> train/prediction: 0.8535742031295968/[0.47148743] </row>
		<row> train/prediction: 0.8536504921275991/[0.47148743] </row>
		<row> train/prediction: 0.8537267811256015/[0.47148743] </row>
		<row> train/prediction: 0.8538030701235471/[0.47148743] </row>
		<row> train/prediction: 0.8538793591215494/[0.47148743] </row>
		<row> train/prediction: 0.8539556481195518/[0.47148743] </row>
		<row> train/prediction: 0.8540319371174974/[0.47138396] </row>
		<row> train/prediction: 0.8541082261154997/[0.47131768] </row>
		<row> train/prediction: 0.8541845151135021/[0.47132465] </row>
		<row> train/prediction: 0.8542608041114477/[0.4713171] </row>
		<row> train/prediction: 0.85433709310945/[0.47132167] </row>
		<row> train/prediction: 0.8544133821074524/[0.47140977] </row>
		<row> train/prediction: 0.854489671105398/[0.47151998] </row>
		<row> train/prediction: 0.8545659601034004/[0.471579] </row>
		<row> train/prediction: 0.8546422491013459/[0.47159278] </row>
		<row> train/prediction: 0.8547185380993483/[0.47155485] </row>
		<row> train/prediction: 0.8547948270973507/[0.4715103] </row>
		<row> train/prediction: 0.8548711160952962/[0.47148743] </row>
		<row> train/prediction: 0.8549474050932986/[0.47148743] </row>
		<row> train/prediction: 0.855023694091301/[0.47148743] </row>
		<row> train/prediction: 0.8550999830892465/[0.47149107] </row>
		<row> train/prediction: 0.8551762720872489/[0.47153762] </row>
		<row> train/prediction: 0.8552525610852513/[0.4716438] </row>
		<row> train/prediction: 0.8553288500831968/[0.47163376] </row>
		<row> train/prediction: 0.8554051390811992/[0.47152534] </row>
		<row> train/prediction: 0.8554814280792016/[0.47174117] </row>
		<row> train/prediction: 0.8555577170771471/[0.47195953] </row>
		<row> train/prediction: 0.8556340060751495/[0.4720626] </row>
		<row> train/prediction: 0.855710295073095/[0.47204167] </row>
		<row> train/prediction: 0.8557865840710974/[0.47205946] </row>
		<row> train/prediction: 0.8558628730690998/[0.472026] </row>
		<row> train/prediction: 0.8559391620670453/[0.47186792] </row>
		<row> train/prediction: 0.8560154510650477/[0.47169015] </row>
		<row> train/prediction: 0.8560917400630501/[0.4715316] </row>
		<row> train/prediction: 0.8561680290609957/[0.47153798] </row>
		<row> train/prediction: 0.856244318058998/[0.4715303] </row>
		<row> train/prediction: 0.8563206070570004/[0.47151542] </row>
		<row> train/prediction: 0.856396896054946/[0.47150695] </row>
		<row> train/prediction: 0.8564731850529483/[0.47148743] </row>
		<row> train/prediction: 0.8565494740509507/[0.47148743] </row>
		<row> train/prediction: 0.8566257630488963/[0.47148743] </row>
		<row> train/prediction: 0.8567020520468986/[0.4714941] </row>
		<row> train/prediction: 0.8567783410448442/[0.47151327] </row>
		<row> train/prediction: 0.8568546300428466/[0.4714821] </row>
		<row> train/prediction: 0.856930919040849/[0.4714194] </row>
		<row> train/prediction: 0.8570072080387945/[0.4714025] </row>
		<row> train/prediction: 0.8570834970367969/[0.4713994] </row>
		<row> train/prediction: 0.8571597860347993/[0.471451] </row>
		<row> train/prediction: 0.8572360750327448/[0.47148743] </row>
		<row> train/prediction: 0.8573123640307472/[0.47150177] </row>
		<row> train/prediction: 0.8573886530287496/[0.47149912] </row>
		<row> train/prediction: 0.8574649420266951/[0.47148743] </row>
		<row> train/prediction: 0.8575412310246975/[0.47148743] </row>
		<row> train/prediction: 0.8576180286160024/[0.47148743] </row>
		<row> train/prediction: 0.8576943176140048/[0.47148743] </row>
		<row> train/prediction: 0.8577706066119504/[0.47148743] </row>
		<row> train/prediction: 0.8578468956099528/[0.47149155] </row>
		<row> train/prediction: 0.8579231846078983/[0.4715185] </row>
		<row> train/prediction: 0.8579994736059007/[0.47148743] </row>
		<row> train/prediction: 0.8580757626039031/[0.47148743] </row>
		<row> train/prediction: 0.8581520516018486/[0.47148743] </row>
		<row> train/prediction: 0.858228340599851/[0.47148743] </row>
		<row> train/prediction: 0.8583046295978534/[0.47148743] </row>
		<row> train/prediction: 0.8583809185957989/[0.47148743] </row>
		<row> train/prediction: 0.8584572075938013/[0.47148743] </row>
		<row> train/prediction: 0.8585334965918037/[0.47148743] </row>
		<row> train/prediction: 0.8586097855897492/[0.47148743] </row>
		<row> train/prediction: 0.8586860745877516/[0.47148743] </row>
		<row> train/prediction: 0.858762363585754/[0.47148743] </row>
		<row> train/prediction: 0.8588386525836995/[0.47148743] </row>
		<row> train/prediction: 0.8589149415817019/[0.47148743] </row>
		<row> train/prediction: 0.8589912305796474/[0.47148743] </row>
		<row> train/prediction: 0.8590675195776498/[0.47148743] </row>
		<row> train/prediction: 0.8591438085756522/[0.47148743] </row>
		<row> train/prediction: 0.8592200975735977/[0.47148743] </row>
		<row> train/prediction: 0.8592963865716001/[0.47148743] </row>
		<row> train/prediction: 0.8593726755696025/[0.47148743] </row>
		<row> train/prediction: 0.859448964567548/[0.47148743] </row>
		<row> train/prediction: 0.8595252535655504/[0.47148743] </row>
		<row> train/prediction: 0.8596015425635528/[0.47148743] </row>
		<row> train/prediction: 0.8596778315614984/[0.47148743] </row>
		<row> train/prediction: 0.8597541205595007/[0.47148743] </row>
		<row> train/prediction: 0.8598304095575031/[0.47148743] </row>
		<row> train/prediction: 0.8599066985554487/[0.47148743] </row>
		<row> train/prediction: 0.859982987553451/[0.47148743] </row>
		<row> train/prediction: 0.8600592765514534/[0.47148743] </row>
		<row> train/prediction: 0.860135565549399/[0.47148743] </row>
		<row> train/prediction: 0.8602118545474013/[0.47148743] </row>
		<row> train/prediction: 0.8602881435453469/[0.47156537] </row>
		<row> train/prediction: 0.8603644325433493/[0.47167367] </row>
		<row> train/prediction: 0.8604407215413516/[0.47171465] </row>
		<row> train/prediction: 0.8605170105392972/[0.47169763] </row>
		<row> train/prediction: 0.8605932995372996/[0.47165164] </row>
		<row> train/prediction: 0.860669588535302/[0.47154087] </row>
		<row> train/prediction: 0.8607458775332475/[0.47148743] </row>
		<row> train/prediction: 0.8608221665312499/[0.47148743] </row>
		<row> train/prediction: 0.8608984555292523/[0.47148743] </row>
		<row> train/prediction: 0.8609747445271978/[0.47148743] </row>
		<row> train/prediction: 0.8610510335252002/[0.47148743] </row>
		<row> train/prediction: 0.8611273225232026/[0.47148743] </row>
		<row> train/prediction: 0.8612036115211481/[0.47148743] </row>
		<row> train/prediction: 0.8612799005191505/[0.47148743] </row>
		<row> train/prediction: 0.861356189517096/[0.47148743] </row>
		<row> train/prediction: 0.8614324785150984/[0.47148743] </row>
		<row> train/prediction: 0.8615087675131008/[0.47148743] </row>
		<row> train/prediction: 0.8615850565110463/[0.47148743] </row>
		<row> train/prediction: 0.8616613455090487/[0.47148743] </row>
		<row> train/prediction: 0.8617376345070511/[0.47148743] </row>
		<row> train/prediction: 0.8618139235049966/[0.47148743] </row>
		<row> train/prediction: 0.861890212502999/[0.47148743] </row>
		<row> train/prediction: 0.8619665015010014/[0.47148743] </row>
		<row> train/prediction: 0.8620427904989469/[0.47148743] </row>
		<row> train/prediction: 0.8621190794969493/[0.47148743] </row>
		<row> train/prediction: 0.8621953684949517/[0.47148743] </row>
		<row> train/prediction: 0.8622716574928972/[0.47148743] </row>
		<row> train/prediction: 0.8623479464908996/[0.47148743] </row>
		<row> train/prediction: 0.8624242354888452/[0.47148743] </row>
		<row> train/prediction: 0.8625005244868476/[0.47148743] </row>
		<row> train/prediction: 0.8625768134848499/[0.47148743] </row>
		<row> train/prediction: 0.8626531024827955/[0.47148743] </row>
		<row> train/prediction: 0.8627293914807979/[0.47148743] </row>
		<row> train/prediction: 0.8628056804788002/[0.47148743] </row>
		<row> train/prediction: 0.8628819694767458/[0.47148743] </row>
		<row> train/prediction: 0.8629582584747482/[0.47148743] </row>
		<row> train/prediction: 0.8630345474727505/[0.47148743] </row>
		<row> train/prediction: 0.8631110907673474/[0.47148743] </row>
		<row> train/prediction: 0.8631873797653498/[0.47148743] </row>
		<row> train/prediction: 0.8632636687633521/[0.47148743] </row>
		<row> train/prediction: 0.8633399577612977/[0.47148743] </row>
		<row> train/prediction: 0.8634162467593001/[0.47148743] </row>
		<row> train/prediction: 0.8634925357573024/[0.47148743] </row>
		<row> train/prediction: 0.863568824755248/[0.47148743] </row>
		<row> train/prediction: 0.8636451137532504/[0.47148743] </row>
		<row> train/prediction: 0.8637214027512528/[0.47148743] </row>
		<row> train/prediction: 0.8637976917491983/[0.47148743] </row>
		<row> train/prediction: 0.8638739807472007/[0.47148743] </row>
		<row> train/prediction: 0.8639502697452031/[0.47148743] </row>
		<row> train/prediction: 0.8640265587431486/[0.47148743] </row>
		<row> train/prediction: 0.864102847741151/[0.47148743] </row>
		<row> train/prediction: 0.8641791367390965/[0.47148743] </row>
		<row> train/prediction: 0.8642554257370989/[0.47148743] </row>
		<row> train/prediction: 0.8643317147351013/[0.47148743] </row>
		<row> train/prediction: 0.8644080037330468/[0.47148743] </row>
		<row> train/prediction: 0.8644842927310492/[0.47148743] </row>
		<row> train/prediction: 0.8645605817290516/[0.47148743] </row>
		<row> train/prediction: 0.8646368707269971/[0.47148743] </row>
		<row> train/prediction: 0.8647131597249995/[0.47148743] </row>
		<row> train/prediction: 0.8647894487230019/[0.47148743] </row>
		<row> train/prediction: 0.8648657377209474/[0.47148743] </row>
		<row> train/prediction: 0.8649420267189498/[0.47148743] </row>
		<row> train/prediction: 0.8650183157169522/[0.47148743] </row>
		<row> train/prediction: 0.8650946047148977/[0.47148743] </row>
		<row> train/prediction: 0.8651708937129001/[0.47148743] </row>
		<row> train/prediction: 0.8652471827108457/[0.47148743] </row>
		<row> train/prediction: 0.865323471708848/[0.47148743] </row>
		<row> train/prediction: 0.8653997607068504/[0.47148743] </row>
		<row> train/prediction: 0.865476049704796/[0.47148743] </row>
		<row> train/prediction: 0.8655523387027984/[0.47148743] </row>
		<row> train/prediction: 0.8656286277008007/[0.47148743] </row>
		<row> train/prediction: 0.8657049166987463/[0.47148743] </row>
		<row> train/prediction: 0.8657812056967487/[0.47148743] </row>
		<row> train/prediction: 0.865857494694751/[0.47148743] </row>
		<row> train/prediction: 0.8659337836926966/[0.47148743] </row>
		<row> train/prediction: 0.866010072690699/[0.47148743] </row>
		<row> train/prediction: 0.8660863616887013/[0.47148743] </row>
		<row> train/prediction: 0.8661626506866469/[0.47148743] </row>
		<row> train/prediction: 0.8662389396846493/[0.47148743] </row>
		<row> train/prediction: 0.8663152286825948/[0.47148743] </row>
		<row> train/prediction: 0.8663915176805972/[0.47148743] </row>
		<row> train/prediction: 0.8664678066785996/[0.47148743] </row>
		<row> train/prediction: 0.8665440956765451/[0.47148743] </row>
		<row> train/prediction: 0.8666203846745475/[0.47148743] </row>
		<row> train/prediction: 0.8666966736725499/[0.47148743] </row>
		<row> train/prediction: 0.8667729626704954/[0.47148743] </row>
		<row> train/prediction: 0.8668492516684978/[0.47148743] </row>
		<row> train/prediction: 0.8669255406665002/[0.47148743] </row>
		<row> train/prediction: 0.8670018296644457/[0.47148743] </row>
		<row> train/prediction: 0.8670781186624481/[0.47148743] </row>
		<row> train/prediction: 0.8671544076604505/[0.47148743] </row>
		<row> train/prediction: 0.867230696658396/[0.47148743] </row>
		<row> train/prediction: 0.8673069856563984/[0.47148743] </row>
		<row> train/prediction: 0.867383274654344/[0.47148743] </row>
		<row> train/prediction: 0.8674595636523463/[0.47148743] </row>
		<row> train/prediction: 0.8675358526503487/[0.47148743] </row>
		<row> train/prediction: 0.8676121416482943/[0.47148743] </row>
		<row> train/prediction: 0.8676884306462966/[0.47148743] </row>
		<row> train/prediction: 0.867764719644299/[0.47148743] </row>
		<row> train/prediction: 0.8678410086422446/[0.47148743] </row>
		<row> train/prediction: 0.8679172976402469/[0.47148743] </row>
		<row> train/prediction: 0.8679935866382493/[0.47148743] </row>
		<row> train/prediction: 0.8680698756361949/[0.47148743] </row>
		<row> train/prediction: 0.8681461646341972/[0.47148743] </row>
		<row> train/prediction: 0.8682224536321996/[0.47148743] </row>
		<row> train/prediction: 0.8682987426301452/[0.47148743] </row>
		<row> train/prediction: 0.8683750316281476/[0.47148743] </row>
		<row> train/prediction: 0.8684513206261499/[0.47148743] </row>
		<row> train/prediction: 0.8685276096240955/[0.47148743] </row>
		<row> train/prediction: 0.8686041529187492/[0.47148743] </row>
		<row> train/prediction: 0.8686804419167515/[0.47148743] </row>
		<row> train/prediction: 0.8687567309146971/[0.47148743] </row>
		<row> train/prediction: 0.8688330199126995/[0.47148743] </row>
		<row> train/prediction: 0.8689093089107018/[0.47148743] </row>
		<row> train/prediction: 0.8689855979086474/[0.47148743] </row>
		<row> train/prediction: 0.8690618869066498/[0.47148743] </row>
		<row> train/prediction: 0.8691381759045953/[0.47148743] </row>
		<row> train/prediction: 0.8692144649025977/[0.47148743] </row>
		<row> train/prediction: 0.8692907539006001/[0.47148743] </row>
		<row> train/prediction: 0.8693670428985456/[0.47148743] </row>
		<row> train/prediction: 0.869443331896548/[0.47148743] </row>
		<row> train/prediction: 0.8695196208945504/[0.47148743] </row>
		<row> train/prediction: 0.8695959098924959/[0.47148743] </row>
		<row> train/prediction: 0.8696721988904983/[0.47148743] </row>
		<row> train/prediction: 0.8697484878885007/[0.47148743] </row>
		<row> train/prediction: 0.8698247768864462/[0.47148743] </row>
		<row> train/prediction: 0.8699010658844486/[0.47148743] </row>
		<row> train/prediction: 0.869977354882451/[0.47148743] </row>
		<row> train/prediction: 0.8700536438803965/[0.47148743] </row>
		<row> train/prediction: 0.8701299328783989/[0.47148743] </row>
		<row> train/prediction: 0.8702062218763444/[0.47148743] </row>
		<row> train/prediction: 0.8702825108743468/[0.47148743] </row>
		<row> train/prediction: 0.8703587998723492/[0.47148743] </row>
		<row> train/prediction: 0.8704350888702947/[0.47148857] </row>
		<row> train/prediction: 0.8705113778682971/[0.4714913] </row>
		<row> train/prediction: 0.8705876668662995/[0.47149387] </row>
		<row> train/prediction: 0.870663955864245/[0.47149396] </row>
		<row> train/prediction: 0.8707402448622474/[0.47149345] </row>
		<row> train/prediction: 0.8708165338602498/[0.4714876] </row>
		<row> train/prediction: 0.8708928228581954/[0.47142234] </row>
		<row> train/prediction: 0.8709691118561977/[0.47137946] </row>
		<row> train/prediction: 0.8710454008542001/[0.47134322] </row>
		<row> train/prediction: 0.8711216898521457/[0.4713188] </row>
		<row> train/prediction: 0.871197978850148/[0.47129104] </row>
		<row> train/prediction: 0.8712742678480936/[0.4712787] </row>
		<row> train/prediction: 0.871350556846096/[0.47129935] </row>
		<row> train/prediction: 0.8714268458440984/[0.47133273] </row>
		<row> train/prediction: 0.8715031348420439/[0.47140175] </row>
		<row> train/prediction: 0.8715794238400463/[0.47146797] </row>
		<row> train/prediction: 0.8716557128380487/[0.47148743] </row>
		<row> train/prediction: 0.8717320018359942/[0.47148743] </row>
		<row> train/prediction: 0.8718082908339966/[0.47148743] </row>
		<row> train/prediction: 0.871884579831999/[0.47148743] </row>
		<row> train/prediction: 0.8719608688299445/[0.47148743] </row>
		<row> train/prediction: 0.8720371578279469/[0.47148743] </row>
		<row> train/prediction: 0.8721134468259493/[0.47148743] </row>
		<row> train/prediction: 0.8721897358238948/[0.47148743] </row>
		<row> train/prediction: 0.8722660248218972/[0.4715134] </row>
		<row> train/prediction: 0.8723423138198996/[0.471525] </row>
		<row> train/prediction: 0.8724186028178451/[0.4715027] </row>
		<row> train/prediction: 0.8724948918158475/[0.47150087] </row>
		<row> train/prediction: 0.872571180813793/[0.4715018] </row>
		<row> train/prediction: 0.8726474698117954/[0.47148743] </row>
		<row> train/prediction: 0.8727237588097978/[0.47148743] </row>
		<row> train/prediction: 0.8728000478077433/[0.47148743] </row>
		<row> train/prediction: 0.8728763368057457/[0.47148743] </row>
		<row> train/prediction: 0.8729526258037481/[0.47148743] </row>
		<row> train/prediction: 0.8730289148016936/[0.47148743] </row>
		<row> train/prediction: 0.873105203799696/[0.47148743] </row>
		<row> train/prediction: 0.8731814927976984/[0.47148743] </row>
		<row> train/prediction: 0.873257781795644/[0.47148743] </row>
		<row> train/prediction: 0.8733340707936463/[0.47148743] </row>
		<row> train/prediction: 0.8734103597916487/[0.47148743] </row>
		<row> train/prediction: 0.8734866487895943/[0.47148743] </row>
		<row> train/prediction: 0.8735629377875966/[0.47148743] </row>
		<row> train/prediction: 0.8736392267855422/[0.47148743] </row>
		<row> train/prediction: 0.8737155157835446/[0.47148743] </row>
		<row> train/prediction: 0.8737918047815469/[0.47148743] </row>
		<row> train/prediction: 0.8738680937794925/[0.47148743] </row>
		<row> train/prediction: 0.8739443827774949/[0.47148743] </row>
		<row> train/prediction: 0.8740206717754972/[0.47148743] </row>
		<row> train/prediction: 0.8740972150700941/[0.47148743] </row>
		<row> train/prediction: 0.8741735040680965/[0.47148743] </row>
		<row> train/prediction: 0.8742497930660988/[0.47148743] </row>
		<row> train/prediction: 0.8743260820640444/[0.47148743] </row>
		<row> train/prediction: 0.8744023710620468/[0.47148743] </row>
		<row> train/prediction: 0.8744786600600492/[0.47148743] </row>
		<row> train/prediction: 0.8745549490579947/[0.47148743] </row>
		<row> train/prediction: 0.8746312380559971/[0.47148743] </row>
		<row> train/prediction: 0.8747075270539995/[0.47148743] </row>
		<row> train/prediction: 0.874783816051945/[0.47148743] </row>
		<row> train/prediction: 0.8748601050499474/[0.47148743] </row>
		<row> train/prediction: 0.8749363940479498/[0.47148743] </row>
		<row> train/prediction: 0.8750126830458953/[0.47148743] </row>
		<row> train/prediction: 0.8750889720438977/[0.47148743] </row>
		<row> train/prediction: 0.8751652610419001/[0.47148743] </row>
		<row> train/prediction: 0.8752415500398456/[0.47148743] </row>
		<row> train/prediction: 0.875317839037848/[0.47148743] </row>
		<row> train/prediction: 0.8753941280357935/[0.47148743] </row>
		<row> train/prediction: 0.8754704170337959/[0.47148743] </row>
		<row> train/prediction: 0.8755467060317983/[0.47148743] </row>
		<row> train/prediction: 0.8756229950297438/[0.47148743] </row>
		<row> train/prediction: 0.8756992840277462/[0.47148743] </row>
		<row> train/prediction: 0.8757755730257486/[0.47148743] </row>
		<row> train/prediction: 0.8758518620236941/[0.47148743] </row>
		<row> train/prediction: 0.8759281510216965/[0.47148743] </row>
		<row> train/prediction: 0.8760044400196989/[0.47148743] </row>
		<row> train/prediction: 0.8760807290176444/[0.47148743] </row>
		<row> train/prediction: 0.8761570180156468/[0.47148743] </row>
		<row> train/prediction: 0.8762333070136492/[0.47148743] </row>
		<row> train/prediction: 0.8763095960115947/[0.47148743] </row>
		<row> train/prediction: 0.8763858850095971/[0.47148743] </row>
		<row> train/prediction: 0.8764621740075427/[0.47148743] </row>
		<row> train/prediction: 0.876538463005545/[0.47148743] </row>
		<row> train/prediction: 0.8766147520035474/[0.47148743] </row>
		<row> train/prediction: 0.876691041001493/[0.47148743] </row>
		<row> train/prediction: 0.8767673299994954/[0.47148743] </row>
		<row> train/prediction: 0.8768436189974977/[0.47148743] </row>
		<row> train/prediction: 0.8769199079954433/[0.47148743] </row>
		<row> train/prediction: 0.8769961969934457/[0.47148743] </row>
		<row> train/prediction: 0.877072485991448/[0.47148743] </row>
		<row> train/prediction: 0.8771487749893936/[0.47148743] </row>
		<row> train/prediction: 0.877225063987396/[0.47148743] </row>
		<row> train/prediction: 0.8773013529853984/[0.47148743] </row>
		<row> train/prediction: 0.8773776419833439/[0.47148743] </row>
		<row> train/prediction: 0.8774539309813463/[0.47148743] </row>
		<row> train/prediction: 0.8775302199792918/[0.47148743] </row>
		<row> train/prediction: 0.8776065089772942/[0.47148743] </row>
		<row> train/prediction: 0.8776827979752966/[0.47148743] </row>
		<row> train/prediction: 0.8777590869732421/[0.47148743] </row>
		<row> train/prediction: 0.8778353759712445/[0.47148743] </row>
		<row> train/prediction: 0.8779116649692469/[0.47148743] </row>
		<row> train/prediction: 0.8779879539671924/[0.47148743] </row>
		<row> train/prediction: 0.8780642429651948/[0.47148743] </row>
		<row> train/prediction: 0.8781405319631972/[0.47148743] </row>
		<row> train/prediction: 0.8782168209611427/[0.47148743] </row>
		<row> train/prediction: 0.8782931099591451/[0.47148743] </row>
		<row> train/prediction: 0.8783693989571475/[0.47148743] </row>
		<row> train/prediction: 0.878445687955093/[0.47148743] </row>
		<row> train/prediction: 0.8785219769530954/[0.47148743] </row>
		<row> train/prediction: 0.878598265951041/[0.47148743] </row>
		<row> train/prediction: 0.8786745549490433/[0.47148743] </row>
		<row> train/prediction: 0.8787508439470457/[0.47148743] </row>
		<row> train/prediction: 0.8788271329449913/[0.47148743] </row>
		<row> train/prediction: 0.8789034219429936/[0.47148743] </row>
		<row> train/prediction: 0.878979710940996/[0.47148743] </row>
		<row> train/prediction: 0.8790559999389416/[0.47148743] </row>
		<row> train/prediction: 0.879132288936944/[0.47148743] </row>
		<row> train/prediction: 0.8792085779349463/[0.47148743] </row>
		<row> train/prediction: 0.8792848669328919/[0.47148743] </row>
		<row> train/prediction: 0.8793611559308943/[0.47148743] </row>
		<row> train/prediction: 0.8794374449288966/[0.47148743] </row>
		<row> train/prediction: 0.8795137339268422/[0.47148743] </row>
		<row> train/prediction: 0.8795900229248446/[0.47148743] </row>
		<row> train/prediction: 0.8796663119228469/[0.47148743] </row>
		<row> train/prediction: 0.8797426009207925/[0.47148743] </row>
		<row> train/prediction: 0.8798188899187949/[0.47148743] </row>
		<row> train/prediction: 0.8798951789167404/[0.47148743] </row>
		<row> train/prediction: 0.8799714679147428/[0.47148743] </row>
		<row> train/prediction: 0.8800477569127452/[0.47148743] </row>
		<row> train/prediction: 0.8801240459106907/[0.47148743] </row>
		<row> train/prediction: 0.8802003349086931/[0.47148743] </row>
		<row> train/prediction: 0.8802766239066955/[0.47148743] </row>
		<row> train/prediction: 0.880352912904641/[0.47148743] </row>
		<row> train/prediction: 0.8804292019026434/[0.47148743] </row>
		<row> train/prediction: 0.8805054909006458/[0.47148743] </row>
		<row> train/prediction: 0.8805817798985913/[0.47148743] </row>
		<row> train/prediction: 0.8806580688965937/[0.47148743] </row>
		<row> train/prediction: 0.8807343578945961/[0.47148743] </row>
		<row> train/prediction: 0.8808106468925416/[0.47148743] </row>
		<row> train/prediction: 0.880886935890544/[0.47148743] </row>
		<row> train/prediction: 0.8809632248884895/[0.47148743] </row>
		<row> train/prediction: 0.8810395138864919/[0.47148743] </row>
		<row> train/prediction: 0.8811158028844943/[0.47148743] </row>
		<row> train/prediction: 0.8811920918824399/[0.47148743] </row>
		<row> train/prediction: 0.8812683808804422/[0.47148743] </row>
		<row> train/prediction: 0.8813446698784446/[0.47148743] </row>
		<row> train/prediction: 0.8814209588763902/[0.47148743] </row>
		<row> train/prediction: 0.8814972478743925/[0.47148743] </row>
		<row> train/prediction: 0.8815735368723949/[0.47148743] </row>
		<row> train/prediction: 0.8816498258703405/[0.47148743] </row>
		<row> train/prediction: 0.8817261148683428/[0.47148743] </row>
		<row> train/prediction: 0.8818024038663452/[0.47148743] </row>
		<row> train/prediction: 0.8818786928642908/[0.47148743] </row>
		<row> train/prediction: 0.8819549818622932/[0.47148743] </row>
		<row> train/prediction: 0.8820312708602387/[0.47148743] </row>
		<row> train/prediction: 0.8821075598582411/[0.47148743] </row>
		<row> train/prediction: 0.8821838488562435/[0.47148743] </row>
		<row> train/prediction: 0.882260137854189/[0.47148743] </row>
		<row> train/prediction: 0.8823364268521914/[0.47148743] </row>
		<row> train/prediction: 0.8824127158501938/[0.47148743] </row>
		<row> train/prediction: 0.8824890048481393/[0.47148743] </row>
		<row> train/prediction: 0.8825652938461417/[0.47148743] </row>
		<row> train/prediction: 0.8826415828441441/[0.47148743] </row>
		<row> train/prediction: 0.8827178718420896/[0.47148743] </row>
		<row> train/prediction: 0.882794160840092/[0.47148743] </row>
		<row> train/prediction: 0.8828704498380944/[0.47148743] </row>
		<row> train/prediction: 0.8829467388360399/[0.47148743] </row>
		<row> train/prediction: 0.8830230278340423/[0.47148743] </row>
		<row> train/prediction: 0.8830993168319878/[0.47148743] </row>
		<row> train/prediction: 0.8831756058299902/[0.47148743] </row>
		<row> train/prediction: 0.8832518948279926/[0.47148743] </row>
		<row> train/prediction: 0.8833281838259381/[0.47148743] </row>
		<row> train/prediction: 0.8834044728239405/[0.47148743] </row>
		<row> train/prediction: 0.8834807618219429/[0.47148743] </row>
		<row> train/prediction: 0.8835570508198884/[0.47148743] </row>
		<row> train/prediction: 0.8836333398178908/[0.47148743] </row>
		<row> train/prediction: 0.8837096288158932/[0.47148743] </row>
		<row> train/prediction: 0.8837859178138388/[0.47148743] </row>
		<row> train/prediction: 0.8838622068118411/[0.47148743] </row>
		<row> train/prediction: 0.8839384958098435/[0.47148743] </row>
		<row> train/prediction: 0.8840147848077891/[0.47148743] </row>
		<row> train/prediction: 0.8840910738057914/[0.47148743] </row>
		<row> train/prediction: 0.8841673628037938/[0.47148743] </row>
		<row> train/prediction: 0.8842436518017394/[0.47148743] </row>
		<row> train/prediction: 0.8843199407997417/[0.47148743] </row>
		<row> train/prediction: 0.8843962297976873/[0.47148743] </row>
		<row> train/prediction: 0.8844725187956897/[0.47148743] </row>
		<row> train/prediction: 0.884548807793692/[0.47148743] </row>
		<row> train/prediction: 0.8846250967916376/[0.47148743] </row>
		<row> train/prediction: 0.88470138578964/[0.47148743] </row>
		<row> train/prediction: 0.8847776747876424/[0.47148743] </row>
		<row> train/prediction: 0.8848539637855879/[0.47148743] </row>
		<row> train/prediction: 0.8849302527835903/[0.47148743] </row>
		<row> train/prediction: 0.8850065417815927/[0.47148743] </row>
		<row> train/prediction: 0.8850833393728976/[0.47148743] </row>
		<row> train/prediction: 0.8851596283708432/[0.47148743] </row>
		<row> train/prediction: 0.8852359173688455/[0.47148743] </row>
		<row> train/prediction: 0.8853122063667911/[0.47148743] </row>
		<row> train/prediction: 0.8853884953647935/[0.47148743] </row>
		<row> train/prediction: 0.8854647843627959/[0.47148743] </row>
		<row> train/prediction: 0.8855410733607414/[0.47148743] </row>
		<row> train/prediction: 0.8856173623587438/[0.47148743] </row>
		<row> train/prediction: 0.8856936513567462/[0.47148743] </row>
		<row> train/prediction: 0.8857699403546917/[0.47148743] </row>
		<row> train/prediction: 0.8858462293526941/[0.47148743] </row>
		<row> train/prediction: 0.8859225183506965/[0.47148743] </row>
		<row> train/prediction: 0.885998807348642/[0.47148743] </row>
		<row> train/prediction: 0.8860750963466444/[0.47148743] </row>
		<row> train/prediction: 0.8861513853446468/[0.47148743] </row>
		<row> train/prediction: 0.8862276743425923/[0.47148743] </row>
		<row> train/prediction: 0.8863039633405947/[0.47148743] </row>
		<row> train/prediction: 0.8863802523385402/[0.47148743] </row>
		<row> train/prediction: 0.8864565413365426/[0.47148743] </row>
		<row> train/prediction: 0.886532830334545/[0.47148743] </row>
		<row> train/prediction: 0.8866091193324905/[0.47148743] </row>
		<row> train/prediction: 0.8866854083304929/[0.47148743] </row>
		<row> train/prediction: 0.8867616973284953/[0.47148743] </row>
		<row> train/prediction: 0.8868379863264408/[0.47148743] </row>
		<row> train/prediction: 0.8869142753244432/[0.47148743] </row>
		<row> train/prediction: 0.8869905643224456/[0.47148743] </row>
		<row> train/prediction: 0.8870668533203911/[0.47148743] </row>
		<row> train/prediction: 0.8871431423183935/[0.47148743] </row>
		<row> train/prediction: 0.8872194313163959/[0.47148743] </row>
		<row> train/prediction: 0.8872957203143415/[0.47148743] </row>
		<row> train/prediction: 0.8873720093123438/[0.47148743] </row>
		<row> train/prediction: 0.8874482983103462/[0.47148743] </row>
		<row> train/prediction: 0.8875245873082918/[0.47148743] </row>
		<row> train/prediction: 0.8876008763062941/[0.47148743] </row>
		<row> train/prediction: 0.8876771653042397/[0.47148743] </row>
		<row> train/prediction: 0.8877534543022421/[0.47148743] </row>
		<row> train/prediction: 0.8878297433002444/[0.47148743] </row>
		<row> train/prediction: 0.88790603229819/[0.47148743] </row>
		<row> train/prediction: 0.8879823212961924/[0.47148743] </row>
		<row> train/prediction: 0.8880586102941948/[0.47148743] </row>
		<row> train/prediction: 0.8881348992921403/[0.47148743] </row>
		<row> train/prediction: 0.8882111882901427/[0.47148743] </row>
		<row> train/prediction: 0.888287477288145/[0.47148743] </row>
		<row> train/prediction: 0.8883637662860906/[0.47148743] </row>
		<row> train/prediction: 0.888440055284093/[0.47148743] </row>
		<row> train/prediction: 0.8885163442820954/[0.47148743] </row>
		<row> train/prediction: 0.8885926332800409/[0.47148743] </row>
		<row> train/prediction: 0.8886689222780433/[0.47148743] </row>
		<row> train/prediction: 0.8887452112759888/[0.47148743] </row>
		<row> train/prediction: 0.8888215002739912/[0.47148743] </row>
		<row> train/prediction: 0.8888977892719936/[0.47148743] </row>
		<row> train/prediction: 0.8889740782699391/[0.47148743] </row>
		<row> train/prediction: 0.8890503672679415/[0.47148743] </row>
		<row> train/prediction: 0.8891266562659439/[0.47148743] </row>
		<row> train/prediction: 0.8892029452638894/[0.47148743] </row>
		<row> train/prediction: 0.8892792342618918/[0.47148743] </row>
		<row> train/prediction: 0.8893555232598942/[0.47148743] </row>
		<row> train/prediction: 0.8894318122578397/[0.47148743] </row>
		<row> train/prediction: 0.8895081012558421/[0.47148743] </row>
		<row> train/prediction: 0.8895843902538445/[0.47148743] </row>
		<row> train/prediction: 0.88966067925179/[0.47148743] </row>
		<row> train/prediction: 0.8897369682497924/[0.47148743] </row>
		<row> train/prediction: 0.889813257247738/[0.47148743] </row>
		<row> train/prediction: 0.8898895462457403/[0.47148743] </row>
		<row> train/prediction: 0.8899658352437427/[0.47148743] </row>
		<row> train/prediction: 0.8900421242416883/[0.47148743] </row>
		<row> train/prediction: 0.8901184132396907/[0.47148743] </row>
		<row> train/prediction: 0.890194702237693/[0.47148743] </row>
		<row> train/prediction: 0.8902709912356386/[0.47148743] </row>
		<row> train/prediction: 0.890347280233641/[0.47148743] </row>
		<row> train/prediction: 0.8904235692316433/[0.47148743] </row>
		<row> train/prediction: 0.8904998582295889/[0.47148743] </row>
		<row> train/prediction: 0.8905764015242426/[0.47148743] </row>
		<row> train/prediction: 0.8906526905222449/[0.47148743] </row>
		<row> train/prediction: 0.8907289795201905/[0.47148743] </row>
		<row> train/prediction: 0.8908052685181929/[0.47148743] </row>
		<row> train/prediction: 0.8908815575161952/[0.47148743] </row>
		<row> train/prediction: 0.8909578465141408/[0.47148743] </row>
		<row> train/prediction: 0.8910341355121432/[0.47148743] </row>
		<row> train/prediction: 0.8911104245101455/[0.47148743] </row>
		<row> train/prediction: 0.8911867135080911/[0.47148743] </row>
		<row> train/prediction: 0.8912630025060935/[0.47148743] </row>
		<row> train/prediction: 0.8913392915040959/[0.47148743] </row>
		<row> train/prediction: 0.8914155805020414/[0.47148743] </row>
		<row> train/prediction: 0.8914918695000438/[0.47148743] </row>
		<row> train/prediction: 0.8915681584979893/[0.47148743] </row>
		<row> train/prediction: 0.8916444474959917/[0.47148743] </row>
		<row> train/prediction: 0.8917207364939941/[0.47148743] </row>
		<row> train/prediction: 0.8917970254919396/[0.47148743] </row>
		<row> train/prediction: 0.891873314489942/[0.47148743] </row>
		<row> train/prediction: 0.8919496034879444/[0.47148743] </row>
		<row> train/prediction: 0.8920258924858899/[0.47148743] </row>
		<row> train/prediction: 0.8921021814838923/[0.47148743] </row>
		<row> train/prediction: 0.8921784704818947/[0.47148743] </row>
		<row> train/prediction: 0.8922547594798402/[0.47148743] </row>
		<row> train/prediction: 0.8923310484778426/[0.47148743] </row>
		<row> train/prediction: 0.892407337475845/[0.47148743] </row>
		<row> train/prediction: 0.8924836264737905/[0.47148743] </row>
		<row> train/prediction: 0.8925599154717929/[0.47148743] </row>
		<row> train/prediction: 0.8926362044697385/[0.47148743] </row>
		<row> train/prediction: 0.8927124934677408/[0.47148743] </row>
		<row> train/prediction: 0.8927887824657432/[0.47148743] </row>
		<row> train/prediction: 0.8928650714636888/[0.47148743] </row>
		<row> train/prediction: 0.8929413604616911/[0.47148743] </row>
		<row> train/prediction: 0.8930176494596935/[0.47148743] </row>
		<row> train/prediction: 0.8930939384576391/[0.47148743] </row>
		<row> train/prediction: 0.8931702274556415/[0.47148743] </row>
		<row> train/prediction: 0.8932465164536438/[0.47148743] </row>
		<row> train/prediction: 0.8933228054515894/[0.47148743] </row>
		<row> train/prediction: 0.8933990944495918/[0.47148743] </row>
		<row> train/prediction: 0.8934753834475941/[0.47148743] </row>
		<row> train/prediction: 0.8935516724455397/[0.47148743] </row>
		<row> train/prediction: 0.8936279614435421/[0.47148743] </row>
		<row> train/prediction: 0.8937042504414876/[0.47148743] </row>
		<row> train/prediction: 0.89378053943949/[0.47148743] </row>
		<row> train/prediction: 0.8938568284374924/[0.47148743] </row>
		<row> train/prediction: 0.8939331174354379/[0.47148743] </row>
		<row> train/prediction: 0.8940094064334403/[0.47148743] </row>
		<row> train/prediction: 0.8940856954314427/[0.47148743] </row>
		<row> train/prediction: 0.8941619844293882/[0.47148743] </row>
		<row> train/prediction: 0.8942382734273906/[0.47148743] </row>
		<row> train/prediction: 0.894314562425393/[0.47148743] </row>
		<row> train/prediction: 0.8943908514233385/[0.47148743] </row>
		<row> train/prediction: 0.8944671404213409/[0.47148743] </row>
		<row> train/prediction: 0.8945434294193433/[0.47148743] </row>
		<row> train/prediction: 0.8946197184172888/[0.47148743] </row>
		<row> train/prediction: 0.8946960074152912/[0.47148743] </row>
		<row> train/prediction: 0.8947722964132936/[0.47148743] </row>
		<row> train/prediction: 0.8948485854112391/[0.47148743] </row>
		<row> train/prediction: 0.8949248744092415/[0.47148743] </row>
		<row> train/prediction: 0.895001163407187/[0.47148743] </row>
		<row> train/prediction: 0.8950774524051894/[0.47148743] </row>
		<row> train/prediction: 0.8951537414031918/[0.47148743] </row>
		<row> train/prediction: 0.8952300304011374/[0.47148743] </row>
		<row> train/prediction: 0.8953063193991397/[0.47148743] </row>
		<row> train/prediction: 0.8953826083971421/[0.47148743] </row>
		<row> train/prediction: 0.8954588973950877/[0.47148743] </row>
		<row> train/prediction: 0.89553518639309/[0.47148743] </row>
		<row> train/prediction: 0.8956114753910924/[0.47148743] </row>
		<row> train/prediction: 0.895687764389038/[0.47148743] </row>
		<row> train/prediction: 0.8957640533870403/[0.47148743] </row>
		<row> train/prediction: 0.8958403423850427/[0.47148743] </row>
		<row> train/prediction: 0.8959166313829883/[0.47148743] </row>
		<row> train/prediction: 0.8959929203809907/[0.47148743] </row>
		<row> train/prediction: 0.8960694636756443/[0.47148743] </row>
		<row> train/prediction: 0.8961457526735899/[0.47148743] </row>
		<row> train/prediction: 0.8962220416715923/[0.47148743] </row>
		<row> train/prediction: 0.8962983306695946/[0.47148743] </row>
		<row> train/prediction: 0.8963746196675402/[0.47148743] </row>
		<row> train/prediction: 0.8964509086655426/[0.47148743] </row>
		<row> train/prediction: 0.8965271976634881/[0.47148743] </row>
		<row> train/prediction: 0.8966034866614905/[0.47148743] </row>
		<row> train/prediction: 0.8966797756594929/[0.47148743] </row>
		<row> train/prediction: 0.8967560646574384/[0.47148743] </row>
		<row> train/prediction: 0.8968323536554408/[0.47148743] </row>
		<row> train/prediction: 0.8969086426534432/[0.47148743] </row>
		<row> train/prediction: 0.8969849316513887/[0.47148743] </row>
		<row> train/prediction: 0.8970612206493911/[0.47148743] </row>
		<row> train/prediction: 0.8971375096473935/[0.47148743] </row>
		<row> train/prediction: 0.897213798645339/[0.47148743] </row>
		<row> train/prediction: 0.8972900876433414/[0.47148743] </row>
		<row> train/prediction: 0.8973663766413438/[0.47148743] </row>
		<row> train/prediction: 0.8974426656392893/[0.47148743] </row>
		<row> train/prediction: 0.8975189546372917/[0.47148743] </row>
		<row> train/prediction: 0.8975952436352372/[0.47148743] </row>
		<row> train/prediction: 0.8976715326332396/[0.47148743] </row>
		<row> train/prediction: 0.897747821631242/[0.47148743] </row>
		<row> train/prediction: 0.8978241106291875/[0.47148743] </row>
		<row> train/prediction: 0.8979003996271899/[0.47148743] </row>
		<row> train/prediction: 0.8979766886251923/[0.47148743] </row>
		<row> train/prediction: 0.8980529776231378/[0.47148743] </row>
		<row> train/prediction: 0.8981292666211402/[0.47148743] </row>
		<row> train/prediction: 0.8982055556191426/[0.47148743] </row>
		<row> train/prediction: 0.8982818446170882/[0.47148743] </row>
		<row> train/prediction: 0.8983581336150905/[0.47148743] </row>
		<row> train/prediction: 0.8984344226130929/[0.47148743] </row>
		<row> train/prediction: 0.8985107116110385/[0.47148743] </row>
		<row> train/prediction: 0.8985870006090408/[0.47148743] </row>
		<row> train/prediction: 0.8986632896070432/[0.47148743] </row>
		<row> train/prediction: 0.8987395786049888/[0.47148743] </row>
		<row> train/prediction: 0.8988158676029911/[0.47148743] </row>
		<row> train/prediction: 0.8988921566009367/[0.47148743] </row>
		<row> train/prediction: 0.8989684455989391/[0.47148743] </row>
		<row> train/prediction: 0.8990447345969415/[0.47148743] </row>
		<row> train/prediction: 0.899121023594887/[0.47148743] </row>
		<row> train/prediction: 0.8991973125928894/[0.47148743] </row>
		<row> train/prediction: 0.8992736015908918/[0.47148743] </row>
		<row> train/prediction: 0.8993498905888373/[0.47148743] </row>
		<row> train/prediction: 0.8994261795868397/[0.47148743] </row>
		<row> train/prediction: 0.8995024685848421/[0.47148743] </row>
		<row> train/prediction: 0.8995787575827876/[0.47148743] </row>
		<row> train/prediction: 0.89965504658079/[0.47148743] </row>
		<row> train/prediction: 0.8997313355787924/[0.47148743] </row>
		<row> train/prediction: 0.8998076245767379/[0.47148743] </row>
		<row> train/prediction: 0.8998839135747403/[0.47148743] </row>
		<row> train/prediction: 0.8999602025726858/[0.47148743] </row>
		<row> train/prediction: 0.9000364915706882/[0.47148743] </row>
		<row> train/prediction: 0.9001127805686906/[0.47148743] </row>
		<row> train/prediction: 0.9001890695666361/[0.47148743] </row>
		<row> train/prediction: 0.9002653585646385/[0.47148743] </row>
		<row> train/prediction: 0.9003416475626409/[0.47148743] </row>
		<row> train/prediction: 0.9004179365605864/[0.47148743] </row>
		<row> train/prediction: 0.9004942255585888/[0.47148743] </row>
		<row> train/prediction: 0.9005705145565912/[0.47148743] </row>
		<row> train/prediction: 0.9006468035545367/[0.47148743] </row>
		<row> train/prediction: 0.9007230925525391/[0.47148743] </row>
		<row> train/prediction: 0.9007993815505415/[0.47148743] </row>
		<row> train/prediction: 0.900875670548487/[0.47148743] </row>
		<row> train/prediction: 0.9009519595464894/[0.47148743] </row>
		<row> train/prediction: 0.901028248544435/[0.47148743] </row>
		<row> train/prediction: 0.9011045375424374/[0.47148743] </row>
		<row> train/prediction: 0.9011808265404397/[0.47148743] </row>
		<row> train/prediction: 0.9012571155383853/[0.47148743] </row>
		<row> train/prediction: 0.9013334045363877/[0.47148743] </row>
		<row> train/prediction: 0.90140969353439/[0.47148743] </row>
		<row> train/prediction: 0.9014859825323356/[0.47148743] </row>
		<row> train/prediction: 0.9015625258269893/[0.47148743] </row>
		<row> train/prediction: 0.9016388148249916/[0.47148743] </row>
		<row> train/prediction: 0.9017151038229372/[0.47148743] </row>
		<row> train/prediction: 0.9017913928209396/[0.47148743] </row>
		<row> train/prediction: 0.901867681818942/[0.47148743] </row>
		<row> train/prediction: 0.9019439708168875/[0.47148743] </row>
		<row> train/prediction: 0.9020202598148899/[0.47148743] </row>
		<row> train/prediction: 0.9020965488128923/[0.47148743] </row>
		<row> train/prediction: 0.9021728378108378/[0.47148743] </row>
		<row> train/prediction: 0.9022491268088402/[0.47148743] </row>
		<row> train/prediction: 0.9023254158068426/[0.47148743] </row>
		<row> train/prediction: 0.9024017048047881/[0.47148743] </row>
		<row> train/prediction: 0.9024779938027905/[0.47148743] </row>
		<row> train/prediction: 0.9025542828007929/[0.47148743] </row>
		<row> train/prediction: 0.9026305717987384/[0.47148743] </row>
		<row> train/prediction: 0.9027068607967408/[0.47148743] </row>
		<row> train/prediction: 0.9027831497946863/[0.47148743] </row>
		<row> train/prediction: 0.9028594387926887/[0.47148743] </row>
		<row> train/prediction: 0.9029357277906911/[0.47148743] </row>
		<row> train/prediction: 0.9030120167886366/[0.47148743] </row>
		<row> train/prediction: 0.903088305786639/[0.47148743] </row>
		<row> train/prediction: 0.9031645947846414/[0.47148743] </row>
		<row> train/prediction: 0.9032408837825869/[0.47148743] </row>
		<row> train/prediction: 0.9033171727805893/[0.47148743] </row>
		<row> train/prediction: 0.9033934617785917/[0.47148743] </row>
		<row> train/prediction: 0.9034697507765372/[0.47148743] </row>
		<row> train/prediction: 0.9035460397745396/[0.47148743] </row>
		<row> train/prediction: 0.903622328772542/[0.47148743] </row>
		<row> train/prediction: 0.9036986177704875/[0.47148743] </row>
		<row> train/prediction: 0.9037749067684899/[0.47148743] </row>
		<row> train/prediction: 0.9038511957664355/[0.47148743] </row>
		<row> train/prediction: 0.9039274847644378/[0.47148743] </row>
		<row> train/prediction: 0.9040037737624402/[0.47148743] </row>
		<row> train/prediction: 0.9040800627603858/[0.47148743] </row>
		<row> train/prediction: 0.9041563517583882/[0.47148743] </row>
		<row> train/prediction: 0.9042326407563905/[0.47148743] </row>
		<row> train/prediction: 0.9043089297543361/[0.47148743] </row>
		<row> train/prediction: 0.9043852187523385/[0.47148743] </row>
		<row> train/prediction: 0.9044615077503408/[0.47148743] </row>
		<row> train/prediction: 0.9045377967482864/[0.47148743] </row>
		<row> train/prediction: 0.9046140857462888/[0.47148743] </row>
		<row> train/prediction: 0.9046903747442911/[0.47148743] </row>
		<row> train/prediction: 0.9047666637422367/[0.47148743] </row>
		<row> train/prediction: 0.9048429527402391/[0.47148743] </row>
		<row> train/prediction: 0.9049192417381846/[0.47148743] </row>
		<row> train/prediction: 0.904995530736187/[0.47148743] </row>
		<row> train/prediction: 0.9050718197341894/[0.47148743] </row>
		<row> train/prediction: 0.9051481087321349/[0.47148743] </row>
		<row> train/prediction: 0.9052243977301373/[0.47148743] </row>
		<row> train/prediction: 0.9053006867281397/[0.47148743] </row>
		<row> train/prediction: 0.9053769757260852/[0.47148743] </row>
		<row> train/prediction: 0.9054532647240876/[0.47148743] </row>
		<row> train/prediction: 0.90552955372209/[0.47148743] </row>
		<row> train/prediction: 0.9056058427200355/[0.47148743] </row>
		<row> train/prediction: 0.9056821317180379/[0.47148743] </row>
		<row> train/prediction: 0.9057584207160403/[0.47148743] </row>
		<row> train/prediction: 0.9058347097139858/[0.47148743] </row>
		<row> train/prediction: 0.9059109987119882/[0.47148743] </row>
		<row> train/prediction: 0.9059872877099906/[0.47148743] </row>
		<row> train/prediction: 0.9060635767079361/[0.47148743] </row>
		<row> train/prediction: 0.9061398657059385/[0.47148743] </row>
		<row> train/prediction: 0.9062161547038841/[0.47148743] </row>
		<row> train/prediction: 0.9062924437018864/[0.47148743] </row>
		<row> train/prediction: 0.9063687326998888/[0.47148743] </row>
		<row> train/prediction: 0.9064450216978344/[0.47148743] </row>
		<row> train/prediction: 0.9065213106958367/[0.47148743] </row>
		<row> train/prediction: 0.9065975996938391/[0.47148743] </row>
		<row> train/prediction: 0.9066738886917847/[0.47148743] </row>
		<row> train/prediction: 0.906750177689787/[0.47148743] </row>
		<row> train/prediction: 0.9068264666877894/[0.47148743] </row>
		<row> train/prediction: 0.906902755685735/[0.47148743] </row>
		<row> train/prediction: 0.9069790446837374/[0.47148743] </row>
		<row> train/prediction: 0.907055587978391/[0.47148743] </row>
		<row> train/prediction: 0.9071318769763366/[0.47148743] </row>
		<row> train/prediction: 0.907208165974339/[0.47148743] </row>
		<row> train/prediction: 0.9072844549723413/[0.47148743] </row>
		<row> train/prediction: 0.9073607439702869/[0.47148743] </row>
		<row> train/prediction: 0.9074370329682893/[0.47148743] </row>
		<row> train/prediction: 0.9075133219662916/[0.47148743] </row>
		<row> train/prediction: 0.9075896109642372/[0.47148743] </row>
		<row> train/prediction: 0.9076658999622396/[0.47148743] </row>
		<row> train/prediction: 0.9077421889601851/[0.47148743] </row>
		<row> train/prediction: 0.9078184779581875/[0.47148743] </row>
		<row> train/prediction: 0.9078947669561899/[0.47148743] </row>
		<row> train/prediction: 0.9079710559541354/[0.47148743] </row>
		<row> train/prediction: 0.9080473449521378/[0.47148743] </row>
		<row> train/prediction: 0.9081236339501402/[0.47148743] </row>
		<row> train/prediction: 0.9081999229480857/[0.47148743] </row>
		<row> train/prediction: 0.9082762119460881/[0.47148743] </row>
		<row> train/prediction: 0.9083525009440905/[0.47148743] </row>
		<row> train/prediction: 0.908428789942036/[0.47148743] </row>
		<row> train/prediction: 0.9085050789400384/[0.47148743] </row>
		<row> train/prediction: 0.9085813679380408/[0.47148743] </row>
		<row> train/prediction: 0.9086576569359863/[0.47148743] </row>
		<row> train/prediction: 0.9087339459339887/[0.47148743] </row>
		<row> train/prediction: 0.9088102349319342/[0.47148743] </row>
		<row> train/prediction: 0.9088865239299366/[0.47148743] </row>
		<row> train/prediction: 0.908962812927939/[0.47148743] </row>
		<row> train/prediction: 0.9090391019258846/[0.47148743] </row>
		<row> train/prediction: 0.9091153909238869/[0.47148743] </row>
		<row> train/prediction: 0.9091916799218893/[0.47148743] </row>
		<row> train/prediction: 0.9092679689198349/[0.47148743] </row>
		<row> train/prediction: 0.9093442579178372/[0.47148743] </row>
		<row> train/prediction: 0.9094205469158396/[0.47148743] </row>
		<row> train/prediction: 0.9094968359137852/[0.47148743] </row>
		<row> train/prediction: 0.9095731249117875/[0.47148743] </row>
		<row> train/prediction: 0.9096494139097899/[0.47148743] </row>
		<row> train/prediction: 0.9097257029077355/[0.47148743] </row>
		<row> train/prediction: 0.9098019919057379/[0.47148743] </row>
		<row> train/prediction: 0.9098782809037402/[0.47148743] </row>
		<row> train/prediction: 0.9099545699016858/[0.47148743] </row>
		<row> train/prediction: 0.9100308588996882/[0.47148743] </row>
		<row> train/prediction: 0.9101071478976337/[0.47148743] </row>
		<row> train/prediction: 0.9101834368956361/[0.47148743] </row>
		<row> train/prediction: 0.9102597258936385/[0.47148743] </row>
		<row> train/prediction: 0.910336014891584/[0.47148743] </row>
		<row> train/prediction: 0.9104123038895864/[0.47148743] </row>
		<row> train/prediction: 0.9104885928875888/[0.47148743] </row>
		<row> train/prediction: 0.9105648818855343/[0.47148743] </row>
		<row> train/prediction: 0.9106411708835367/[0.47148743] </row>
		<row> train/prediction: 0.9107174598815391/[0.47148743] </row>
		<row> train/prediction: 0.9107937488794846/[0.47148743] </row>
		<row> train/prediction: 0.910870037877487/[0.47148743] </row>
		<row> train/prediction: 0.9109463268754894/[0.47148743] </row>
		<row> train/prediction: 0.9110226158734349/[0.47148743] </row>
		<row> train/prediction: 0.9110989048714373/[0.47148743] </row>
		<row> train/prediction: 0.9111751938693828/[0.47148743] </row>
		<row> train/prediction: 0.9112514828673852/[0.47148743] </row>
		<row> train/prediction: 0.9113277718653876/[0.47148743] </row>
		<row> train/prediction: 0.9114040608633331/[0.47148743] </row>
		<row> train/prediction: 0.9114803498613355/[0.47148743] </row>
		<row> train/prediction: 0.9115566388593379/[0.47148743] </row>
		<row> train/prediction: 0.9116329278572834/[0.47148743] </row>
		<row> train/prediction: 0.9117092168552858/[0.47148743] </row>
		<row> train/prediction: 0.9117855058532882/[0.47148743] </row>
		<row> train/prediction: 0.9118617948512338/[0.47148743] </row>
		<row> train/prediction: 0.9119380838492361/[0.47148743] </row>
		<row> train/prediction: 0.9120143728472385/[0.47148743] </row>
		<row> train/prediction: 0.9120906618451841/[0.47148743] </row>
		<row> train/prediction: 0.9121669508431864/[0.47148743] </row>
		<row> train/prediction: 0.912243239841132/[0.47148743] </row>
		<row> train/prediction: 0.9123195288391344/[0.47148743] </row>
		<row> train/prediction: 0.9123958178371367/[0.47148743] </row>
		<row> train/prediction: 0.9124721068350823/[0.47148743] </row>
		<row> train/prediction: 0.912548650129736/[0.47148743] </row>
		<row> train/prediction: 0.9126249391277383/[0.47148743] </row>
		<row> train/prediction: 0.9127012281256839/[0.47148743] </row>
		<row> train/prediction: 0.9127775171236863/[0.47148743] </row>
		<row> train/prediction: 0.9128538061216886/[0.47148743] </row>
		<row> train/prediction: 0.9129300951196342/[0.47148743] </row>
		<row> train/prediction: 0.9130063841176366/[0.47148743] </row>
		<row> train/prediction: 0.913082673115639/[0.47148743] </row>
		<row> train/prediction: 0.9131589621135845/[0.47148743] </row>
		<row> train/prediction: 0.9132352511115869/[0.47148743] </row>
		<row> train/prediction: 0.9133115401095893/[0.47148743] </row>
		<row> train/prediction: 0.9133878291075348/[0.47148743] </row>
		<row> train/prediction: 0.9134641181055372/[0.47148743] </row>
		<row> train/prediction: 0.9135404071035396/[0.47148743] </row>
		<row> train/prediction: 0.9136166961014851/[0.47148743] </row>
		<row> train/prediction: 0.9136929850994875/[0.47148743] </row>
		<row> train/prediction: 0.9137692740974899/[0.47148743] </row>
		<row> train/prediction: 0.9138455630954354/[0.47148743] </row>
		<row> train/prediction: 0.9139218520934378/[0.47148743] </row>
		<row> train/prediction: 0.9139981410913833/[0.47148743] </row>
		<row> train/prediction: 0.9140744300893857/[0.47148743] </row>
		<row> train/prediction: 0.9141507190873881/[0.47148743] </row>
		<row> train/prediction: 0.9142270080853336/[0.47148743] </row>
		<row> train/prediction: 0.914303297083336/[0.47148743] </row>
		<row> train/prediction: 0.9143795860813384/[0.47148743] </row>
		<row> train/prediction: 0.9144558750792839/[0.47148743] </row>
		<row> train/prediction: 0.9145321640772863/[0.47148743] </row>
		<row> train/prediction: 0.9146084530752887/[0.47148222] </row>
		<row> train/prediction: 0.9146847420732342/[0.47147536] </row>
		<row> train/prediction: 0.9147610310712366/[0.47145966] </row>
		<row> train/prediction: 0.914837320069239/[0.47145283] </row>
		<row> train/prediction: 0.9149136090671846/[0.47145423] </row>
		<row> train/prediction: 0.9149898980651869/[0.47145367] </row>
		<row> train/prediction: 0.9150661870631325/[0.47146282] </row>
		<row> train/prediction: 0.9151424760611349/[0.4714646] </row>
		<row> train/prediction: 0.9152187650591372/[0.47146225] </row>
		<row> train/prediction: 0.9152950540570828/[0.47146535] </row>
		<row> train/prediction: 0.9153713430550852/[0.47146297] </row>
		<row> train/prediction: 0.9154476320530875/[0.4714733] </row>
		<row> train/prediction: 0.9155239210510331/[0.47148556] </row>
		<row> train/prediction: 0.9156002100490355/[0.47148743] </row>
		<row> train/prediction: 0.9156764990470379/[0.47148743] </row>
		<row> train/prediction: 0.9157527880449834/[0.47148743] </row>
		<row> train/prediction: 0.9158290770429858/[0.47148743] </row>
		<row> train/prediction: 0.9159053660409882/[0.47148743] </row>
		<row> train/prediction: 0.9198729025293346/[0.47148743] </row>
		<row> train/prediction: 0.919949191527337/[0.47148743] </row>
		<row> train/prediction: 0.9200254805253394/[0.47148743] </row>
		<row> train/prediction: 0.9201017695232849/[0.47148743] </row>
		<row> train/prediction: 0.9201780585212873/[0.47148743] </row>
		<row> train/prediction: 0.9202543475192897/[0.47148743] </row>
		<row> train/prediction: 0.9203306365172352/[0.47148743] </row>
		<row> train/prediction: 0.9204069255152376/[0.47148743] </row>
		<row> train/prediction: 0.92048321451324/[0.47148743] </row>
		<row> train/prediction: 0.9205595035111855/[0.47148743] </row>
		<row> train/prediction: 0.9206357925091879/[0.47148743] </row>
		<row> train/prediction: 0.9207120815071335/[0.47148743] </row>
		<row> train/prediction: 0.9207883705051358/[0.47148743] </row>
		<row> train/prediction: 0.9208646595031382/[0.47148743] </row>
		<row> train/prediction: 0.9209409485010838/[0.47148743] </row>
		<row> train/prediction: 0.9210172374990861/[0.47148743] </row>
		<row> train/prediction: 0.9210935264970885/[0.47148743] </row>
		<row> train/prediction: 0.9211698154950341/[0.47148743] </row>
		<row> train/prediction: 0.9212461044930365/[0.47148743] </row>
		<row> train/prediction: 0.9213223934910388/[0.47148743] </row>
		<row> train/prediction: 0.9213986824889844/[0.47148743] </row>
		<row> train/prediction: 0.9214749714869868/[0.47148743] </row>
		<row> train/prediction: 0.9215512604849891/[0.47148743] </row>
		<row> train/prediction: 0.9216275494829347/[0.47148743] </row>
		<row> train/prediction: 0.9217038384809371/[0.47148743] </row>
		<row> train/prediction: 0.9217801274788826/[0.47148743] </row>
		<row> train/prediction: 0.921856416476885/[0.47148743] </row>
		<row> train/prediction: 0.9219327054748874/[0.47148743] </row>
		<row> train/prediction: 0.9220089944728329/[0.47148743] </row>
		<row> train/prediction: 0.9220852834708353/[0.47148743] </row>
		<row> train/prediction: 0.9221615724688377/[0.47148743] </row>
		<row> train/prediction: 0.9222378614667832/[0.4714967] </row>
		<row> train/prediction: 0.9223141504647856/[0.47149438] </row>
		<row> train/prediction: 0.922390439462788/[0.47149107] </row>
		<row> train/prediction: 0.9224667284607335/[0.47149286] </row>
		<row> train/prediction: 0.9225430174587359/[0.47149643] </row>
		<row> train/prediction: 0.9226193064567383/[0.47148943] </row>
		<row> train/prediction: 0.9226955954546838/[0.47148743] </row>
		<row> train/prediction: 0.9227718844526862/[0.47148743] </row>
		<row> train/prediction: 0.9228481734506317/[0.47148743] </row>
		<row> train/prediction: 0.9229244624486341/[0.47148743] </row>
		<row> train/prediction: 0.9230007514466365/[0.47148743] </row>
		<row> train/prediction: 0.923077040444582/[0.47147316] </row>
		<row> train/prediction: 0.9231533294425844/[0.4714721] </row>
		<row> train/prediction: 0.9232296184405868/[0.47147134] </row>
		<row> train/prediction: 0.9233059074385324/[0.47144103] </row>
		<row> train/prediction: 0.9233821964365347/[0.47131494] </row>
		<row> train/prediction: 0.9234584854345371/[0.47128478] </row>
		<row> train/prediction: 0.9235347744324827/[0.47116938] </row>
		<row> train/prediction: 0.923611063430485/[0.47127202] </row>
		<row> train/prediction: 0.9236873524284874/[0.47147644] </row>
		<row> train/prediction: 0.923763641426433/[0.47155842] </row>
		<row> train/prediction: 0.9238399304244354/[0.4716483] </row>
		<row> train/prediction: 0.9239162194223809/[0.47167543] </row>
		<row> train/prediction: 0.9239925084203833/[0.47176147] </row>
		<row> train/prediction: 0.9240687974183857/[0.47189876] </row>
		<row> train/prediction: 0.9241450864163312/[0.47197065] </row>
		<row> train/prediction: 0.9242213754143336/[0.4719897] </row>
		<row> train/prediction: 0.924297664412336/[0.47202522] </row>
		<row> train/prediction: 0.9243739534102815/[0.4720896] </row>
		<row> train/prediction: 0.9244502424082839/[0.47193635] </row>
		<row> train/prediction: 0.9245265314062863/[0.47182712] </row>
		<row> train/prediction: 0.9246028204042318/[0.4715997] </row>
		<row> train/prediction: 0.9246791094022342/[0.47139174] </row>
		<row> train/prediction: 0.9247553984002366/[0.47145241] </row>
		<row> train/prediction: 0.9248316873981821/[0.47142392] </row>
		<row> train/prediction: 0.9249079763961845/[0.47146133] </row>
		<row> train/prediction: 0.9249842653941869/[0.4713826] </row>
		<row> train/prediction: 0.9250605543921324/[0.47158238] </row>
		<row> train/prediction: 0.9251368433901348/[0.4716575] </row>
		<row> train/prediction: 0.9252131323880803/[0.4715987] </row>
		<row> train/prediction: 0.9252894213860827/[0.47161388] </row>
		<row> train/prediction: 0.9253657103840851/[0.47149178] </row>
		<row> train/prediction: 0.9254419993820306/[0.4715103] </row>
		<row> train/prediction: 0.925518288380033/[0.4715526] </row>
		<row> train/prediction: 0.9255945773780354/[0.4715188] </row>
		<row> train/prediction: 0.925670866375981/[0.4716345] </row>
		<row> train/prediction: 0.9257471553739833/[0.47163343] </row>
		<row> train/prediction: 0.9258234443719857/[0.4715634] </row>
		<row> train/prediction: 0.9258997333699313/[0.47151962] </row>
		<row> train/prediction: 0.9259760223679336/[0.47153127] </row>
		<row> train/prediction: 0.926052311365936/[0.47145736] </row>
		<row> train/prediction: 0.9261286003638816/[0.47148743] </row>
		<row> train/prediction: 0.9262048893618839/[0.47148743] </row>
		<row> train/prediction: 0.9262811783598295/[0.47148767] </row>
		<row> train/prediction: 0.9263574673578319/[0.47149372] </row>
		<row> train/prediction: 0.9264337563558342/[0.47149232] </row>
		<row> train/prediction: 0.9265100453537798/[0.47148743] </row>
		<row> train/prediction: 0.9265863343517822/[0.47148743] </row>
		<row> train/prediction: 0.9266626233497846/[0.47148743] </row>
		<row> train/prediction: 0.9267389123477301/[0.47148743] </row>
		<row> train/prediction: 0.9268152013457325/[0.47148743] </row>
		<row> train/prediction: 0.9268914903437349/[0.47148743] </row>
		<row> train/prediction: 0.9269677793416804/[0.47148743] </row>
		<row> train/prediction: 0.9270440683396828/[0.47148743] </row>
		<row> train/prediction: 0.9271203573376852/[0.47148743] </row>
		<row> train/prediction: 0.9271966463356307/[0.47148743] </row>
		<row> train/prediction: 0.9272729353336331/[0.47148743] </row>
		<row> train/prediction: 0.9273492243315786/[0.47148743] </row>
		<row> train/prediction: 0.927425513329581/[0.4714965] </row>
		<row> train/prediction: 0.9275018023275834/[0.47150737] </row>
		<row> train/prediction: 0.9275780913255289/[0.4715061] </row>
		<row> train/prediction: 0.9276543803235313/[0.4715048] </row>
		<row> train/prediction: 0.9277306693215337/[0.4715061] </row>
		<row> train/prediction: 0.9278069583194792/[0.4714984] </row>
		<row> train/prediction: 0.9278832473174816/[0.47147337] </row>
		<row> train/prediction: 0.927959536315484/[0.47149184] </row>
		<row> train/prediction: 0.9280358253134295/[0.4714708] </row>
		<row> train/prediction: 0.9281121143114319/[0.47142655] </row>
		<row> train/prediction: 0.9281884033094343/[0.47138548] </row>
		<row> train/prediction: 0.9282646923073798/[0.47135964] </row>
		<row> train/prediction: 0.9283409813053822/[0.47137386] </row>
		<row> train/prediction: 0.9284172703033278/[0.47137144] </row>
		<row> train/prediction: 0.9284935593013302/[0.4714196] </row>
		<row> train/prediction: 0.9285698482993325/[0.47142273] </row>
		<row> train/prediction: 0.9286461372972781/[0.47145095] </row>
		<row> train/prediction: 0.9287224262952805/[0.47144744] </row>
		<row> train/prediction: 0.9287987152932828/[0.47144693] </row>
		<row> train/prediction: 0.9288750042912284/[0.4714626] </row>
		<row> train/prediction: 0.9289512932892308/[0.47148743] </row>
		<row> train/prediction: 0.9290278365838844/[0.47148743] </row>
		<row> train/prediction: 0.92910412558183/[0.47148743] </row>
		<row> train/prediction: 0.9291804145798324/[0.47148743] </row>
		<row> train/prediction: 0.9292567035778347/[0.47148743] </row>
		<row> train/prediction: 0.9293329925757803/[0.47148743] </row>
		<row> train/prediction: 0.9294092815737827/[0.47148743] </row>
		<row> train/prediction: 0.929485570571785/[0.47148743] </row>
		<row> train/prediction: 0.9295618595697306/[0.47148743] </row>
		<row> train/prediction: 0.929638148567733/[0.47148743] </row>
		<row> train/prediction: 0.9297144375657354/[0.47148743] </row>
		<row> train/prediction: 0.9297907265636809/[0.47148743] </row>
		<row> train/prediction: 0.9298670155616833/[0.47148743] </row>
		<row> train/prediction: 0.9299433045596857/[0.47148743] </row>
		<row> train/prediction: 0.9300195935576312/[0.47148743] </row>
		<row> train/prediction: 0.9300958825556336/[0.47148743] </row>
		<row> train/prediction: 0.9301721715535791/[0.47148743] </row>
		<row> train/prediction: 0.9302484605515815/[0.47148743] </row>
		<row> train/prediction: 0.9303247495495839/[0.47148743] </row>
		<row> train/prediction: 0.9304010385475294/[0.47148743] </row>
		<row> train/prediction: 0.9304773275455318/[0.47148743] </row>
		<row> train/prediction: 0.9305536165435342/[0.47148743] </row>
		<row> train/prediction: 0.9306299055414797/[0.47148743] </row>
		<row> train/prediction: 0.9307061945394821/[0.47148743] </row>
		<row> train/prediction: 0.9307824835374845/[0.47148743] </row>
		<row> train/prediction: 0.93085877253543/[0.47148743] </row>
		<row> train/prediction: 0.9309350615334324/[0.47148743] </row>
		<row> train/prediction: 0.9310113505314348/[0.47148743] </row>
		<row> train/prediction: 0.9310876395293803/[0.47148743] </row>
		<row> train/prediction: 0.9311639285273827/[0.47148743] </row>
		<row> train/prediction: 0.9312402175253283/[0.47148743] </row>
		<row> train/prediction: 0.9313165065233306/[0.47148743] </row>
		<row> train/prediction: 0.931392795521333/[0.47148743] </row>
		<row> train/prediction: 0.9314690845192786/[0.47148743] </row>
		<row> train/prediction: 0.931545373517281/[0.47148743] </row>
		<row> train/prediction: 0.9316216625152833/[0.47148743] </row>
		<row> train/prediction: 0.9316979515132289/[0.47148743] </row>
		<row> train/prediction: 0.9317742405112313/[0.47148743] </row>
		<row> train/prediction: 0.9318505295092336/[0.47148743] </row>
		<row> train/prediction: 0.9319268185071792/[0.47148743] </row>
		<row> train/prediction: 0.9320031075051816/[0.47148743] </row>
		<row> train/prediction: 0.9320793965031839/[0.47148743] </row>
		<row> train/prediction: 0.9321556855011295/[0.47148743] </row>
		<row> train/prediction: 0.9322319744991319/[0.47148743] </row>
		<row> train/prediction: 0.9323082634971342/[0.47148743] </row>
		<row> train/prediction: 0.9323845524950798/[0.47148743] </row>
		<row> train/prediction: 0.9324608414930822/[0.47148743] </row>
		<row> train/prediction: 0.9325371304910277/[0.47148743] </row>
		<row> train/prediction: 0.9326134194890301/[0.47148743] </row>
		<row> train/prediction: 0.9326897084870325/[0.47148743] </row>
		<row> train/prediction: 0.932765997484978/[0.47148743] </row>
		<row> train/prediction: 0.9328422864829804/[0.47148743] </row>
		<row> train/prediction: 0.9329185754809828/[0.47148743] </row>
		<row> train/prediction: 0.9329948644789283/[0.47148743] </row>
		<row> train/prediction: 0.9330711534769307/[0.47148743] </row>
		<row> train/prediction: 0.9331474424749331/[0.47148743] </row>
		<row> train/prediction: 0.9332237314728786/[0.47148743] </row>
		<row> train/prediction: 0.933300020470881/[0.47148743] </row>
		<row> train/prediction: 0.9333763094688834/[0.47148743] </row>
		<row> train/prediction: 0.9334525984668289/[0.47148743] </row>
		<row> train/prediction: 0.9335288874648313/[0.47148743] </row>
		<row> train/prediction: 0.9336051764627769/[0.47148743] </row>
		<row> train/prediction: 0.9336814654607792/[0.47148743] </row>
		<row> train/prediction: 0.9337577544587816/[0.47148743] </row>
		<row> train/prediction: 0.9338340434567272/[0.47148743] </row>
		<row> train/prediction: 0.9339103324547295/[0.47148743] </row>
		<row> train/prediction: 0.9339866214527319/[0.47148743] </row>
		<row> train/prediction: 0.9340629104506775/[0.47148743] </row>
		<row> train/prediction: 0.9341391994486798/[0.47148743] </row>
		<row> train/prediction: 0.9342154884466822/[0.47148743] </row>
		<row> train/prediction: 0.9342917774446278/[0.47148743] </row>
		<row> train/prediction: 0.9343680664426302/[0.47148743] </row>
		<row> train/prediction: 0.9344443554406325/[0.47148743] </row>
		<row> train/prediction: 0.9345208987352294/[0.47148743] </row>
		<row> train/prediction: 0.9345971877332317/[0.47148743] </row>
		<row> train/prediction: 0.9346734767312341/[0.47148743] </row>
		<row> train/prediction: 0.9347497657291797/[0.47148743] </row>
		<row> train/prediction: 0.934826054727182/[0.47148743] </row>
		<row> train/prediction: 0.9349023437251844/[0.47148743] </row>
		<row> train/prediction: 0.93497863272313/[0.47148743] </row>
		<row> train/prediction: 0.9350549217211324/[0.47148743] </row>
		<row> train/prediction: 0.9351312107190779/[0.47148743] </row>
		<row> train/prediction: 0.9352074997170803/[0.47148743] </row>
		<row> train/prediction: 0.9352837887150827/[0.47148743] </row>
		<row> train/prediction: 0.9353600777130282/[0.47148743] </row>
		<row> train/prediction: 0.9354363667110306/[0.47148743] </row>
		<row> train/prediction: 0.935512655709033/[0.47148743] </row>
		<row> train/prediction: 0.9355889447069785/[0.47148743] </row>
		<row> train/prediction: 0.9356652337049809/[0.47148743] </row>
		<row> train/prediction: 0.9357415227029833/[0.47148743] </row>
		<row> train/prediction: 0.9358178117009288/[0.47148743] </row>
		<row> train/prediction: 0.9358941006989312/[0.47148743] </row>
		<row> train/prediction: 0.9359703896969336/[0.47148743] </row>
		<row> train/prediction: 0.9360466786948791/[0.47148743] </row>
		<row> train/prediction: 0.9361229676928815/[0.47148743] </row>
		<row> train/prediction: 0.9361992566908839/[0.47148743] </row>
		<row> train/prediction: 0.9362755456888294/[0.47148743] </row>
		<row> train/prediction: 0.9363518346868318/[0.47148743] </row>
		<row> train/prediction: 0.9364281236847773/[0.47148743] </row>
		<row> train/prediction: 0.9365044126827797/[0.47148743] </row>
		<row> train/prediction: 0.9365807016807821/[0.47148743] </row>
		<row> train/prediction: 0.9366569906787277/[0.47148743] </row>
		<row> train/prediction: 0.93673327967673/[0.47148743] </row>
		<row> train/prediction: 0.9368095686747324/[0.47148743] </row>
		<row> train/prediction: 0.936885857672678/[0.47148743] </row>
		<row> train/prediction: 0.9369621466706803/[0.47148743] </row>
		<row> train/prediction: 0.9370384356686827/[0.47148743] </row>
		<row> train/prediction: 0.9371147246666283/[0.47148743] </row>
		<row> train/prediction: 0.9371910136646306/[0.47148743] </row>
		<row> train/prediction: 0.937267302662633/[0.47148743] </row>
		<row> train/prediction: 0.9373435916605786/[0.47148743] </row>
		<row> train/prediction: 0.937419880658581/[0.47148743] </row>
		<row> train/prediction: 0.9374961696565265/[0.47148743] </row>
		<row> train/prediction: 0.9375724586545289/[0.47148743] </row>
		<row> train/prediction: 0.9376487476525313/[0.47148743] </row>
		<row> train/prediction: 0.9377250366504768/[0.47148743] </row>
		<row> train/prediction: 0.9378013256484792/[0.47148743] </row>
		<row> train/prediction: 0.9378776146464816/[0.47148743] </row>
		<row> train/prediction: 0.9379539036444271/[0.47148743] </row>
		<row> train/prediction: 0.9380301926424295/[0.47148743] </row>
		<row> train/prediction: 0.9381064816404319/[0.47148743] </row>
		<row> train/prediction: 0.9381827706383774/[0.47148743] </row>
		<row> train/prediction: 0.9382590596363798/[0.47148743] </row>
		<row> train/prediction: 0.9383353486343822/[0.47148743] </row>
		<row> train/prediction: 0.9384116376323277/[0.47148743] </row>
		<row> train/prediction: 0.9384879266303301/[0.47148743] </row>
		<row> train/prediction: 0.9385642156282756/[0.47148743] </row>
		<row> train/prediction: 0.938640504626278/[0.47148743] </row>
		<row> train/prediction: 0.9387167936242804/[0.47148743] </row>
		<row> train/prediction: 0.9387930826222259/[0.47148743] </row>
		<row> train/prediction: 0.9388693716202283/[0.47148743] </row>
		<row> train/prediction: 0.9389456606182307/[0.47148743] </row>
		<row> train/prediction: 0.9390219496161762/[0.47148743] </row>
		<row> train/prediction: 0.9390982386141786/[0.47148743] </row>
		<row> train/prediction: 0.939174527612181/[0.47148743] </row>
		<row> train/prediction: 0.9392508166101265/[0.47148743] </row>
		<row> train/prediction: 0.9393271056081289/[0.47148743] </row>
		<row> train/prediction: 0.9394033946061313/[0.47148743] </row>
		<row> train/prediction: 0.9394796836040769/[0.47148743] </row>
		<row> train/prediction: 0.9395559726020792/[0.47148743] </row>
		<row> train/prediction: 0.9396322616000248/[0.47148743] </row>
		<row> train/prediction: 0.9397085505980272/[0.47148743] </row>
		<row> train/prediction: 0.9397848395960295/[0.47148743] </row>
		<row> train/prediction: 0.9398611285939751/[0.47148743] </row>
		<row> train/prediction: 0.9399374175919775/[0.47148743] </row>
		<row> train/prediction: 0.9400139608866311/[0.47148743] </row>
		<row> train/prediction: 0.9400902498846335/[0.47148743] </row>
		<row> train/prediction: 0.9401665388825791/[0.47148743] </row>
		<row> train/prediction: 0.9402428278805814/[0.47148743] </row>
		<row> train/prediction: 0.940319116878527/[0.47148743] </row>
		<row> train/prediction: 0.9403954058765294/[0.47148743] </row>
		<row> train/prediction: 0.9404716948745317/[0.47148743] </row>
		<row> train/prediction: 0.9405479838724773/[0.47148743] </row>
		<row> train/prediction: 0.9406242728704797/[0.47148743] </row>
		<row> train/prediction: 0.940700561868482/[0.47148743] </row>
		<row> train/prediction: 0.9407768508664276/[0.47148743] </row>
		<row> train/prediction: 0.94085313986443/[0.47148743] </row>
		<row> train/prediction: 0.9409294288624324/[0.47148743] </row>
		<row> train/prediction: 0.9410057178603779/[0.47148743] </row>
		<row> train/prediction: 0.9410820068583803/[0.47148743] </row>
		<row> train/prediction: 0.9411582958563827/[0.47148743] </row>
		<row> train/prediction: 0.9412345848543282/[0.47148743] </row>
		<row> train/prediction: 0.9413108738523306/[0.47148743] </row>
		<row> train/prediction: 0.9413871628502761/[0.47148743] </row>
		<row> train/prediction: 0.9414634518482785/[0.47148743] </row>
		<row> train/prediction: 0.9415397408462809/[0.47148743] </row>
		<row> train/prediction: 0.9416160298442264/[0.47148743] </row>
		<row> train/prediction: 0.9416923188422288/[0.47148743] </row>
		<row> train/prediction: 0.9417686078402312/[0.47148743] </row>
		<row> train/prediction: 0.9418448968381767/[0.47148743] </row>
		<row> train/prediction: 0.9419211858361791/[0.47148743] </row>
		<row> train/prediction: 0.9419974748341815/[0.47148743] </row>
		<row> train/prediction: 0.942073763832127/[0.47148743] </row>
		<row> train/prediction: 0.9421500528301294/[0.47148743] </row>
		<row> train/prediction: 0.9422263418281318/[0.47148743] </row>
		<row> train/prediction: 0.9423026308260773/[0.47148743] </row>
		<row> train/prediction: 0.9423789198240797/[0.47148743] </row>
		<row> train/prediction: 0.9424552088220253/[0.47148743] </row>
		<row> train/prediction: 0.9425314978200277/[0.47148743] </row>
		<row> train/prediction: 0.94260778681803/[0.47148743] </row>
		<row> train/prediction: 0.9426840758159756/[0.47148743] </row>
		<row> train/prediction: 0.942760364813978/[0.47148743] </row>
		<row> train/prediction: 0.9428366538119803/[0.47148743] </row>
		<row> train/prediction: 0.9429129428099259/[0.47148743] </row>
		<row> train/prediction: 0.9429892318079283/[0.47148743] </row>
		<row> train/prediction: 0.9430655208059306/[0.47148743] </row>
		<row> train/prediction: 0.9431418098038762/[0.47148743] </row>
		<row> train/prediction: 0.9432180988018786/[0.47148743] </row>
		<row> train/prediction: 0.943294387799881/[0.47148743] </row>
		<row> train/prediction: 0.9433706767978265/[0.47148743] </row>
		<row> train/prediction: 0.9434469657958289/[0.47148743] </row>
		<row> train/prediction: 0.9435232547938313/[0.47148743] </row>
		<row> train/prediction: 0.9435995437917768/[0.47148743] </row>
		<row> train/prediction: 0.9436758327897792/[0.47148743] </row>
		<row> train/prediction: 0.9437521217877247/[0.47148743] </row>
		<row> train/prediction: 0.9438284107857271/[0.47148743] </row>
		<row> train/prediction: 0.9439046997837295/[0.47148743] </row>
		<row> train/prediction: 0.943980988781675/[0.47148743] </row>
		<row> train/prediction: 0.9440572777796774/[0.47148743] </row>
		<row> train/prediction: 0.9441335667776798/[0.47148743] </row>
		<row> train/prediction: 0.9442098557756253/[0.47148743] </row>
		<row> train/prediction: 0.9442861447736277/[0.47148743] </row>
		<row> train/prediction: 0.9443624337716301/[0.47148743] </row>
		<row> train/prediction: 0.9444387227695756/[0.47148743] </row>
		<row> train/prediction: 0.944515011767578/[0.47148743] </row>
		<row> train/prediction: 0.9445913007655804/[0.47148743] </row>
		<row> train/prediction: 0.9446675897635259/[0.47148743] </row>
		<row> train/prediction: 0.9447438787615283/[0.47148743] </row>
		<row> train/prediction: 0.9448201677594739/[0.47148743] </row>
		<row> train/prediction: 0.9448964567574762/[0.47148743] </row>
		<row> train/prediction: 0.9449727457554786/[0.47148743] </row>
		<row> train/prediction: 0.9450490347534242/[0.47148743] </row>
		<row> train/prediction: 0.9451253237514265/[0.47148743] </row>
		<row> train/prediction: 0.9452016127494289/[0.47148743] </row>
		<row> train/prediction: 0.9452779017473745/[0.47148743] </row>
		<row> train/prediction: 0.9453541907453769/[0.47148743] </row>
		<row> train/prediction: 0.9454304797433792/[0.47148743] </row>
		<row> train/prediction: 0.9455070230379761/[0.47148743] </row>
		<row> train/prediction: 0.9455833120359785/[0.47148743] </row>
		<row> train/prediction: 0.9456596010339808/[0.47148743] </row>
		<row> train/prediction: 0.9457358900319264/[0.47148743] </row>
		<row> train/prediction: 0.9458121790299288/[0.47148743] </row>
		<row> train/prediction: 0.9458884680279311/[0.47148743] </row>
		<row> train/prediction: 0.9459647570258767/[0.47148743] </row>
		<row> train/prediction: 0.9460410460238791/[0.47148743] </row>
		<row> train/prediction: 0.9461173350218814/[0.47148743] </row>
		<row> train/prediction: 0.946193624019827/[0.47148743] </row>
		<row> train/prediction: 0.9462699130178294/[0.47148743] </row>
		<row> train/prediction: 0.9463462020157749/[0.47148743] </row>
		<row> train/prediction: 0.9464224910137773/[0.47148743] </row>
		<row> train/prediction: 0.9464987800117797/[0.47148743] </row>
		<row> train/prediction: 0.9465750690097252/[0.47148743] </row>
		<row> train/prediction: 0.9466513580077276/[0.47148743] </row>
		<row> train/prediction: 0.94672764700573/[0.47148743] </row>
		<row> train/prediction: 0.9468039360036755/[0.47148743] </row>
		<row> train/prediction: 0.9468802250016779/[0.47148743] </row>
		<row> train/prediction: 0.9469565139996803/[0.47148743] </row>
		<row> train/prediction: 0.9470328029976258/[0.471477] </row>
		<row> train/prediction: 0.9471090919956282/[0.47140086] </row>
		<row> train/prediction: 0.9471853809936306/[0.47139153] </row>
		<row> train/prediction: 0.9472616699915761/[0.47142014] </row>
		<row> train/prediction: 0.9473379589895785/[0.47148743] </row>
		<row> train/prediction: 0.9474142479875809/[0.47148743] </row>
		<row> train/prediction: 0.9474905369855264/[0.47148743] </row>
		<row> train/prediction: 0.9475668259835288/[0.47148743] </row>
		<row> train/prediction: 0.9476431149814744/[0.47148743] </row>
		<row> train/prediction: 0.9477194039794767/[0.47148743] </row>
		<row> train/prediction: 0.9477956929774791/[0.47148743] </row>
		<row> train/prediction: 0.9478719819754247/[0.47148743] </row>
		<row> train/prediction: 0.947948270973427/[0.47148743] </row>
		<row> train/prediction: 0.9480245599714294/[0.47148743] </row>
		<row> train/prediction: 0.948100848969375/[0.47148743] </row>
		<row> train/prediction: 0.9481771379673773/[0.47148743] </row>
		<row> train/prediction: 0.9482534269653797/[0.47148743] </row>
		<row> train/prediction: 0.9483297159633253/[0.47148743] </row>
		<row> train/prediction: 0.9484060049613277/[0.47148743] </row>
		<row> train/prediction: 0.94848229395933/[0.47148743] </row>
		<row> train/prediction: 0.9485585829572756/[0.47148743] </row>
		<row> train/prediction: 0.948634871955278/[0.47148743] </row>
		<row> train/prediction: 0.9487111609532235/[0.47148743] </row>
		<row> train/prediction: 0.9487874499512259/[0.47148743] </row>
		<row> train/prediction: 0.9488637389492283/[0.47148743] </row>
		<row> train/prediction: 0.9489400279471738/[0.47148743] </row>
		<row> train/prediction: 0.9490163169451762/[0.47148743] </row>
		<row> train/prediction: 0.9490926059431786/[0.47148743] </row>
		<row> train/prediction: 0.9491688949411241/[0.47148743] </row>
		<row> train/prediction: 0.9492451839391265/[0.47148743] </row>
		<row> train/prediction: 0.9493214729371289/[0.47148743] </row>
		<row> train/prediction: 0.9493977619350744/[0.47148743] </row>
		<row> train/prediction: 0.9494740509330768/[0.47148743] </row>
		<row> train/prediction: 0.9495503399310792/[0.47148743] </row>
		<row> train/prediction: 0.9496266289290247/[0.47148743] </row>
		<row> train/prediction: 0.9497029179270271/[0.47148743] </row>
		<row> train/prediction: 0.9497792069249726/[0.47148743] </row>
		<row> train/prediction: 0.949855495922975/[0.47148743] </row>
		<row> train/prediction: 0.9499317849209774/[0.47148743] </row>
		<row> train/prediction: 0.950008073918923/[0.47148743] </row>
		<row> train/prediction: 0.9500843629169253/[0.47148743] </row>
		<row> train/prediction: 0.9501606519149277/[0.47148743] </row>
		<row> train/prediction: 0.9502369409128733/[0.47148743] </row>
		<row> train/prediction: 0.9503132299108756/[0.47148743] </row>
		<row> train/prediction: 0.950389518908878/[0.47143567] </row>
		<row> train/prediction: 0.9504658079068236/[0.47137818] </row>
		<row> train/prediction: 0.9505420969048259/[0.47131392] </row>
		<row> train/prediction: 0.9506183859028283/[0.47128183] </row>
		<row> train/prediction: 0.9506946749007739/[0.47127718] </row>
		<row> train/prediction: 0.9507709638987762/[0.47123232] </row>
		<row> train/prediction: 0.9508472528967218/[0.47122768] </row>
		<row> train/prediction: 0.9509235418947242/[0.47123632] </row>
		<row> train/prediction: 0.9510003394860291/[0.47127983] </row>
		<row> train/prediction: 0.9510766284840315/[0.47127855] </row>
		<row> train/prediction: 0.9511529174819771/[0.4713016] </row>
		<row> train/prediction: 0.9512292064799794/[0.4713086] </row>
		<row> train/prediction: 0.9513054954779818/[0.4713647] </row>
		<row> train/prediction: 0.9513817844759274/[0.4714312] </row>
		<row> train/prediction: 0.9514580734739297/[0.47146463] </row>
		<row> train/prediction: 0.9515343624719321/[0.47148743] </row>
		<row> train/prediction: 0.9516106514698777/[0.47148743] </row>
		<row> train/prediction: 0.95168694046788/[0.47148743] </row>
		<row> train/prediction: 0.9517632294658824/[0.47148743] </row>
		<row> train/prediction: 0.951839518463828/[0.47148743] </row>
		<row> train/prediction: 0.9519158074618304/[0.47148743] </row>
		<row> train/prediction: 0.9519920964597759/[0.47148743] </row>
		<row> train/prediction: 0.9520683854577783/[0.47148743] </row>
		<row> train/prediction: 0.9521446744557807/[0.47148743] </row>
		<row> train/prediction: 0.9522209634537262/[0.47148743] </row>
		<row> train/prediction: 0.9522972524517286/[0.47148743] </row>
		<row> train/prediction: 0.952373541449731/[0.47148743] </row>
		<row> train/prediction: 0.9524498304476765/[0.47148743] </row>
		<row> train/prediction: 0.9525261194456789/[0.47148743] </row>
		<row> train/prediction: 0.9526024084436813/[0.47148743] </row>
		<row> train/prediction: 0.9526786974416268/[0.47148743] </row>
		<row> train/prediction: 0.9527549864396292/[0.47148743] </row>
		<row> train/prediction: 0.9528312754376316/[0.47148743] </row>
		<row> train/prediction: 0.9529075644355771/[0.47148743] </row>
		<row> train/prediction: 0.9529838534335795/[0.47148743] </row>
		<row> train/prediction: 0.953060142431525/[0.47148743] </row>
		<row> train/prediction: 0.9531364314295274/[0.47148743] </row>
		<row> train/prediction: 0.9532127204275298/[0.47148743] </row>
		<row> train/prediction: 0.9532890094254753/[0.47148743] </row>
		<row> train/prediction: 0.9533652984234777/[0.47148743] </row>
		<row> train/prediction: 0.9534415874214801/[0.47148743] </row>
		<row> train/prediction: 0.9535178764194256/[0.47148743] </row>
		<row> train/prediction: 0.953594165417428/[0.47148743] </row>
		<row> train/prediction: 0.9536704544154304/[0.47148743] </row>
		<row> train/prediction: 0.953746743413376/[0.47148743] </row>
		<row> train/prediction: 0.9538230324113783/[0.47148743] </row>
		<row> train/prediction: 0.9538993214093807/[0.47148743] </row>
		<row> train/prediction: 0.9539756104073263/[0.47148743] </row>
		<row> train/prediction: 0.9540518994053286/[0.47148743] </row>
		<row> train/prediction: 0.9541281884032742/[0.47148743] </row>
		<row> train/prediction: 0.9542044774012766/[0.47148743] </row>
		<row> train/prediction: 0.954280766399279/[0.47148743] </row>
		<row> train/prediction: 0.9543570553972245/[0.47148743] </row>
		<row> train/prediction: 0.9544333443952269/[0.47148743] </row>
		<row> train/prediction: 0.9545096333932293/[0.47148743] </row>
		<row> train/prediction: 0.9545859223911748/[0.47148743] </row>
		<row> train/prediction: 0.9546622113891772/[0.47148743] </row>
		<row> train/prediction: 0.9547385003871796/[0.47148743] </row>
		<row> train/prediction: 0.9548147893851251/[0.47148743] </row>
		<row> train/prediction: 0.9548910783831275/[0.47148743] </row>
		<row> train/prediction: 0.9549673673811299/[0.47148743] </row>
		<row> train/prediction: 0.9550436563790754/[0.47148743] </row>
		<row> train/prediction: 0.9551199453770778/[0.47148743] </row>
		<row> train/prediction: 0.9551962343750802/[0.47148743] </row>
		<row> train/prediction: 0.9552725233730257/[0.47148743] </row>
		<row> train/prediction: 0.9553488123710281/[0.47148743] </row>
		<row> train/prediction: 0.9554251013689736/[0.47148743] </row>
		<row> train/prediction: 0.955501390366976/[0.47148743] </row>
		<row> train/prediction: 0.9555776793649784/[0.47148743] </row>
		<row> train/prediction: 0.9556539683629239/[0.47148743] </row>
		<row> train/prediction: 0.9557302573609263/[0.47148743] </row>
		<row> train/prediction: 0.9558065463589287/[0.47148743] </row>
		<row> train/prediction: 0.9558828353568742/[0.47148743] </row>
		<row> train/prediction: 0.9559591243548766/[0.47148743] </row>
		<row> train/prediction: 0.956035413352879/[0.47148743] </row>
		<row> train/prediction: 0.9561117023508245/[0.47148743] </row>
		<row> train/prediction: 0.9561879913488269/[0.47148743] </row>
		<row> train/prediction: 0.9562642803468293/[0.47148743] </row>
		<row> train/prediction: 0.9563405693447748/[0.47148743] </row>
		<row> train/prediction: 0.9564168583427772/[0.47148743] </row>
		<row> train/prediction: 0.9564934016374309/[0.47148743] </row>
		<row> train/prediction: 0.9565696906353764/[0.47148743] </row>
		<row> train/prediction: 0.9566459796333788/[0.47148743] </row>
		<row> train/prediction: 0.9567222686313812/[0.47148743] </row>
		<row> train/prediction: 0.9567985576293268/[0.47148743] </row>
		<row> train/prediction: 0.9568748466273291/[0.47148743] </row>
		<row> train/prediction: 0.9569511356252747/[0.47148743] </row>
		<row> train/prediction: 0.9570274246232771/[0.47148743] </row>
		<row> train/prediction: 0.9571037136212794/[0.47148743] </row>
		<row> train/prediction: 0.957180002619225/[0.47148743] </row>
		<row> train/prediction: 0.9572562916172274/[0.47148743] </row>
		<row> train/prediction: 0.9573325806152297/[0.47148743] </row>
		<row> train/prediction: 0.9574088696131753/[0.47148743] </row>
		<row> train/prediction: 0.9574851586111777/[0.47148743] </row>
		<row> train/prediction: 0.95756144760918/[0.4715045] </row>
		<row> train/prediction: 0.9576377366071256/[0.4715446] </row>
		<row> train/prediction: 0.957714025605128/[0.471554] </row>
		<row> train/prediction: 0.9577903146031304/[0.47160396] </row>
		<row> train/prediction: 0.9578666036010759/[0.47158238] </row>
		<row> train/prediction: 0.9579428925990783/[0.47156098] </row>
		<row> train/prediction: 0.9580191815970807/[0.47150227] </row>
		<row> train/prediction: 0.9580954705950262/[0.47148743] </row>
		<row> train/prediction: 0.9581717595930286/[0.47149396] </row>
		<row> train/prediction: 0.9582480485909741/[0.47148743] </row>
		<row> train/prediction: 0.9583243375889765/[0.47148743] </row>
		<row> train/prediction: 0.9584006265869789/[0.47148743] </row>
		<row> train/prediction: 0.9584769155849244/[0.47148743] </row>
		<row> train/prediction: 0.9585532045829268/[0.47148743] </row>
		<row> train/prediction: 0.9586294935809292/[0.47148743] </row>
		<row> train/prediction: 0.9587057825788747/[0.47148743] </row>
		<row> train/prediction: 0.9587820715768771/[0.47148743] </row>
		<row> train/prediction: 0.9588583605748795/[0.47148743] </row>
		<row> train/prediction: 0.958934649572825/[0.47148743] </row>
		<row> train/prediction: 0.9590109385708274/[0.47149834] </row>
		<row> train/prediction: 0.9590872275688298/[0.47149968] </row>
		<row> train/prediction: 0.9591635165667753/[0.47148743] </row>
		<row> train/prediction: 0.9592398055647777/[0.47148743] </row>
		<row> train/prediction: 0.9593160945627233/[0.47148743] </row>
		<row> train/prediction: 0.9593923835607256/[0.47148743] </row>
		<row> train/prediction: 0.959468672558728/[0.47148743] </row>
		<row> train/prediction: 0.9595449615566736/[0.47148743] </row>
		<row> train/prediction: 0.959621250554676/[0.47148743] </row>
		<row> train/prediction: 0.9596975395526783/[0.47148743] </row>
		<row> train/prediction: 0.9597738285506239/[0.47148743] </row>
		<row> train/prediction: 0.9598501175486263/[0.47148743] </row>
		<row> train/prediction: 0.9599264065466286/[0.47148743] </row>
		<row> train/prediction: 0.9600026955445742/[0.47148743] </row>
		<row> train/prediction: 0.9600789845425766/[0.47148743] </row>
		<row> train/prediction: 0.960155273540579/[0.47148743] </row>
		<row> train/prediction: 0.9602315625385245/[0.47148743] </row>
		<row> train/prediction: 0.9603078515365269/[0.47148743] </row>
		<row> train/prediction: 0.9603841405344724/[0.47148743] </row>
		<row> train/prediction: 0.9604604295324748/[0.47148743] </row>
		<row> train/prediction: 0.9605367185304772/[0.47152776] </row>
		<row> train/prediction: 0.9606130075284227/[0.47154486] </row>
		<row> train/prediction: 0.9606892965264251/[0.47156292] </row>
		<row> train/prediction: 0.9607655855244275/[0.47159263] </row>
		<row> train/prediction: 0.960841874522373/[0.47158498] </row>
		<row> train/prediction: 0.9609181635203754/[0.47154173] </row>
		<row> train/prediction: 0.9609944525183778/[0.47147954] </row>
		<row> train/prediction: 0.9610707415163233/[0.4715241] </row>
		<row> train/prediction: 0.9611470305143257/[0.4715063] </row>
		<row> train/prediction: 0.9612233195123281/[0.47148743] </row>
		<row> train/prediction: 0.9612996085102736/[0.47148773] </row>
		<row> train/prediction: 0.961375897508276/[0.47149178] </row>
		<row> train/prediction: 0.9614521865062216/[0.47148743] </row>
		<row> train/prediction: 0.9615284755042239/[0.47148743] </row>
		<row> train/prediction: 0.9616047645022263/[0.47148743] </row>
		<row> train/prediction: 0.9616810535001719/[0.47148743] </row>
		<row> train/prediction: 0.9617573424981742/[0.47148743] </row>
		<row> train/prediction: 0.9618336314961766/[0.47148684] </row>
		<row> train/prediction: 0.9619099204941222/[0.4713138] </row>
		<row> train/prediction: 0.9619864637887758/[0.47132757] </row>
		<row> train/prediction: 0.9620627527867782/[0.4712411] </row>
		<row> train/prediction: 0.9621390417847238/[0.4712223] </row>
		<row> train/prediction: 0.9622153307827261/[0.47121507] </row>
		<row> train/prediction: 0.9622916197807285/[0.47122037] </row>
		<row> train/prediction: 0.9623679087786741/[0.47128916] </row>
		<row> train/prediction: 0.9624441977766764/[0.47124133] </row>
		<row> train/prediction: 0.9625204867746788/[0.47129795] </row>
		<row> train/prediction: 0.9625967757726244/[0.4713501] </row>
		<row> train/prediction: 0.9626730647706268/[0.47146675] </row>
		<row> train/prediction: 0.9627493537686291/[0.47149262] </row>
		<row> train/prediction: 0.9628256427665747/[0.4714986] </row>
		<row> train/prediction: 0.9629019317645771/[0.4715425] </row>
		<row> train/prediction: 0.9629782207625794/[0.47163352] </row>
		<row> train/prediction: 0.963054509760525/[0.47154713] </row>
		<row> train/prediction: 0.9631307987585274/[0.47156662] </row>
		<row> train/prediction: 0.9632070877564729/[0.47155464] </row>
		<row> train/prediction: 0.9632833767544753/[0.47162932] </row>
		<row> train/prediction: 0.9633596657524777/[0.47168103] </row>
		<row> train/prediction: 0.9634359547504232/[0.47183615] </row>
		<row> train/prediction: 0.9635122437484256/[0.4721314] </row>
		<row> train/prediction: 0.963588532746428/[0.47225457] </row>
		<row> train/prediction: 0.9636648217443735/[0.47231302] </row>
		<row> train/prediction: 0.9637411107423759/[0.4723125] </row>
		<row> train/prediction: 0.9638173997403783/[0.47236463] </row>
		<row> train/prediction: 0.9638936887383238/[0.47218785] </row>
		<row> train/prediction: 0.9639699777363262/[0.47191578] </row>
		<row> train/prediction: 0.9640462667343286/[0.47171795] </row>
		<row> train/prediction: 0.9641225557322741/[0.47151342] </row>
		<row> train/prediction: 0.9641988447302765/[0.4715154] </row>
		<row> train/prediction: 0.964275133728222/[0.47151217] </row>
		<row> train/prediction: 0.9643514227262244/[0.47150448] </row>
		<row> train/prediction: 0.9644277117242268/[0.47148982] </row>
		<row> train/prediction: 0.9645040007221723/[0.47148743] </row>
		<row> train/prediction: 0.9645802897201747/[0.47148743] </row>
		<row> train/prediction: 0.9646565787181771/[0.47148743] </row>
		<row> train/prediction: 0.9647328677161227/[0.47148743] </row>
		<row> train/prediction: 0.964809156714125/[0.47148743] </row>
		<row> train/prediction: 0.9648854457121274/[0.47148743] </row>
		<row> train/prediction: 0.964961734710073/[0.47148743] </row>
		<row> train/prediction: 0.9650380237080753/[0.47148743] </row>
		<row> train/prediction: 0.9651143127060777/[0.47148743] </row>
		<row> train/prediction: 0.9651906017040233/[0.47148743] </row>
		<row> train/prediction: 0.9652668907020256/[0.47148743] </row>
		<row> train/prediction: 0.9653431796999712/[0.47148743] </row>
		<row> train/prediction: 0.9654194686979736/[0.47148743] </row>
		<row> train/prediction: 0.965495757695976/[0.47148743] </row>
		<row> train/prediction: 0.9655720466939215/[0.47148743] </row>
		<row> train/prediction: 0.9656483356919239/[0.47148743] </row>
		<row> train/prediction: 0.9657246246899263/[0.47148743] </row>
		<row> train/prediction: 0.9658009136878718/[0.47148743] </row>
		<row> train/prediction: 0.9658772026858742/[0.47148743] </row>
		<row> train/prediction: 0.9659534916838766/[0.47148743] </row>
		<row> train/prediction: 0.9660297806818221/[0.47148743] </row>
		<row> train/prediction: 0.9661060696798245/[0.47148162] </row>
		<row> train/prediction: 0.9661823586778269/[0.47148195] </row>
		<row> train/prediction: 0.9662586476757724/[0.47145614] </row>
		<row> train/prediction: 0.9663349366737748/[0.47142592] </row>
		<row> train/prediction: 0.9664112256717772/[0.47140196] </row>
		<row> train/prediction: 0.9664875146697227/[0.47139382] </row>
		<row> train/prediction: 0.9665638036677251/[0.4714084] </row>
		<row> train/prediction: 0.9666400926656706/[0.4714368] </row>
		<row> train/prediction: 0.966716381663673/[0.47143757] </row>
		<row> train/prediction: 0.9667926706616754/[0.47144392] </row>
		<row> train/prediction: 0.9668689596596209/[0.47145042] </row>
		<row> train/prediction: 0.9669452486576233/[0.47147322] </row>
		<row> train/prediction: 0.9670215376556257/[0.47148743] </row>
		<row> train/prediction: 0.9670978266535712/[0.47148743] </row>
		<row> train/prediction: 0.9671741156515736/[0.47148743] </row>
		<row> train/prediction: 0.967250404649576/[0.47148743] </row>
		<row> train/prediction: 0.9673266936475216/[0.47148743] </row>
		<row> train/prediction: 0.9674029826455239/[0.47148743] </row>
		<row> train/prediction: 0.9674792716435263/[0.47148743] </row>
		<row> train/prediction: 0.9675555606414719/[0.47148743] </row>
		<row> train/prediction: 0.9676318496394742/[0.47148743] </row>
		<row> train/prediction: 0.9677081386374198/[0.47148743] </row>
		<row> train/prediction: 0.9677844276354222/[0.47148743] </row>
		<row> train/prediction: 0.9678607166334245/[0.47148743] </row>
		<row> train/prediction: 0.9679370056313701/[0.47148743] </row>
		<row> train/prediction: 0.9680132946293725/[0.47148743] </row>
		<row> train/prediction: 0.9680895836273749/[0.47148743] </row>
		<row> train/prediction: 0.9681658726253204/[0.47148743] </row>
		<row> train/prediction: 0.9682421616233228/[0.47148743] </row>
		<row> train/prediction: 0.9683184506213252/[0.47148743] </row>
		<row> train/prediction: 0.9683947396192707/[0.47148743] </row>
		<row> train/prediction: 0.9684710286172731/[0.47148743] </row>
		<row> train/prediction: 0.9685473176152755/[0.47148743] </row>
		<row> train/prediction: 0.968623606613221/[0.47148743] </row>
		<row> train/prediction: 0.9686998956112234/[0.47152215] </row>
		<row> train/prediction: 0.9687761846091689/[0.47161058] </row>
		<row> train/prediction: 0.9688524736071713/[0.4716192] </row>
		<row> train/prediction: 0.9689287626051737/[0.4716315] </row>
		<row> train/prediction: 0.9690050516031192/[0.47166762] </row>
		<row> train/prediction: 0.9690813406011216/[0.47171742] </row>
		<row> train/prediction: 0.969157629599124/[0.47163248] </row>
		<row> train/prediction: 0.9692339185970695/[0.47148743] </row>
		<row> train/prediction: 0.9693102075950719/[0.47148743] </row>
		<row> train/prediction: 0.9693864965930743/[0.47148743] </row>
		<row> train/prediction: 0.9694627855910198/[0.47148743] </row>
		<row> train/prediction: 0.9695390745890222/[0.47148743] </row>
		<row> train/prediction: 0.9696153635870246/[0.47148743] </row>
		<row> train/prediction: 0.9696916525849701/[0.47148743] </row>
		<row> train/prediction: 0.9697679415829725/[0.47148743] </row>
		<row> train/prediction: 0.9698442305809181/[0.47148743] </row>
		<row> train/prediction: 0.9699205195789204/[0.47148743] </row>
		<row> train/prediction: 0.9699968085769228/[0.47148743] </row>
		<row> train/prediction: 0.9700730975748684/[0.47148743] </row>
		<row> train/prediction: 0.9701493865728708/[0.47148743] </row>
		<row> train/prediction: 0.9702256755708731/[0.47148743] </row>
		<row> train/prediction: 0.9703019645688187/[0.47148743] </row>
		<row> train/prediction: 0.9703782535668211/[0.47148743] </row>
		<row> train/prediction: 0.9704545425648234/[0.47148743] </row>
		<row> train/prediction: 0.970530831562769/[0.47148743] </row>
		<row> train/prediction: 0.9706071205607714/[0.47148743] </row>
		<row> train/prediction: 0.9706834095587737/[0.47148743] </row>
		<row> train/prediction: 0.9707596985567193/[0.47148743] </row>
		<row> train/prediction: 0.9708359875547217/[0.47148743] </row>
		<row> train/prediction: 0.970912276552724/[0.47148743] </row>
		<row> train/prediction: 0.9709885655506696/[0.47148743] </row>
		<row> train/prediction: 0.971064854548672/[0.47148743] </row>
		<row> train/prediction: 0.9711411435466175/[0.47148743] </row>
		<row> train/prediction: 0.9712174325446199/[0.47148743] </row>
		<row> train/prediction: 0.9712937215426223/[0.47148743] </row>
		<row> train/prediction: 0.9713700105405678/[0.47148743] </row>
		<row> train/prediction: 0.9714462995385702/[0.47148743] </row>
		<row> train/prediction: 0.9715988775345181/[0.47148743] </row>
		<row> train/prediction: 0.9716751665325205/[0.47148743] </row>
		<row> train/prediction: 0.9717514555305229/[0.47148743] </row>
		<row> train/prediction: 0.9718277445284684/[0.47148743] </row>
		<row> train/prediction: 0.9719040335264708/[0.47148743] </row>
		<row> train/prediction: 0.9719803225244732/[0.47148743] </row>
		<row> train/prediction: 0.9720566115224187/[0.47148743] </row>
		<row> train/prediction: 0.9721329005204211/[0.47148743] </row>
		<row> train/prediction: 0.9722091895183667/[0.47148743] </row>
		<row> train/prediction: 0.972285478516369/[0.47148743] </row>
		<row> train/prediction: 0.9723617675143714/[0.47148743] </row>
		<row> train/prediction: 0.972438056512317/[0.47153294] </row>
		<row> train/prediction: 0.9725143455103193/[0.471533] </row>
		<row> train/prediction: 0.9725906345083217/[0.47154072] </row>
		<row> train/prediction: 0.9726669235062673/[0.47151247] </row>
		<row> train/prediction: 0.9727432125042696/[0.47148743] </row>
		<row> train/prediction: 0.972819501502272/[0.47148743] </row>
		<row> train/prediction: 0.9728957905002176/[0.47148743] </row>
		<row> train/prediction: 0.9729723337948712/[0.47148743] </row>
		<row> train/prediction: 0.9730486227928736/[0.47148743] </row>
		<row> train/prediction: 0.9731249117908192/[0.47148743] </row>
		<row> train/prediction: 0.9732012007888216/[0.47148743] </row>
		<row> train/prediction: 0.9732774897868239/[0.47148743] </row>
		<row> train/prediction: 0.9733537787847695/[0.47148743] </row>
		<row> train/prediction: 0.9734300677827719/[0.47148743] </row>
		<row> train/prediction: 0.9735063567807742/[0.47148743] </row>
		<row> train/prediction: 0.9735826457787198/[0.47148743] </row>
		<row> train/prediction: 0.9736589347767222/[0.47148743] </row>
		<row> train/prediction: 0.9737352237747245/[0.47148743] </row>
		<row> train/prediction: 0.9738115127726701/[0.47148743] </row>
		<row> train/prediction: 0.9738878017706725/[0.47148743] </row>
		<row> train/prediction: 0.973964090768618/[0.47148743] </row>
		<row> train/prediction: 0.9740403797666204/[0.47148743] </row>
		<row> train/prediction: 0.9741166687646228/[0.47148743] </row>
		<row> train/prediction: 0.9741929577625683/[0.47148743] </row>
		<row> train/prediction: 0.9742692467605707/[0.47148743] </row>
		<row> train/prediction: 0.9743455357585731/[0.47148743] </row>
		<row> train/prediction: 0.9744218247565186/[0.47148743] </row>
		<row> train/prediction: 0.974498113754521/[0.47148743] </row>
		<row> train/prediction: 0.9745744027525234/[0.47148743] </row>
		<row> train/prediction: 0.9843594839303478/[0.47148743] </row>
		<row> train/prediction: 0.9844357729283502/[0.47148743] </row>
		<row> train/prediction: 0.9845120619262957/[0.47148743] </row>
		<row> train/prediction: 0.9845883509242981/[0.47148743] </row>
		<row> train/prediction: 0.9846646399223005/[0.47154117] </row>
		<row> train/prediction: 0.984740928920246/[0.47166803] </row>
		<row> train/prediction: 0.9848172179182484/[0.47170466] </row>
		<row> train/prediction: 0.9848935069162508/[0.4716912] </row>
		<row> train/prediction: 0.9849697959141963/[0.47165403] </row>
		<row> train/prediction: 0.9850460849121987/[0.47158435] </row>
		<row> train/prediction: 0.9851223739102011/[0.47150794] </row>
		<row> train/prediction: 0.9851986629081466/[0.47148743] </row>
		<row> train/prediction: 0.985274951906149/[0.47148743] </row>
		<row> train/prediction: 0.9853512409040945/[0.47148743] </row>
		<row> train/prediction: 0.9854275299020969/[0.47148743] </row>
		<row> train/prediction: 0.9855038189000993/[0.47148743] </row>
		<row> train/prediction: 0.9855801078980448/[0.47148743] </row>
		<row> train/prediction: 0.9856563968960472/[0.47148743] </row>
		<row> train/prediction: 0.9857326858940496/[0.47148743] </row>
		<row> train/prediction: 0.9858089748919951/[0.47148743] </row>
		<row> train/prediction: 0.9858852638899975/[0.47148743] </row>
		<row> train/prediction: 0.9859615528879999/[0.47148743] </row>
		<row> train/prediction: 0.9860378418859455/[0.47148743] </row>
		<row> train/prediction: 0.9861141308839478/[0.47148743] </row>
		<row> train/prediction: 0.9861904198819502/[0.47148743] </row>
		<row> train/prediction: 0.9862667088798958/[0.47148743] </row>
		<row> train/prediction: 0.9863429978778981/[0.47148743] </row>
		<row> train/prediction: 0.9864192868758437/[0.47148743] </row>
		<row> train/prediction: 0.9864955758738461/[0.47148743] </row>
		<row> train/prediction: 0.9865718648718484/[0.47148743] </row>
		<row> train/prediction: 0.986648153869794/[0.47148743] </row>
		<row> train/prediction: 0.9867244428677964/[0.47148743] </row>
		<row> train/prediction: 0.9868007318657988/[0.47148743] </row>
		<row> train/prediction: 0.9868770208637443/[0.47148743] </row>
		<row> train/prediction: 0.9869533098617467/[0.47148743] </row>
		<row> train/prediction: 0.9870295988597491/[0.47148743] </row>
		<row> train/prediction: 0.9871058878576946/[0.47148743] </row>
		<row> train/prediction: 0.987182176855697/[0.47148743] </row>
		<row> train/prediction: 0.9872584658536994/[0.47148743] </row>
		<row> train/prediction: 0.9873347548516449/[0.47148743] </row>
		<row> train/prediction: 0.9874110438496473/[0.47148743] </row>
		<row> train/prediction: 0.9874873328475928/[0.47148743] </row>
		<row> train/prediction: 0.9875636218455952/[0.47148743] </row>
		<row> train/prediction: 0.9876399108435976/[0.47148743] </row>
		<row> train/prediction: 0.9877161998415431/[0.47148743] </row>
		<row> train/prediction: 0.9877932517295562/[0.47148743] </row>
		<row> train/prediction: 0.9878695407275018/[0.47148743] </row>
		<row> train/prediction: 0.9879458297255042/[0.47148743] </row>
		<row> train/prediction: 0.9880221187234497/[0.47148743] </row>
		<row> train/prediction: 0.9880984077214521/[0.47148743] </row>
		<row> train/prediction: 0.9881746967194545/[0.47148743] </row>
		<row> train/prediction: 0.9882509857174/[0.47148743] </row>
		<row> train/prediction: 0.9883272747154024/[0.47148743] </row>
		<row> train/prediction: 0.9884035637134048/[0.47148743] </row>
		<row> train/prediction: 0.9884798527113503/[0.47148743] </row>
		<row> train/prediction: 0.9885561417093527/[0.47148743] </row>
		<row> train/prediction: 0.9886324307073551/[0.47148743] </row>
		<row> train/prediction: 0.9887087197053006/[0.47148743] </row>
		<row> train/prediction: 0.988785008703303/[0.47148743] </row>
		<row> train/prediction: 0.9888612977013054/[0.47148743] </row>
		<row> train/prediction: 0.9889375866992509/[0.47148743] </row>
		<row> train/prediction: 0.9890138756972533/[0.47148743] </row>
		<row> train/prediction: 0.9890901646951988/[0.47148743] </row>
		<row> train/prediction: 0.9891664536932012/[0.47148743] </row>
		<row> train/prediction: 0.9892427426912036/[0.47148743] </row>
		<row> train/prediction: 0.9893190316891491/[0.47148743] </row>
		<row> train/prediction: 0.9893953206871515/[0.47148743] </row>
		<row> train/prediction: 0.9894716096851539/[0.47148743] </row>
		<row> train/prediction: 0.9895478986830994/[0.47148743] </row>
		<row> train/prediction: 0.9896241876811018/[0.47148743] </row>
		<row> train/prediction: 0.9897004766791042/[0.47148743] </row>
		<row> train/prediction: 0.9897767656770498/[0.47148743] </row>
		<row> train/prediction: 0.9898530546750521/[0.47148743] </row>
		<row> train/prediction: 0.9899293436730545/[0.47148743] </row>
		<row> train/prediction: 0.9900056326710001/[0.47148743] </row>
		<row> train/prediction: 0.9900819216690024/[0.47148743] </row>
		<row> train/prediction: 0.990158210666948/[0.47148743] </row>
		<row> train/prediction: 0.9902344996649504/[0.47148743] </row>
		<row> train/prediction: 0.9903107886629527/[0.47148743] </row>
		<row> train/prediction: 0.9903870776608983/[0.47148743] </row>
		<row> train/prediction: 0.9904633666589007/[0.47148743] </row>
		<row> train/prediction: 0.990539655656903/[0.47148743] </row>
		<row> train/prediction: 0.9906159446548486/[0.47148743] </row>
		<row> train/prediction: 0.990692233652851/[0.47148743] </row>
		<row> train/prediction: 0.9907685226508534/[0.47148743] </row>
	</data>
</root>
