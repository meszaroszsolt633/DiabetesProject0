<?xml version="1.0" ?>
<root>
	<model>
		Model details:
		<hyperparameters>
			<backward_slidingwindow> 2 </backward_slidingwindow>
			<forward_slidingwindow> 15 </forward_slidingwindow>
			<learning_rate> 0.001 </learning_rate>
			<oversampling> False </oversampling>
			<scaling> True </scaling>
			<expansion_factor> 5 </expansion_factor>
			<expansion_multiplier> 1 </expansion_multiplier>
		</hyperparameters>
		<layers>
			<layer>1 name:lstm units:256  return_sequences:True </layer>
			<layer>2 name:dropout units:0.3 </layer>
			<layer>3 name:lstm_1 units:128  return_sequences:True </layer>
			<layer>4 name:dropout_1 units:0.3 </layer>
			<layer>5 name:lstm_2 units:64  return_sequences:False </layer>
			<layer>6 name:dropout_2 units:0.3 </layer>
			<layer>7 name:dense units:1 </layer>
		</layers>
		<history>
			<metrics> epoch:0 loss:0.052573442459106445 mae:0.13254009187221527, mse:0.052573442459106445, rmse:0.1744779497385025, val_loss:0.03438872843980789, val_mae:0.10574235767126083, val_mse:0.03438872843980789, val_rmse:0.13481932878494263</metrics>
			<metrics> epoch:1 loss:0.05092663690447807 mae:0.13394345343112946, mse:0.05092663690447807, rmse:0.17335090041160583, val_loss:0.03430420160293579, val_mae:0.10713331401348114, val_mse:0.03430420160293579, val_rmse:0.13563334941864014</metrics>
			<metrics> epoch:2 loss:0.05058225244283676 mae:0.13477295637130737, mse:0.05058225244283676, rmse:0.17399297654628754, val_loss:0.034512780606746674, val_mae:0.10886738449335098, val_mse:0.034512780606746674, val_rmse:0.13726291060447693</metrics>
			<metrics> epoch:3 loss:0.05040997266769409 mae:0.13346640765666962, mse:0.05040997266769409, rmse:0.17224371433258057, val_loss:0.03426060453057289, val_mae:0.10846641659736633, val_mse:0.03426060453057289, val_rmse:0.1366039216518402</metrics>
			<metrics> epoch:4 loss:0.05041401460766792 mae:0.1337176114320755, mse:0.05041401460766792, rmse:0.17301411926746368, val_loss:0.03368731588125229, val_mae:0.10771925747394562, val_mse:0.03368731588125229, val_rmse:0.13525943458080292</metrics>
			<metrics> epoch:5 loss:0.050287771970033646 mae:0.13314813375473022, mse:0.050287771970033646, rmse:0.17258143424987793, val_loss:0.03346944972872734, val_mae:0.10919392108917236, val_mse:0.03346944972872734, val_rmse:0.13592147827148438</metrics>
			<metrics> epoch:6 loss:0.05015052855014801 mae:0.13408273458480835, mse:0.05015052855014801, rmse:0.17378343641757965, val_loss:0.0341355986893177, val_mae:0.11119530349969864, val_mse:0.0341355986893177, val_rmse:0.13835495710372925</metrics>
			<metrics> epoch:7 loss:0.050440464168787 mae:0.13173995912075043, mse:0.050440464168787, rmse:0.17183096706867218, val_loss:0.033661551773548126, val_mae:0.11227916181087494, val_mse:0.033661551773548126, val_rmse:0.1383570432662964</metrics>
			<metrics> epoch:8 loss:0.050040218979120255 mae:0.13508012890815735, mse:0.050040218979120255, rmse:0.1739654839038849, val_loss:0.033334311097860336, val_mae:0.10998373478651047, val_mse:0.033334311097860336, val_rmse:0.13649414479732513</metrics>
			<metrics> epoch:9 loss:0.04997396841645241 mae:0.13386572897434235, mse:0.04997396841645241, rmse:0.1732529252767563, val_loss:0.03391685336828232, val_mae:0.11527619510889053, val_mse:0.03391685336828232, val_rmse:0.14082542061805725</metrics>
			<metrics> epoch:10 loss:0.04995471611618996 mae:0.1331210434436798, mse:0.04995471611618996, rmse:0.17302586138248444, val_loss:0.03378269448876381, val_mae:0.11340132355690002, val_mse:0.03378269448876381, val_rmse:0.13947691023349762</metrics>
			<metrics> epoch:11 loss:0.049560654908418655 mae:0.13287746906280518, mse:0.049560654908418655, rmse:0.172490656375885, val_loss:0.033205628395080566, val_mae:0.11179646104574203, val_mse:0.033205628395080566, val_rmse:0.13775405287742615</metrics>
			<metrics> epoch:12 loss:0.049671709537506104 mae:0.1321430206298828, mse:0.049671709537506104, rmse:0.17250767350196838, val_loss:0.03291059285402298, val_mae:0.10923757404088974, val_mse:0.03291059285402298, val_rmse:0.13552944362163544</metrics>
			<metrics> epoch:13 loss:0.04965914413332939 mae:0.13244272768497467, mse:0.04965914413332939, rmse:0.17278845608234406, val_loss:0.03293469175696373, val_mae:0.1088690459728241, val_mse:0.03293469175696373, val_rmse:0.13577304780483246</metrics>
			<metrics> epoch:14 loss:0.04954243823885918 mae:0.13284015655517578, mse:0.04954243823885918, rmse:0.17266519367694855, val_loss:0.03296077251434326, val_mae:0.11143861711025238, val_mse:0.03296077251434326, val_rmse:0.1374206840991974</metrics>
			<metrics> epoch:15 loss:0.049637507647275925 mae:0.13268133997917175, mse:0.049637507647275925, rmse:0.17291030287742615, val_loss:0.03284626081585884, val_mae:0.1107398197054863, val_mse:0.03284626081585884, val_rmse:0.1367441713809967</metrics>
			<metrics> epoch:16 loss:0.04961715638637543 mae:0.13287661969661713, mse:0.04961715638637543, rmse:0.17314644157886505, val_loss:0.03311381861567497, val_mae:0.11372444033622742, val_mse:0.03311381861567497, val_rmse:0.13899070024490356</metrics>
			<metrics> epoch:17 loss:0.04934017360210419 mae:0.1321605145931244, mse:0.04934017360210419, rmse:0.17220290005207062, val_loss:0.03277340531349182, val_mae:0.11367613822221756, val_mse:0.03277340531349182, val_rmse:0.1386944055557251</metrics>
			<metrics> epoch:18 loss:0.049358680844306946 mae:0.1325005292892456, mse:0.049358680844306946, rmse:0.17291316390037537, val_loss:0.033554498106241226, val_mae:0.11476574093103409, val_mse:0.033554498106241226, val_rmse:0.14086349308490753</metrics>
			<metrics> epoch:19 loss:0.04954782873392105 mae:0.13208670914173126, mse:0.04954782873392105, rmse:0.17272073030471802, val_loss:0.03302621468901634, val_mae:0.11216872930526733, val_mse:0.03302621468901634, val_rmse:0.1383633315563202</metrics>
			<metrics> epoch:20 loss:0.04939078539609909 mae:0.13275936245918274, mse:0.04939078539609909, rmse:0.17309878766536713, val_loss:0.03295956552028656, val_mae:0.11233770847320557, val_mse:0.03295956552028656, val_rmse:0.13818460702896118</metrics>
			<metrics> epoch:21 loss:0.04943398758769035 mae:0.13191184401512146, mse:0.04943398758769035, rmse:0.17230375111103058, val_loss:0.03279155492782593, val_mae:0.11383900046348572, val_mse:0.03279155492782593, val_rmse:0.13886873424053192</metrics>
			<metrics> epoch:22 loss:0.049328144639730453 mae:0.13272351026535034, mse:0.049328144639730453, rmse:0.17286790907382965, val_loss:0.03304535895586014, val_mae:0.11597777903079987, val_mse:0.03304535895586014, val_rmse:0.14076730608940125</metrics>
			<metrics> epoch:23 loss:0.04925447329878807 mae:0.13181164860725403, mse:0.04925447329878807, rmse:0.17239905893802643, val_loss:0.03300065919756889, val_mae:0.11615616083145142, val_mse:0.03300065919756889, val_rmse:0.14070726931095123</metrics>
			<metrics> epoch:24 loss:0.04937027022242546 mae:0.13252700865268707, mse:0.04937027022242546, rmse:0.17304639518260956, val_loss:0.03305043652653694, val_mae:0.11431565135717392, val_mse:0.03305043652653694, val_rmse:0.13998521864414215</metrics>
			<metrics> epoch:25 loss:0.04925243929028511 mae:0.13223502039909363, mse:0.04925243929028511, rmse:0.17323876917362213, val_loss:0.03270646557211876, val_mae:0.11306551098823547, val_mse:0.03270646557211876, val_rmse:0.13867473602294922</metrics>
			<metrics> epoch:26 loss:0.04931012913584709 mae:0.13172447681427002, mse:0.04931012913584709, rmse:0.17225147783756256, val_loss:0.03273608908057213, val_mae:0.11371913552284241, val_mse:0.03273608908057213, val_rmse:0.13917993009090424</metrics>
			<metrics> epoch:27 loss:0.0493406243622303 mae:0.13126572966575623, mse:0.0493406243622303, rmse:0.17261339724063873, val_loss:0.034411486238241196, val_mae:0.11838775873184204, val_mse:0.034411486238241196, val_rmse:0.145436093211174</metrics>
			<metrics> epoch:28 loss:0.04951837658882141 mae:0.13343285024166107, mse:0.04951837658882141, rmse:0.17311064898967743, val_loss:0.032250724732875824, val_mae:0.1106831431388855, val_mse:0.032250724732875824, val_rmse:0.1365339308977127</metrics>
			<metrics> epoch:29 loss:0.0490102581679821 mae:0.13216111063957214, mse:0.0490102581679821, rmse:0.17254626750946045, val_loss:0.032398324459791183, val_mae:0.11379822343587875, val_mse:0.032398324459791183, val_rmse:0.13876110315322876</metrics>
			<metrics> epoch:30 loss:0.04903898760676384 mae:0.13147862255573273, mse:0.04903898760676384, rmse:0.17227089405059814, val_loss:0.03247007727622986, val_mae:0.11286509782075882, val_mse:0.03247007727622986, val_rmse:0.1385020911693573</metrics>
			<metrics> epoch:31 loss:0.049073316156864166 mae:0.13188020884990692, mse:0.049073316156864166, rmse:0.17281265556812286, val_loss:0.03227420896291733, val_mae:0.11322980374097824, val_mse:0.03227420896291733, val_rmse:0.13827359676361084</metrics>
			<metrics> epoch:32 loss:0.04911748319864273 mae:0.1321558654308319, mse:0.04911748319864273, rmse:0.17241241037845612, val_loss:0.032295528799295425, val_mae:0.11265848577022552, val_mse:0.032295528799295425, val_rmse:0.13809455931186676</metrics>
			<metrics> epoch:33 loss:0.04904496669769287 mae:0.13169723749160767, mse:0.04904496669769287, rmse:0.17240598797798157, val_loss:0.032581377774477005, val_mae:0.11523707956075668, val_mse:0.032581377774477005, val_rmse:0.14049780368804932</metrics>
			<metrics> epoch:34 loss:0.04904555156826973 mae:0.13237249851226807, mse:0.04904555156826973, rmse:0.17347446084022522, val_loss:0.03272115811705589, val_mae:0.11503573507070541, val_mse:0.03272115811705589, val_rmse:0.1404450386762619</metrics>
			<metrics> epoch:35 loss:0.04900310933589935 mae:0.13142551481723785, mse:0.04900310933589935, rmse:0.1726018786430359, val_loss:0.032411303371191025, val_mae:0.11400263011455536, val_mse:0.032411303371191025, val_rmse:0.1392080932855606</metrics>
			<metrics> epoch:36 loss:0.04893846437335014 mae:0.13216686248779297, mse:0.04893846437335014, rmse:0.17310789227485657, val_loss:0.032135799527168274, val_mae:0.11132866144180298, val_mse:0.032135799527168274, val_rmse:0.13673971593379974</metrics>
			<metrics> epoch:37 loss:0.04889528825879097 mae:0.13112418353557587, mse:0.04889528825879097, rmse:0.17238128185272217, val_loss:0.03220914304256439, val_mae:0.11294837296009064, val_mse:0.03220914304256439, val_rmse:0.1379663497209549</metrics>
			<metrics> epoch:38 loss:0.048883575946092606 mae:0.13118363916873932, mse:0.048883575946092606, rmse:0.1723976880311966, val_loss:0.03223571181297302, val_mae:0.11392200738191605, val_mse:0.03223571181297302, val_rmse:0.13877055048942566</metrics>
			<metrics> epoch:39 loss:0.048907242715358734 mae:0.1320335865020752, mse:0.048907242715358734, rmse:0.17297852039337158, val_loss:0.03259939327836037, val_mae:0.1148301437497139, val_mse:0.03259939327836037, val_rmse:0.13985514640808105</metrics>
			<metrics> epoch:40 loss:0.048905808478593826 mae:0.13123732805252075, mse:0.048905808478593826, rmse:0.17252641916275024, val_loss:0.03228709474205971, val_mae:0.11337745934724808, val_mse:0.03228709474205971, val_rmse:0.13825921714305878</metrics>
			<metrics> epoch:41 loss:0.04885753616690636 mae:0.13065733015537262, mse:0.04885753616690636, rmse:0.17205941677093506, val_loss:0.03224622458219528, val_mae:0.11261887103319168, val_mse:0.03224622458219528, val_rmse:0.13810019195079803</metrics>
			<metrics> epoch:42 loss:0.048861775547266006 mae:0.13148853182792664, mse:0.048861775547266006, rmse:0.172603577375412, val_loss:0.032125554978847504, val_mae:0.11297452449798584, val_mse:0.032125554978847504, val_rmse:0.1382315754890442</metrics>
			<metrics> epoch:43 loss:0.04872235283255577 mae:0.13073308765888214, mse:0.04872235283255577, rmse:0.17243772745132446, val_loss:0.0321478433907032, val_mae:0.11391635239124298, val_mse:0.0321478433907032, val_rmse:0.13864703476428986</metrics>
			<metrics> epoch:44 loss:0.04873347654938698 mae:0.13127057254314423, mse:0.04873347654938698, rmse:0.17268383502960205, val_loss:0.032448332756757736, val_mae:0.11446572840213776, val_mse:0.032448332756757736, val_rmse:0.1398930549621582</metrics>
			<metrics> epoch:45 loss:0.04875761270523071 mae:0.1307840645313263, mse:0.04875761270523071, rmse:0.17238272726535797, val_loss:0.03218148648738861, val_mae:0.11267154663801193, val_mse:0.03218148648738861, val_rmse:0.1384914517402649</metrics>
			<metrics> epoch:46 loss:0.048766378313302994 mae:0.13081108033657074, mse:0.048766378313302994, rmse:0.17261388897895813, val_loss:0.032554496079683304, val_mae:0.11457083374261856, val_mse:0.032554496079683304, val_rmse:0.140445277094841</metrics>
			<metrics> epoch:47 loss:0.04878748953342438 mae:0.1316492259502411, mse:0.04878748953342438, rmse:0.17287670075893402, val_loss:0.032122138887643814, val_mae:0.11185303330421448, val_mse:0.032122138887643814, val_rmse:0.13735763728618622</metrics>
			<metrics> epoch:48 loss:0.04862489551305771 mae:0.13096381723880768, mse:0.04862489551305771, rmse:0.17290036380290985, val_loss:0.032079681754112244, val_mae:0.11133573204278946, val_mse:0.032079681754112244, val_rmse:0.13714724779129028</metrics>
			<metrics> epoch:49 loss:0.04852431267499924 mae:0.13021115958690643, mse:0.04852431267499924, rmse:0.17213498055934906, val_loss:0.03249913826584816, val_mae:0.11423317342996597, val_mse:0.03249913826584816, val_rmse:0.1399218887090683</metrics>
			<metrics> epoch:50 loss:0.048730380833148956 mae:0.13064607977867126, mse:0.048730380833148956, rmse:0.17292672395706177, val_loss:0.03213177248835564, val_mae:0.11251918226480484, val_mse:0.03213177248835564, val_rmse:0.13799336552619934</metrics>
			<metrics> epoch:51 loss:0.04850563779473305 mae:0.13079465925693512, mse:0.04850563779473305, rmse:0.17227782309055328, val_loss:0.032132841646671295, val_mae:0.11129197478294373, val_mse:0.032132841646671295, val_rmse:0.13693028688430786</metrics>
			<metrics> epoch:52 loss:0.048465099185705185 mae:0.13002249598503113, mse:0.048465099185705185, rmse:0.17210474610328674, val_loss:0.03223909065127373, val_mae:0.11316979676485062, val_mse:0.03223909065127373, val_rmse:0.13891912996768951</metrics>
			<metrics> epoch:53 loss:0.0484439991414547 mae:0.13025841116905212, mse:0.0484439991414547, rmse:0.17233017086982727, val_loss:0.032040517777204514, val_mae:0.11193560808897018, val_mse:0.032040517777204514, val_rmse:0.13732074201107025</metrics>
			<metrics> epoch:54 loss:0.04836788401007652 mae:0.12993402779102325, mse:0.04836788401007652, rmse:0.17199747264385223, val_loss:0.03191626816987991, val_mae:0.11064061522483826, val_mse:0.03191626816987991, val_rmse:0.13609622418880463</metrics>
			<metrics> epoch:55 loss:0.04835205152630806 mae:0.13046014308929443, mse:0.04835205152630806, rmse:0.17217926681041718, val_loss:0.03223446011543274, val_mae:0.11105066537857056, val_mse:0.03223446011543274, val_rmse:0.13775959610939026</metrics>
			<metrics> epoch:56 loss:0.048406731337308884 mae:0.1304394006729126, mse:0.048406731337308884, rmse:0.17223024368286133, val_loss:0.031867869198322296, val_mae:0.11005735397338867, val_mse:0.031867869198322296, val_rmse:0.13656632602214813</metrics>
			<metrics> epoch:57 loss:0.048418596386909485 mae:0.13047023117542267, mse:0.048418596386909485, rmse:0.17206959426403046, val_loss:0.03316553682088852, val_mae:0.11235486716032028, val_mse:0.03316553682088852, val_rmse:0.14086134731769562</metrics>
			<metrics> epoch:58 loss:0.048476457595825195 mae:0.13023875653743744, mse:0.048476457595825195, rmse:0.17187419533729553, val_loss:0.03233300521969795, val_mae:0.10795319080352783, val_mse:0.03233300521969795, val_rmse:0.1371202915906906</metrics>
			<metrics> epoch:59 loss:0.0485013872385025 mae:0.13025528192520142, mse:0.0485013872385025, rmse:0.1728089451789856, val_loss:0.03235182911157608, val_mae:0.11017583310604095, val_mse:0.03235182911157608, val_rmse:0.13805320858955383</metrics>
			<metrics> epoch:60 loss:0.048076000064611435 mae:0.1294110119342804, mse:0.048076000064611435, rmse:0.17221848666667938, val_loss:0.03194321691989899, val_mae:0.11010038107633591, val_mse:0.03194321691989899, val_rmse:0.13695332407951355</metrics>
			<metrics> epoch:61 loss:0.04825502634048462 mae:0.12958979606628418, mse:0.04825502634048462, rmse:0.17227491736412048, val_loss:0.031474608927965164, val_mae:0.10656458884477615, val_mse:0.031474608927965164, val_rmse:0.1337413638830185</metrics>
			<metrics> epoch:62 loss:0.047985006123781204 mae:0.12942785024642944, mse:0.047985006123781204, rmse:0.17237621545791626, val_loss:0.03173482418060303, val_mae:0.10898232460021973, val_mse:0.03173482418060303, val_rmse:0.1354057788848877</metrics>
			<metrics> epoch:63 loss:0.04813188314437866 mae:0.1298542469739914, mse:0.04813188314437866, rmse:0.17251800000667572, val_loss:0.03235238417983055, val_mae:0.11160759627819061, val_mse:0.03235238417983055, val_rmse:0.138640895485878</metrics>
			<metrics> epoch:64 loss:0.048003289848566055 mae:0.12909260392189026, mse:0.048003289848566055, rmse:0.17199330031871796, val_loss:0.03189760819077492, val_mae:0.10744395852088928, val_mse:0.03189760819077492, val_rmse:0.13487091660499573</metrics>
			<metrics> epoch:65 loss:0.04828973487019539 mae:0.12912967801094055, mse:0.04828973487019539, rmse:0.17219209671020508, val_loss:0.03175819292664528, val_mae:0.10733924806118011, val_mse:0.03175819292664528, val_rmse:0.13516230881214142</metrics>
			<metrics> epoch:66 loss:0.04808155447244644 mae:0.12947969138622284, mse:0.04808155447244644, rmse:0.17195840179920197, val_loss:0.031149426475167274, val_mae:0.1077275201678276, val_mse:0.031149426475167274, val_rmse:0.13362246751785278</metrics>
			<metrics> epoch:67 loss:0.04810064658522606 mae:0.1295231282711029, mse:0.04810064658522606, rmse:0.17235291004180908, val_loss:0.03126936033368111, val_mae:0.1068047508597374, val_mse:0.03126936033368111, val_rmse:0.132912278175354</metrics>
			<metrics> epoch:68 loss:0.04773861914873123 mae:0.1278749704360962, mse:0.04773861914873123, rmse:0.1709519624710083, val_loss:0.03157828748226166, val_mae:0.10679931193590164, val_mse:0.03157828748226166, val_rmse:0.13457153737545013</metrics>
			<metrics> epoch:69 loss:0.04808064177632332 mae:0.12891334295272827, mse:0.04808064177632332, rmse:0.17178498208522797, val_loss:0.03132667765021324, val_mae:0.10596605390310287, val_mse:0.03132667765021324, val_rmse:0.1333041489124298</metrics>
			<metrics> epoch:70 loss:0.04783644899725914 mae:0.12826241552829742, mse:0.04783644899725914, rmse:0.17157267034053802, val_loss:0.03135503828525543, val_mae:0.10626677423715591, val_mse:0.03135503828525543, val_rmse:0.1333606094121933</metrics>
			<metrics> epoch:71 loss:0.04769350215792656 mae:0.12818796932697296, mse:0.04769350215792656, rmse:0.17174972593784332, val_loss:0.03106302209198475, val_mae:0.10392516106367111, val_mse:0.03106302209198475, val_rmse:0.13174718618392944</metrics>
			<metrics> epoch:72 loss:0.04789537936449051 mae:0.12708717584609985, mse:0.04789537936449051, rmse:0.17122793197631836, val_loss:0.03053339757025242, val_mae:0.10242275148630142, val_mse:0.03053339757025242, val_rmse:0.12964941561222076</metrics>
			<metrics> epoch:73 loss:0.04724299907684326 mae:0.12775954604148865, mse:0.04724299907684326, rmse:0.17031927406787872, val_loss:0.03081652894616127, val_mae:0.10386044532060623, val_mse:0.03081652894616127, val_rmse:0.13225144147872925</metrics>
			<metrics> epoch:74 loss:0.04721708223223686 mae:0.1261831372976303, mse:0.04721708223223686, rmse:0.17068107426166534, val_loss:0.030422696843743324, val_mae:0.10060525685548782, val_mse:0.030422696843743324, val_rmse:0.1296142339706421</metrics>
			<metrics> epoch:75 loss:0.04693277180194855 mae:0.12580107152462006, mse:0.04693277180194855, rmse:0.1705862283706665, val_loss:0.03014141321182251, val_mae:0.09988719969987869, val_mse:0.03014141321182251, val_rmse:0.12861482799053192</metrics>
			<metrics> epoch:76 loss:0.046717673540115356 mae:0.12525081634521484, mse:0.046717673540115356, rmse:0.16974595189094543, val_loss:0.03034111298620701, val_mae:0.09711561352014542, val_mse:0.03034111298620701, val_rmse:0.1279425024986267</metrics>
			<metrics> epoch:77 loss:0.04666854441165924 mae:0.1248866468667984, mse:0.04666854441165924, rmse:0.1695423722267151, val_loss:0.03033658117055893, val_mae:0.10095983743667603, val_mse:0.03033658117055893, val_rmse:0.12981121242046356</metrics>
			<metrics> epoch:78 loss:0.046340033411979675 mae:0.12500135600566864, mse:0.046340033411979675, rmse:0.16996581852436066, val_loss:0.030358996242284775, val_mae:0.10249122232198715, val_mse:0.030358996242284775, val_rmse:0.13058975338935852</metrics>
			<metrics> epoch:79 loss:0.04638803005218506 mae:0.12462494522333145, mse:0.04638803005218506, rmse:0.1698928326368332, val_loss:0.030268162488937378, val_mae:0.09955881536006927, val_mse:0.030268162488937378, val_rmse:0.12909212708473206</metrics>
			<metrics> epoch:80 loss:0.0460200197994709 mae:0.12351022660732269, mse:0.0460200197994709, rmse:0.16880632936954498, val_loss:0.03045702539384365, val_mae:0.09955772012472153, val_mse:0.03045702539384365, val_rmse:0.12942230701446533</metrics>
			<metrics> epoch:81 loss:0.0456605888903141 mae:0.12245059013366699, mse:0.0456605888903141, rmse:0.1681085228919983, val_loss:0.031992021948099136, val_mae:0.10384329408407211, val_mse:0.031992021948099136, val_rmse:0.134822815656662</metrics>
			<metrics> epoch:82 loss:0.04558341205120087 mae:0.12400713562965393, mse:0.04558341205120087, rmse:0.16932258009910583, val_loss:0.031079379841685295, val_mae:0.10099038481712341, val_mse:0.031079379841685295, val_rmse:0.13165655732154846</metrics>
			<metrics> epoch:83 loss:0.04567243531346321 mae:0.12368951737880707, mse:0.04567243531346321, rmse:0.16868586838245392, val_loss:0.03128577768802643, val_mae:0.10286787152290344, val_mse:0.03128577768802643, val_rmse:0.13283094763755798</metrics>
			<metrics> epoch:84 loss:0.045536406338214874 mae:0.12257981300354004, mse:0.045536406338214874, rmse:0.16860808432102203, val_loss:0.030870908871293068, val_mae:0.09918790310621262, val_mse:0.030870908871293068, val_rmse:0.13000115752220154</metrics>
			<metrics> epoch:85 loss:0.04528842866420746 mae:0.12228070199489594, mse:0.04528842866420746, rmse:0.16772609949111938, val_loss:0.032762907445430756, val_mae:0.10636542737483978, val_mse:0.032762907445430756, val_rmse:0.13664883375167847</metrics>
			<metrics> epoch:86 loss:0.04529346153140068 mae:0.12235590070486069, mse:0.04529346153140068, rmse:0.16834531724452972, val_loss:0.03301267698407173, val_mae:0.10972315073013306, val_mse:0.03301267698407173, val_rmse:0.1392425149679184</metrics>
			<metrics> epoch:87 loss:0.04480751231312752 mae:0.12223668396472931, mse:0.04480751231312752, rmse:0.16774030029773712, val_loss:0.0311437901109457, val_mae:0.10091498494148254, val_mse:0.0311437901109457, val_rmse:0.13074055314064026</metrics>
			<metrics> epoch:88 loss:0.04489864781498909 mae:0.12243393063545227, mse:0.04489864781498909, rmse:0.16822068393230438, val_loss:0.03324756771326065, val_mae:0.10629377514123917, val_mse:0.03324756771326065, val_rmse:0.13793522119522095</metrics>
			<metrics> epoch:89 loss:0.04517862945795059 mae:0.12187439203262329, mse:0.04517862945795059, rmse:0.16736510396003723, val_loss:0.032971277832984924, val_mae:0.10367868840694427, val_mse:0.032971277832984924, val_rmse:0.13599923253059387</metrics>
			<metrics> epoch:90 loss:0.04467412829399109 mae:0.12040401250123978, mse:0.04467412829399109, rmse:0.16640402376651764, val_loss:0.032894566655159, val_mae:0.10044564306735992, val_mse:0.032894566655159, val_rmse:0.13495321571826935</metrics>
			<metrics> epoch:91 loss:0.04495897889137268 mae:0.1215619444847107, mse:0.04495897889137268, rmse:0.16740447282791138, val_loss:0.03306734189391136, val_mae:0.10077857971191406, val_mse:0.03306734189391136, val_rmse:0.13487477600574493</metrics>
			<metrics> epoch:92 loss:0.04484787955880165 mae:0.12094393372535706, mse:0.04484787955880165, rmse:0.16670210659503937, val_loss:0.03362786024808884, val_mae:0.10718560218811035, val_mse:0.03362786024808884, val_rmse:0.13953514397144318</metrics>
			<metrics> epoch:93 loss:0.044817205518484116 mae:0.1214834600687027, mse:0.044817205518484116, rmse:0.16759397089481354, val_loss:0.03590559586882591, val_mae:0.11367303878068924, val_mse:0.03590559586882591, val_rmse:0.14694413542747498</metrics>
			<metrics> epoch:94 loss:0.04430733621120453 mae:0.11923567205667496, mse:0.04430733621120453, rmse:0.1663721799850464, val_loss:0.03599916771054268, val_mae:0.11050859093666077, val_mse:0.03599916771054268, val_rmse:0.14372135698795319</metrics>
			<metrics> epoch:95 loss:0.043861113488674164 mae:0.11842785775661469, mse:0.043861113488674164, rmse:0.16405969858169556, val_loss:0.03318442404270172, val_mae:0.10245557129383087, val_mse:0.03318442404270172, val_rmse:0.13531655073165894</metrics>
			<metrics> epoch:96 loss:0.0453389436006546 mae:0.12098664790391922, mse:0.0453389436006546, rmse:0.16734997928142548, val_loss:0.03303678333759308, val_mae:0.10346616804599762, val_mse:0.03303678333759308, val_rmse:0.1344648152589798</metrics>
			<metrics> epoch:97 loss:0.04389457777142525 mae:0.1188635602593422, mse:0.04389457777142525, rmse:0.16447274386882782, val_loss:0.03445889428257942, val_mae:0.10539329051971436, val_mse:0.03445889428257942, val_rmse:0.13744117319583893</metrics>
			<metrics> epoch:98 loss:0.04386446997523308 mae:0.11940087378025055, mse:0.04386446997523308, rmse:0.16551139950752258, val_loss:0.03315002843737602, val_mae:0.10260698199272156, val_mse:0.03315002843737602, val_rmse:0.13444240391254425</metrics>
			<metrics> epoch:99 loss:0.04431666061282158 mae:0.119584821164608, mse:0.04431666061282158, rmse:0.16470696032047272, val_loss:0.03283558413386345, val_mae:0.10338441282510757, val_mse:0.03283558413386345, val_rmse:0.13498447835445404</metrics>
		</history>
	</model>
	<data>
		<row> train/prediction: 0.0/[0.02045987] </row>
		<row> train/prediction: 0.0/[0.02197136] </row>
		<row> train/prediction: 0.0/[0.02358849] </row>
		<row> train/prediction: 0.0/[0.02394447] </row>
		<row> train/prediction: 0.0/[0.02445346] </row>
		<row> train/prediction: 0.0/[0.02492869] </row>
		<row> train/prediction: 0.0/[0.02504295] </row>
		<row> train/prediction: 0.0/[0.02567276] </row>
		<row> train/prediction: 0.0/[0.02639858] </row>
		<row> train/prediction: 0.0/[0.02647623] </row>
		<row> train/prediction: 0.0/[0.02637091] </row>
		<row> train/prediction: 0.0/[0.02632508] </row>
		<row> train/prediction: 0.0/[0.02625373] </row>
		<row> train/prediction: 0.0/[0.02610961] </row>
		<row> train/prediction: 0.0/[0.02543649] </row>
		<row> train/prediction: 0.0/[0.02464253] </row>
		<row> train/prediction: 0.0/[0.02459374] </row>
		<row> train/prediction: 0.0/[0.02544569] </row>
		<row> train/prediction: 0.0/[0.02565019] </row>
		<row> train/prediction: 0.0/[0.02566897] </row>
		<row> train/prediction: 0.0/[0.02476285] </row>
		<row> train/prediction: 0.0/[0.02134819] </row>
		<row> train/prediction: 0.0/[0.02166265] </row>
		<row> train/prediction: 0.0/[0.0290568] </row>
		<row> train/prediction: 0.0/[0.03022422] </row>
		<row> train/prediction: 0.0/[0.0237444] </row>
		<row> train/prediction: 0.0/[0.02111104] </row>
		<row> train/prediction: 0.0/[0.02553881] </row>
		<row> train/prediction: 0.0/[0.03334371] </row>
		<row> train/prediction: 0.0/[0.03194894] </row>
		<row> train/prediction: 0.0/[0.02430058] </row>
		<row> train/prediction: 0.0/[0.02072499] </row>
		<row> train/prediction: 0.0/[0.01154202] </row>
		<row> train/prediction: 0.0/[0.00228229] </row>
		<row> train/prediction: 0.0/[0.00146279] </row>
		<row> train/prediction: 0.0/[0.00717994] </row>
		<row> train/prediction: 0.0/[0.01269274] </row>
		<row> train/prediction: 0.0/[0.063761] </row>
		<row> train/prediction: 0.0/[0.13372716] </row>
		<row> train/prediction: 0.0/[0.14536548] </row>
		<row> train/prediction: 0.0/[0.17125821] </row>
		<row> train/prediction: 0.0/[0.22748977] </row>
		<row> train/prediction: 0.0/[0.24358702] </row>
		<row> train/prediction: 0.0/[0.24971348] </row>
		<row> train/prediction: 0.0/[0.23845738] </row>
		<row> train/prediction: 0.0/[0.20722246] </row>
		<row> train/prediction: 0.0/[0.1229196] </row>
		<row> train/prediction: 0.0/[0.06338603] </row>
		<row> train/prediction: 0.0/[0.05006041] </row>
		<row> train/prediction: 0.0/[0.04352785] </row>
		<row> train/prediction: 0.0/[0.03684936] </row>
		<row> train/prediction: 0.0/[0.03315013] </row>
		<row> train/prediction: 0.0/[0.03431992] </row>
		<row> train/prediction: 0.0/[0.03759733] </row>
		<row> train/prediction: 0.0/[0.03722113] </row>
		<row> train/prediction: 0.0/[0.03388498] </row>
		<row> train/prediction: 0.0/[0.02994318] </row>
		<row> train/prediction: 0.0/[0.02819192] </row>
		<row> train/prediction: 0.0/[0.03027394] </row>
		<row> train/prediction: 0.0/[0.03588355] </row>
		<row> train/prediction: 0.0/[0.04214774] </row>
		<row> train/prediction: 0.0/[0.04464234] </row>
		<row> train/prediction: 0.0/[0.04245277] </row>
		<row> train/prediction: 0.0/[0.04083505] </row>
		<row> train/prediction: 0.0/[0.0420142] </row>
		<row> train/prediction: 0.0/[0.03497934] </row>
		<row> train/prediction: 0.0/[0.02415268] </row>
		<row> train/prediction: 0.0/[0.01766496] </row>
		<row> train/prediction: 0.0/[0.01191964] </row>
		<row> train/prediction: 0.0/[0.00640336] </row>
		<row> train/prediction: 0.0/[0.0063237] </row>
		<row> train/prediction: 0.0/[0.02598239] </row>
		<row> train/prediction: 0.0/[0.03118597] </row>
		<row> train/prediction: 0.0/[0.02905315] </row>
		<row> train/prediction: 0.0/[0.0274032] </row>
		<row> train/prediction: 0.0/[0.03283327] </row>
		<row> train/prediction: 0.0/[0.04410162] </row>
		<row> train/prediction: 0.0/[0.0462881] </row>
		<row> train/prediction: 0.0/[0.04315805] </row>
		<row> train/prediction: 0.0/[0.03503533] </row>
		<row> train/prediction: 0.0/[0.02666066] </row>
		<row> train/prediction: 0.0/[0.02086013] </row>
		<row> train/prediction: 0.0/[0.01517833] </row>
		<row> train/prediction: 0.0/[0.00792317] </row>
		<row> train/prediction: 0.0/[0.00350672] </row>
		<row> train/prediction: 0.0/[0.00722335] </row>
		<row> train/prediction: 0.0/[0.00553527] </row>
		<row> train/prediction: 0.0/[-0.00767322] </row>
		<row> train/prediction: 0.0/[-0.02292673] </row>
		<row> train/prediction: 0.0/[-0.0282271] </row>
		<row> train/prediction: 0.0/[-0.01943338] </row>
		<row> train/prediction: 0.0/[-0.01043222] </row>
		<row> train/prediction: 0.0/[-0.0008365] </row>
		<row> train/prediction: 0.0/[0.00884793] </row>
		<row> train/prediction: 0.0/[0.01450046] </row>
		<row> train/prediction: 0.0/[0.01247174] </row>
		<row> train/prediction: 0.0/[0.00499146] </row>
		<row> train/prediction: 0.0/[-0.00337413] </row>
		<row> train/prediction: 0.0/[-0.00704652] </row>
		<row> train/prediction: 0.0/[-0.00035084] </row>
		<row> train/prediction: 0.0/[0.0190412] </row>
		<row> train/prediction: 0.4/[0.04689863] </row>
		<row> train/prediction: 0.4/[0.07407518] </row>
		<row> train/prediction: 0.4/[0.11548875] </row>
		<row> train/prediction: 0.4/[0.17866105] </row>
		<row> train/prediction: 0.4/[0.22789147] </row>
		<row> train/prediction: 0.4/[0.23701951] </row>
		<row> train/prediction: 0.4/[0.22455665] </row>
		<row> train/prediction: 0.4/[0.21180898] </row>
		<row> train/prediction: 0.4/[0.19425866] </row>
		<row> train/prediction: 0.4/[0.16972673] </row>
		<row> train/prediction: 0.4/[0.14875087] </row>
		<row> train/prediction: 0.0/[0.1306769] </row>
		<row> train/prediction: 0.0/[0.10605437] </row>
		<row> train/prediction: 0.0/[0.08391067] </row>
		<row> train/prediction: 0.0/[0.07447293] </row>
		<row> train/prediction: 0.0/[0.06899275] </row>
		<row> train/prediction: 0.0/[0.05740581] </row>
		<row> train/prediction: 0.0/[0.04888928] </row>
		<row> train/prediction: 0.0/[0.05008854] </row>
		<row> train/prediction: 0.0/[0.05130589] </row>
		<row> train/prediction: 0.0/[0.05029684] </row>
		<row> train/prediction: 0.0/[0.050861] </row>
		<row> train/prediction: 0.0/[0.04685713] </row>
		<row> train/prediction: 0.0/[0.04213321] </row>
		<row> train/prediction: 0.0/[0.03485802] </row>
		<row> train/prediction: 0.0/[0.02510931] </row>
		<row> train/prediction: 0.0/[0.02225713] </row>
		<row> train/prediction: 0.0/[0.03213919] </row>
		<row> train/prediction: 0.0/[0.04529387] </row>
		<row> train/prediction: 0.0/[0.05462355] </row>
		<row> train/prediction: 0.0/[0.06194126] </row>
		<row> train/prediction: 0.0/[0.06592049] </row>
		<row> train/prediction: 0.0/[0.06511284] </row>
		<row> train/prediction: 0.0/[0.06250042] </row>
		<row> train/prediction: 0.0/[0.05652311] </row>
		<row> train/prediction: 0.0/[0.04632128] </row>
		<row> train/prediction: 0.0/[0.03779801] </row>
		<row> train/prediction: 0.0/[0.02525529] </row>
		<row> train/prediction: 0.0/[0.01929436] </row>
		<row> train/prediction: 0.0/[0.01818312] </row>
		<row> train/prediction: 0.0/[0.06460286] </row>
		<row> train/prediction: 0.3/[0.14082348] </row>
		<row> train/prediction: 0.3/[0.13931186] </row>
		<row> train/prediction: 0.3/[0.14259154] </row>
		<row> train/prediction: 0.3/[0.16375384] </row>
		<row> train/prediction: 0.3/[0.18722442] </row>
		<row> train/prediction: 0.3/[0.19845885] </row>
		<row> train/prediction: 0.3/[0.20255703] </row>
		<row> train/prediction: 0.3/[0.20926431] </row>
		<row> train/prediction: 0.3/[0.22090116] </row>
		<row> train/prediction: 0.3/[0.22835147] </row>
		<row> train/prediction: 0.3/[0.19905151] </row>
		<row> train/prediction: 0.0/[0.14507908] </row>
		<row> train/prediction: 0.0/[0.1044386] </row>
		<row> train/prediction: 0.0/[0.08705506] </row>
		<row> train/prediction: 0.0/[0.07642832] </row>
		<row> train/prediction: 0.0/[0.0642163] </row>
		<row> train/prediction: 0.0/[0.04899915] </row>
		<row> train/prediction: 0.0/[0.03070477] </row>
		<row> train/prediction: 0.0/[0.00978897] </row>
		<row> train/prediction: 0.0/[-0.0055964] </row>
		<row> train/prediction: 0.0/[-0.00200976] </row>
		<row> train/prediction: 0.0/[0.00615222] </row>
		<row> train/prediction: 0.0/[0.00113788] </row>
		<row> train/prediction: 0.0/[-0.00204515] </row>
		<row> train/prediction: 0.0/[0.00077114] </row>
		<row> train/prediction: 0.0/[0.02323046] </row>
		<row> train/prediction: 0.0/[0.05148214] </row>
		<row> train/prediction: 0.0/[0.07320432] </row>
		<row> train/prediction: 0.0/[0.09384617] </row>
		<row> train/prediction: 0.0/[0.11598594] </row>
		<row> train/prediction: 0.0/[0.13775694] </row>
		<row> train/prediction: 0.0/[0.1634939] </row>
		<row> train/prediction: 0.0/[0.20163038] </row>
		<row> train/prediction: 0.0/[0.23269376] </row>
		<row> train/prediction: 0.0/[0.2296294] </row>
		<row> train/prediction: 0.0/[0.19246551] </row>
		<row> train/prediction: 0.0/[0.15348513] </row>
		<row> train/prediction: 0.0/[0.13997042] </row>
		<row> train/prediction: 0.0/[0.13798699] </row>
		<row> train/prediction: 0.0/[0.11521927] </row>
		<row> train/prediction: 0.0/[0.08460137] </row>
		<row> train/prediction: 0.0/[0.06699407] </row>
		<row> train/prediction: 0.0/[0.04912698] </row>
		<row> train/prediction: 0.0/[0.03865768] </row>
		<row> train/prediction: 0.0/[0.03266548] </row>
		<row> train/prediction: 0.0/[0.02678564] </row>
		<row> train/prediction: 0.0/[0.02811334] </row>
		<row> train/prediction: 0.0/[0.03799006] </row>
		<row> train/prediction: 0.0/[0.04478662] </row>
		<row> train/prediction: 0.0/[0.04713] </row>
		<row> train/prediction: 0.0/[0.04653478] </row>
		<row> train/prediction: 0.0/[0.04225174] </row>
		<row> train/prediction: 0.0/[0.03403657] </row>
		<row> train/prediction: 0.0/[0.02415534] </row>
		<row> train/prediction: 0.0/[0.02995756] </row>
		<row> train/prediction: 0.0/[0.05113636] </row>
		<row> train/prediction: 0.0/[0.06341653] </row>
		<row> train/prediction: 0.0/[0.07622497] </row>
		<row> train/prediction: 0.0/[0.08537991] </row>
		<row> train/prediction: 0.0/[0.09001207] </row>
		<row> train/prediction: 0.0/[0.09116169] </row>
		<row> train/prediction: 0.0/[0.09115703] </row>
		<row> train/prediction: 0.0/[0.08760895] </row>
		<row> train/prediction: 0.0/[0.07952593] </row>
		<row> train/prediction: 0.0/[0.07002848] </row>
		<row> train/prediction: 0.0/[0.06498411] </row>
		<row> train/prediction: 0.0/[0.06807974] </row>
		<row> train/prediction: 0.0/[0.09482753] </row>
		<row> train/prediction: 0.0/[0.16843158] </row>
		<row> train/prediction: 0.0/[0.21042642] </row>
		<row> train/prediction: 0.0/[0.23114473] </row>
		<row> train/prediction: 0.0/[0.22960389] </row>
		<row> train/prediction: 0.0/[0.23485008] </row>
		<row> train/prediction: 0.0/[0.2178041] </row>
		<row> train/prediction: 0.0/[0.16703525] </row>
		<row> train/prediction: 0.0/[0.11702343] </row>
		<row> train/prediction: 0.0/[0.08612437] </row>
		<row> train/prediction: 0.0/[0.06688528] </row>
		<row> train/prediction: 0.0/[0.05212494] </row>
		<row> train/prediction: 0.0/[0.03642973] </row>
		<row> train/prediction: 0.0/[0.03061515] </row>
		<row> train/prediction: 1.0/[0.03850827] </row>
		<row> train/prediction: 1.0/[0.06159586] </row>
		<row> train/prediction: 1.0/[0.09793109] </row>
		<row> train/prediction: 1.0/[0.12408381] </row>
		<row> train/prediction: 1.0/[0.14335218] </row>
		<row> train/prediction: 1.0/[0.1609971] </row>
		<row> train/prediction: 1.0/[0.1550188] </row>
		<row> train/prediction: 1.0/[0.13651453] </row>
		<row> train/prediction: 1.0/[0.1186851] </row>
		<row> train/prediction: 1.0/[0.10525625] </row>
		<row> train/prediction: 1.0/[0.09457539] </row>
		<row> train/prediction: 0.0/[0.08859394] </row>
		<row> train/prediction: 0.0/[0.08493924] </row>
		<row> train/prediction: 0.0/[0.07764254] </row>
		<row> train/prediction: 0.0/[0.06633396] </row>
		<row> train/prediction: 0.0/[0.05737988] </row>
		<row> train/prediction: 0.0/[0.04296385] </row>
		<row> train/prediction: 0.0/[0.02788174] </row>
		<row> train/prediction: 0.0/[0.02500102] </row>
		<row> train/prediction: 0.0/[0.03647928] </row>
		<row> train/prediction: 0.0/[0.03486677] </row>
		<row> train/prediction: 0.0/[0.02947345] </row>
		<row> train/prediction: 0.0/[0.05335896] </row>
		<row> train/prediction: 0.0/[0.12548986] </row>
		<row> train/prediction: 0.0/[0.17853755] </row>
		<row> train/prediction: 0.0/[0.19257459] </row>
		<row> train/prediction: 0.0/[0.1895763] </row>
		<row> train/prediction: 0.0/[0.17755967] </row>
		<row> train/prediction: 0.0/[0.18125615] </row>
		<row> train/prediction: 0.0/[0.17951968] </row>
		<row> train/prediction: 0.0/[0.16713503] </row>
		<row> train/prediction: 0.0/[0.15343979] </row>
		<row> train/prediction: 0.0/[0.13744956] </row>
		<row> train/prediction: 0.0/[0.11738455] </row>
		<row> train/prediction: 0.0/[0.10075922] </row>
		<row> train/prediction: 0.0/[0.0907791] </row>
		<row> train/prediction: 0.0/[0.08368172] </row>
		<row> train/prediction: 0.0/[0.07906199] </row>
		<row> train/prediction: 0.0/[0.07789471] </row>
		<row> train/prediction: 0.0/[0.07872468] </row>
		<row> train/prediction: 0.0/[0.08118987] </row>
		<row> train/prediction: 0.0/[0.08716403] </row>
		<row> train/prediction: 0.0/[0.09609556] </row>
		<row> train/prediction: 0.0/[0.1084764] </row>
		<row> train/prediction: 0.0/[0.12026075] </row>
		<row> train/prediction: 0.0/[0.12841174] </row>
		<row> train/prediction: 0.0/[0.13690218] </row>
		<row> train/prediction: 0.0/[0.14520401] </row>
		<row> train/prediction: 0.0/[0.15086345] </row>
		<row> train/prediction: 0.0/[0.15870589] </row>
		<row> train/prediction: 0.0/[0.169043] </row>
		<row> train/prediction: 0.0/[0.17683578] </row>
		<row> train/prediction: 0.0/[0.18532819] </row>
		<row> train/prediction: 0.0/[0.19573493] </row>
		<row> train/prediction: 0.0/[0.20537466] </row>
		<row> train/prediction: 0.0/[0.21437135] </row>
		<row> train/prediction: 0.0/[0.22456086] </row>
		<row> train/prediction: 0.0/[0.23265675] </row>
		<row> train/prediction: 0.0/[0.24126443] </row>
		<row> train/prediction: 0.0/[0.2622494] </row>
		<row> train/prediction: 0.0/[0.29568955] </row>
		<row> train/prediction: 0.0/[0.32400095] </row>
		<row> train/prediction: 0.0/[0.337687] </row>
		<row> train/prediction: 0.0/[0.34299764] </row>
		<row> train/prediction: 0.0/[0.34412524] </row>
		<row> train/prediction: 0.0/[0.34395653] </row>
		<row> train/prediction: 0.0/[0.3443533] </row>
		<row> train/prediction: 0.0/[0.34396094] </row>
		<row> train/prediction: 0.0/[0.34285098] </row>
		<row> train/prediction: 0.0/[0.34274372] </row>
		<row> train/prediction: 0.0/[0.3422012] </row>
		<row> train/prediction: 0.0/[0.3405209] </row>
		<row> train/prediction: 0.0/[0.3417593] </row>
		<row> train/prediction: 0.0/[0.34281206] </row>
		<row> train/prediction: 0.0/[0.3403959] </row>
		<row> train/prediction: 0.0/[0.34109414] </row>
		<row> train/prediction: 0.0/[0.34245163] </row>
		<row> train/prediction: 0.0/[0.34069198] </row>
		<row> train/prediction: 0.0/[0.34092224] </row>
		<row> train/prediction: 0.0/[0.34243137] </row>
		<row> train/prediction: 0.0/[0.34101337] </row>
		<row> train/prediction: 0.0/[0.3409235] </row>
		<row> train/prediction: 0.0/[0.3423448] </row>
		<row> train/prediction: 0.0/[0.34138846] </row>
		<row> train/prediction: 0.0/[0.34112713] </row>
		<row> train/prediction: 0.0/[0.3421788] </row>
		<row> train/prediction: 0.0/[0.34116885] </row>
		<row> train/prediction: 0.0/[0.3394389] </row>
		<row> train/prediction: 0.0/[0.34219655] </row>
		<row> train/prediction: 0.0/[0.34108815] </row>
		<row> train/prediction: 0.0/[0.3385833] </row>
		<row> train/prediction: 0.0/[0.33972132] </row>
		<row> train/prediction: 0.0/[0.33681622] </row>
		<row> train/prediction: 0.0/[0.33154592] </row>
		<row> train/prediction: 0.0/[0.32548907] </row>
		<row> train/prediction: 0.0/[0.31183696] </row>
		<row> train/prediction: 0.0/[0.2926485] </row>
		<row> train/prediction: 0.0/[0.26136777] </row>
		<row> train/prediction: 0.0/[0.22449684] </row>
		<row> train/prediction: 0.0/[0.19350913] </row>
		<row> train/prediction: 0.0/[0.17048927] </row>
		<row> train/prediction: 0.0/[0.16931334] </row>
		<row> train/prediction: 0.0/[0.16182369] </row>
		<row> train/prediction: 0.0/[0.15511787] </row>
		<row> train/prediction: 0.0/[0.14732891] </row>
		<row> train/prediction: 0.0/[0.1334166] </row>
		<row> train/prediction: 0.0/[0.11196756] </row>
		<row> train/prediction: 0.0/[0.08541606] </row>
		<row> train/prediction: 0.0/[0.06096389] </row>
		<row> train/prediction: 0.0/[0.04536578] </row>
		<row> train/prediction: 0.0/[0.03683046] </row>
		<row> train/prediction: 0.0/[0.0312457] </row>
		<row> train/prediction: 0.0/[0.02585705] </row>
		<row> train/prediction: 0.0/[0.02071152] </row>
		<row> train/prediction: 0.0/[0.0177139] </row>
		<row> train/prediction: 0.0/[0.01752822] </row>
		<row> train/prediction: 0.0/[0.01844616] </row>
		<row> train/prediction: 0.0/[0.0191204] </row>
		<row> train/prediction: 0.0/[0.01990198] </row>
		<row> train/prediction: 0.0/[0.02089099] </row>
		<row> train/prediction: 0.0/[0.02196656] </row>
		<row> train/prediction: 0.0/[0.0232592] </row>
		<row> train/prediction: 0.0/[0.02434321] </row>
		<row> train/prediction: 0.0/[0.02470919] </row>
		<row> train/prediction: 0.0/[0.02539966] </row>
		<row> train/prediction: 0.0/[0.02685264] </row>
		<row> train/prediction: 0.0/[0.02805602] </row>
		<row> train/prediction: 0.0/[0.02867479] </row>
		<row> train/prediction: 0.0/[0.02921633] </row>
		<row> train/prediction: 0.0/[0.02962139] </row>
		<row> train/prediction: 0.0/[0.02929833] </row>
		<row> train/prediction: 0.0/[0.02811438] </row>
		<row> train/prediction: 0.0/[0.02527229] </row>
		<row> train/prediction: 0.0/[0.02025364] </row>
		<row> train/prediction: 0.0/[0.01486618] </row>
		<row> train/prediction: 0.0/[0.02081085] </row>
		<row> train/prediction: 0.0/[0.03789838] </row>
		<row> train/prediction: 0.0/[0.02120264] </row>
		<row> train/prediction: 0.0/[0.01264667] </row>
		<row> train/prediction: 0.0/[0.01572292] </row>
		<row> train/prediction: 0.0/[0.02379575] </row>
		<row> train/prediction: 0.0/[0.03387533] </row>
		<row> train/prediction: 0.0/[0.03465121] </row>
		<row> train/prediction: 0.0/[0.03071655] </row>
		<row> train/prediction: 0.0/[0.03101701] </row>
		<row> train/prediction: 0.0/[0.03568206] </row>
		<row> train/prediction: 0.0/[0.03907876] </row>
		<row> train/prediction: 0.0/[0.03792628] </row>
		<row> train/prediction: 0.0/[0.03260588] </row>
		<row> train/prediction: 0.0/[0.02242252] </row>
		<row> train/prediction: 0.0/[0.01578425] </row>
		<row> train/prediction: 0.0/[0.01821272] </row>
		<row> train/prediction: 0.0/[0.02889433] </row>
		<row> train/prediction: 0.0/[0.0360438] </row>
		<row> train/prediction: 0.0/[0.03568808] </row>
		<row> train/prediction: 0.0/[0.03309699] </row>
		<row> train/prediction: 0.0/[0.03423317] </row>
		<row> train/prediction: 0.0/[0.04041399] </row>
		<row> train/prediction: 0.0/[0.04463765] </row>
		<row> train/prediction: 0.0/[0.04295735] </row>
		<row> train/prediction: 0.0/[0.04141039] </row>
		<row> train/prediction: 0.0/[0.04618379] </row>
		<row> train/prediction: 0.0/[0.04970875] </row>
		<row> train/prediction: 0.0/[0.05429671] </row>
		<row> train/prediction: 0.0/[0.08051448] </row>
		<row> train/prediction: 0.0/[0.14201961] </row>
		<row> train/prediction: 0.0/[0.19262318] </row>
		<row> train/prediction: 0.0/[0.2120907] </row>
		<row> train/prediction: 0.0/[0.21042317] </row>
		<row> train/prediction: 0.2/[0.20846674] </row>
		<row> train/prediction: 0.2/[0.21049562] </row>
		<row> train/prediction: 0.2/[0.21635586] </row>
		<row> train/prediction: 0.2/[0.20393196] </row>
		<row> train/prediction: 0.2/[0.16837558] </row>
		<row> train/prediction: 0.2/[0.1301932] </row>
		<row> train/prediction: 0.2/[0.10637587] </row>
		<row> train/prediction: 0.2/[0.09888569] </row>
		<row> train/prediction: 0.2/[0.09909152] </row>
		<row> train/prediction: 0.2/[0.10538499] </row>
		<row> train/prediction: 0.2/[0.11231905] </row>
		<row> train/prediction: 0.0/[0.11572684] </row>
		<row> train/prediction: 0.0/[0.12149478] </row>
		<row> train/prediction: 0.0/[0.1249125] </row>
		<row> train/prediction: 0.0/[0.11261049] </row>
		<row> train/prediction: 0.0/[0.09332133] </row>
		<row> train/prediction: 0.0/[0.07937232] </row>
		<row> train/prediction: 0.0/[0.06752287] </row>
		<row> train/prediction: 0.0/[0.05569068] </row>
		<row> train/prediction: 0.0/[0.04545785] </row>
		<row> train/prediction: 0.0/[0.0353793] </row>
		<row> train/prediction: 0.0/[0.02452497] </row>
		<row> train/prediction: 0.0/[0.01431288] </row>
		<row> train/prediction: 0.0/[0.0059649] </row>
		<row> train/prediction: 0.0/[0.00246792] </row>
		<row> train/prediction: 0.0/[0.00632558] </row>
		<row> train/prediction: 0.0/[0.01120741] </row>
		<row> train/prediction: 0.0/[0.02370533] </row>
		<row> train/prediction: 0.0/[0.06782919] </row>
		<row> train/prediction: 0.0/[0.13925886] </row>
		<row> train/prediction: 0.0/[0.1933235] </row>
		<row> train/prediction: 0.9/[0.21723804] </row>
		<row> train/prediction: 0.9/[0.22017735] </row>
		<row> train/prediction: 0.9/[0.22148156] </row>
		<row> train/prediction: 0.9/[0.21678069] </row>
		<row> train/prediction: 0.9/[0.20559335] </row>
		<row> train/prediction: 0.9/[0.1855146] </row>
		<row> train/prediction: 0.9/[0.15955901] </row>
		<row> train/prediction: 0.9/[0.1266124] </row>
		<row> train/prediction: 0.9/[0.08348741] </row>
		<row> train/prediction: 0.9/[0.05781023] </row>
		<row> train/prediction: 0.9/[0.04951631] </row>
		<row> train/prediction: 0.0/[0.04723213] </row>
		<row> train/prediction: 0.0/[0.05390006] </row>
		<row> train/prediction: 0.0/[0.05462536] </row>
		<row> train/prediction: 0.0/[0.03776819] </row>
		<row> train/prediction: 0.0/[0.02532652] </row>
		<row> train/prediction: 0.0/[0.02038111] </row>
		<row> train/prediction: 0.0/[0.01809876] </row>
		<row> train/prediction: 0.0/[0.01819725] </row>
		<row> train/prediction: 0.0/[0.01984596] </row>
		<row> train/prediction: 0.0/[0.02092239] </row>
		<row> train/prediction: 0.0/[0.02162404] </row>
		<row> train/prediction: 0.0/[0.02277797] </row>
		<row> train/prediction: 0.0/[0.02434055] </row>
		<row> train/prediction: 0.0/[0.02752099] </row>
		<row> train/prediction: 0.0/[0.03121578] </row>
		<row> train/prediction: 0.0/[0.03050706] </row>
		<row> train/prediction: 0.0/[0.02838903] </row>
		<row> train/prediction: 0.0/[0.02673998] </row>
		<row> train/prediction: 0.0/[0.02598725] </row>
		<row> train/prediction: 0.0/[0.02996369] </row>
		<row> train/prediction: 0.0/[0.0333434] </row>
		<row> train/prediction: 0.0/[0.02989674] </row>
		<row> train/prediction: 0.0/[0.02918918] </row>
		<row> train/prediction: 0.0/[0.04242282] </row>
		<row> train/prediction: 0.0/[0.07177313] </row>
		<row> train/prediction: 0.0/[0.09142959] </row>
		<row> train/prediction: 0.0/[0.07649034] </row>
		<row> train/prediction: 0.0/[0.04379138] </row>
		<row> train/prediction: 0.0/[0.01889986] </row>
		<row> train/prediction: 0.0/[0.01746361] </row>
		<row> train/prediction: 0.0/[0.03905339] </row>
		<row> train/prediction: 0.0/[0.06760652] </row>
		<row> train/prediction: 0.0/[0.09253031] </row>
		<row> train/prediction: 0.0/[0.0983723] </row>
		<row> train/prediction: 0.0/[0.07861464] </row>
		<row> train/prediction: 0.0/[0.05241985] </row>
		<row> train/prediction: 0.0/[0.03904076] </row>
		<row> train/prediction: 0.0/[0.03369696] </row>
		<row> train/prediction: 0.0/[0.03108956] </row>
		<row> train/prediction: 0.0/[0.03057764] </row>
		<row> train/prediction: 0.0/[0.03312995] </row>
		<row> train/prediction: 0.0/[0.0337228] </row>
		<row> train/prediction: 0.0/[0.02392627] </row>
		<row> train/prediction: 0.0/[0.0068432] </row>
		<row> train/prediction: 0.0/[-0.00472356] </row>
		<row> train/prediction: 0.0/[-0.00725999] </row>
		<row> train/prediction: 0.0/[-0.0043002] </row>
		<row> train/prediction: 0.0/[0.00448118] </row>
		<row> train/prediction: 0.0/[0.01326881] </row>
		<row> train/prediction: 0.0/[0.01222266] </row>
		<row> train/prediction: 0.0/[0.00536898] </row>
		<row> train/prediction: 0.0/[0.0014855] </row>
		<row> train/prediction: 0.0/[0.01576834] </row>
		<row> train/prediction: 0.0/[0.02264639] </row>
		<row> train/prediction: 0.0/[0.02067628] </row>
		<row> train/prediction: 0.0/[0.01860064] </row>
		<row> train/prediction: 0.0/[0.01149049] </row>
		<row> train/prediction: 0.0/[0.00587925] </row>
		<row> train/prediction: 0.0/[0.00537469] </row>
		<row> train/prediction: 0.0/[0.00751766] </row>
		<row> train/prediction: 0.0/[0.00688379] </row>
		<row> train/prediction: 0.0/[0.00501525] </row>
		<row> train/prediction: 0.0/[0.00434972] </row>
		<row> train/prediction: 0.0/[0.00210085] </row>
		<row> train/prediction: 0.0/[-0.00062368] </row>
		<row> train/prediction: 0.0/[-0.00070397] </row>
		<row> train/prediction: 0.0/[0.00221674] </row>
		<row> train/prediction: 0.0/[0.01740347] </row>
		<row> train/prediction: 0.0/[0.06770355] </row>
		<row> train/prediction: 0.0/[0.11724603] </row>
		<row> train/prediction: 0.0/[0.1464608] </row>
		<row> train/prediction: 0.67/[0.18160567] </row>
		<row> train/prediction: 0.67/[0.23764089] </row>
		<row> train/prediction: 0.67/[0.24058348] </row>
		<row> train/prediction: 0.67/[0.22396597] </row>
		<row> train/prediction: 0.67/[0.1851593] </row>
		<row> train/prediction: 0.67/[0.16651669] </row>
		<row> train/prediction: 0.67/[0.15290292] </row>
		<row> train/prediction: 0.67/[0.1363622] </row>
		<row> train/prediction: 0.67/[0.11054139] </row>
		<row> train/prediction: 0.67/[0.08235103] </row>
		<row> train/prediction: 0.01/[0.0572216] </row>
		<row> train/prediction: 0.01/[0.03894018] </row>
		<row> train/prediction: 0.01/[0.03122987] </row>
		<row> train/prediction: 0.01/[0.02866783] </row>
		<row> train/prediction: 0.01/[0.03028094] </row>
		<row> train/prediction: 0.01/[0.04054431] </row>
		<row> train/prediction: 0.01/[0.07109396] </row>
		<row> train/prediction: 0.01/[0.10998787] </row>
		<row> train/prediction: 0.01/[0.14098024] </row>
		<row> train/prediction: 0.01/[0.15284792] </row>
		<row> train/prediction: 0.01/[0.1428062] </row>
		<row> train/prediction: 0.0/[0.11217543] </row>
		<row> train/prediction: 0.0/[0.0904147] </row>
		<row> train/prediction: 0.0/[0.08575113] </row>
		<row> train/prediction: 0.0/[0.08610318] </row>
		<row> train/prediction: 0.0/[0.07504687] </row>
		<row> train/prediction: 0.0/[0.05895661] </row>
		<row> train/prediction: 0.0/[0.04807123] </row>
		<row> train/prediction: 0.0/[0.04668458] </row>
		<row> train/prediction: 0.0/[0.04776352] </row>
		<row> train/prediction: 0.0/[0.05082789] </row>
		<row> train/prediction: 0.0/[0.06292482] </row>
		<row> train/prediction: 0.0/[0.07746999] </row>
		<row> train/prediction: 0.0/[0.09179828] </row>
		<row> train/prediction: 0.0/[0.12125281] </row>
		<row> train/prediction: 0.0/[0.1512223] </row>
		<row> train/prediction: 0.0/[0.16074675] </row>
		<row> train/prediction: 0.0/[0.17088631] </row>
		<row> train/prediction: 0.0/[0.18480879] </row>
		<row> train/prediction: 0.0/[0.1797005] </row>
		<row> train/prediction: 0.0/[0.1754466] </row>
		<row> train/prediction: 0.0/[0.16967136] </row>
		<row> train/prediction: 0.0/[0.15462816] </row>
		<row> train/prediction: 0.0/[0.1300453] </row>
		<row> train/prediction: 0.0/[0.09349369] </row>
		<row> train/prediction: 0.0/[0.05484315] </row>
		<row> train/prediction: 0.0/[0.0313089] </row>
		<row> train/prediction: 0.0/[0.02079452] </row>
		<row> train/prediction: 0.0/[0.0182398] </row>
		<row> train/prediction: 0.0/[0.02044529] </row>
		<row> train/prediction: 0.0/[0.02239042] </row>
		<row> train/prediction: 0.0/[0.02287662] </row>
		<row> train/prediction: 0.0/[0.02341571] </row>
		<row> train/prediction: 0.0/[0.02434904] </row>
		<row> train/prediction: 0.0/[0.02515502] </row>
		<row> train/prediction: 0.0/[0.02586743] </row>
		<row> train/prediction: 0.0/[0.02614561] </row>
		<row> train/prediction: 0.0/[0.02574123] </row>
		<row> train/prediction: 0.0/[0.02485536] </row>
		<row> train/prediction: 0.0/[0.02422217] </row>
		<row> train/prediction: 0.0/[0.0244447] </row>
		<row> train/prediction: 0.0/[0.0250948] </row>
		<row> train/prediction: 0.0/[0.0255862] </row>
		<row> train/prediction: 0.0/[0.02640026] </row>
		<row> train/prediction: 0.0/[0.02812319] </row>
		<row> train/prediction: 0.0/[0.03070309] </row>
		<row> train/prediction: 0.0/[0.03389229] </row>
		<row> train/prediction: 0.0/[0.03637159] </row>
		<row> train/prediction: 0.0/[0.03786326] </row>
		<row> train/prediction: 0.0/[0.03871188] </row>
		<row> train/prediction: 0.0/[0.0397808] </row>
		<row> train/prediction: 0.0/[0.04187946] </row>
		<row> train/prediction: 0.0/[0.0428847] </row>
		<row> train/prediction: 0.0/[0.04212144] </row>
		<row> train/prediction: 0.0/[0.03954872] </row>
		<row> train/prediction: 0.0/[0.03528642] </row>
		<row> train/prediction: 0.0/[0.03073545] </row>
		<row> train/prediction: 0.0/[0.02864356] </row>
		<row> train/prediction: 0.0/[0.02873278] </row>
		<row> train/prediction: 0.0/[0.02824905] </row>
		<row> train/prediction: 0.0/[0.02834585] </row>
		<row> train/prediction: 0.0/[0.0300022] </row>
		<row> train/prediction: 0.0/[0.03128114] </row>
		<row> train/prediction: 0.0/[0.03227792] </row>
		<row> train/prediction: 0.0/[0.0314057] </row>
		<row> train/prediction: 0.0/[0.02420163] </row>
		<row> train/prediction: 0.0/[0.01498157] </row>
		<row> train/prediction: 0.0/[0.01034833] </row>
		<row> train/prediction: 0.0/[0.01302438] </row>
		<row> train/prediction: 0.0/[0.02023865] </row>
		<row> train/prediction: 0.0/[0.01868188] </row>
		<row> train/prediction: 0.0/[0.01245981] </row>
		<row> train/prediction: 0.0/[0.00723823] </row>
		<row> train/prediction: 0.0/[0.00386275] </row>
		<row> train/prediction: 0.0/[0.00096894] </row>
		<row> train/prediction: 0.0/[-0.00020979] </row>
		<row> train/prediction: 0.0/[0.00200669] </row>
		<row> train/prediction: 0.0/[0.00610331] </row>
		<row> train/prediction: 0.0/[0.00970194] </row>
		<row> train/prediction: 0.0/[0.01173073] </row>
		<row> train/prediction: 0.0/[0.01165452] </row>
		<row> train/prediction: 0.0/[0.01043933] </row>
		<row> train/prediction: 0.0/[0.00970287] </row>
		<row> train/prediction: 0.0/[0.01101387] </row>
		<row> train/prediction: 0.0/[0.01821389] </row>
		<row> train/prediction: 0.0/[0.03167459] </row>
		<row> train/prediction: 0.0/[0.04436792] </row>
		<row> train/prediction: 0.0/[0.05537744] </row>
		<row> train/prediction: 0.0/[0.07232321] </row>
		<row> train/prediction: 0.0/[0.10345405] </row>
		<row> train/prediction: 0.0/[0.14749536] </row>
		<row> train/prediction: 0.0/[0.1918385] </row>
		<row> train/prediction: 0.0/[0.21677911] </row>
		<row> train/prediction: 0.0/[0.21924311] </row>
		<row> train/prediction: 0.0/[0.2105267] </row>
		<row> train/prediction: 0.0/[0.1993249] </row>
		<row> train/prediction: 0.0/[0.18914017] </row>
		<row> train/prediction: 0.0/[0.17717788] </row>
		<row> train/prediction: 0.0/[0.15542603] </row>
		<row> train/prediction: 0.0/[0.12062346] </row>
		<row> train/prediction: 0.0/[0.09475974] </row>
		<row> train/prediction: 0.0/[0.08095833] </row>
		<row> train/prediction: 0.0/[0.06517746] </row>
		<row> train/prediction: 0.0/[0.05045344] </row>
		<row> train/prediction: 0.0/[0.04104219] </row>
		<row> train/prediction: 0.0/[0.03200179] </row>
		<row> train/prediction: 0.0/[0.01950519] </row>
		<row> train/prediction: 0.0/[0.0115345] </row>
		<row> train/prediction: 0.0/[0.01093454] </row>
		<row> train/prediction: 0.0/[0.01202326] </row>
		<row> train/prediction: 0.0/[0.00804275] </row>
		<row> train/prediction: 0.0/[-0.00228586] </row>
		<row> train/prediction: 0.0/[-0.00552389] </row>
		<row> train/prediction: 0.0/[0.00925054] </row>
		<row> train/prediction: 0.0/[0.01852401] </row>
		<row> train/prediction: 0.0/[0.01457481] </row>
		<row> train/prediction: 0.0/[0.00852879] </row>
		<row> train/prediction: 0.0/[0.00681821] </row>
		<row> train/prediction: 0.0/[2.3707747e-05] </row>
		<row> train/prediction: 0.0/[-0.01111534] </row>
		<row> train/prediction: 0.0/[-0.01880272] </row>
		<row> train/prediction: 0.0/[-0.01728451] </row>
		<row> train/prediction: 0.0/[-0.00415372] </row>
		<row> train/prediction: 0.0/[0.00874855] </row>
		<row> train/prediction: 0.0/[0.01497506] </row>
		<row> train/prediction: 0.0/[0.01722841] </row>
		<row> train/prediction: 0.0/[0.01592034] </row>
		<row> train/prediction: 0.0/[0.01197504] </row>
		<row> train/prediction: 0.0/[0.00702176] </row>
		<row> train/prediction: 0.0/[0.00445015] </row>
		<row> train/prediction: 0.0/[0.00611034] </row>
		<row> train/prediction: 0.0/[0.00877631] </row>
		<row> train/prediction: 0.0/[0.00723775] </row>
		<row> train/prediction: 0.0/[-0.00199798] </row>
		<row> train/prediction: 0.0/[-0.01083596] </row>
		<row> train/prediction: 0.0/[-0.00486933] </row>
		<row> train/prediction: 0.0/[0.01169407] </row>
		<row> train/prediction: 0.0/[0.02588003] </row>
		<row> train/prediction: 0.0/[0.02763084] </row>
		<row> train/prediction: 0.0/[0.01891501] </row>
		<row> train/prediction: 0.0/[0.00897624] </row>
		<row> train/prediction: 0.0/[0.00109333] </row>
		<row> train/prediction: 0.0/[-0.00161334] </row>
		<row> train/prediction: 0.0/[0.01179851] </row>
		<row> train/prediction: 0.0/[0.02379952] </row>
		<row> train/prediction: 0.0/[0.0248041] </row>
		<row> train/prediction: 0.0/[0.02882437] </row>
		<row> train/prediction: 0.9/[0.03617441] </row>
		<row> train/prediction: 0.9/[0.0395746] </row>
		<row> train/prediction: 0.9/[0.0384853] </row>
		<row> train/prediction: 0.9/[0.03696553] </row>
		<row> train/prediction: 0.9/[0.03653536] </row>
		<row> train/prediction: 0.9/[0.03448029] </row>
		<row> train/prediction: 0.9/[0.02651105] </row>
		<row> train/prediction: 0.9/[0.01472174] </row>
		<row> train/prediction: 0.9/[0.00630178] </row>
		<row> train/prediction: 0.9/[0.00806459] </row>
		<row> train/prediction: 0.9/[0.02797123] </row>
		<row> train/prediction: 0.0/[0.07306645] </row>
		<row> train/prediction: 0.0/[0.15193799] </row>
		<row> train/prediction: 0.0/[0.2208732] </row>
		<row> train/prediction: 0.0/[0.2343865] </row>
		<row> train/prediction: 0.0/[0.2206775] </row>
		<row> train/prediction: 0.0/[0.21121308] </row>
		<row> train/prediction: 0.0/[0.21297902] </row>
		<row> train/prediction: 0.0/[0.21004122] </row>
		<row> train/prediction: 0.0/[0.20520493] </row>
		<row> train/prediction: 0.0/[0.1999628] </row>
		<row> train/prediction: 0.0/[0.18728042] </row>
		<row> train/prediction: 0.0/[0.14585198] </row>
		<row> train/prediction: 0.0/[0.10666901] </row>
		<row> train/prediction: 0.0/[0.09603607] </row>
		<row> train/prediction: 0.0/[0.0989978] </row>
		<row> train/prediction: 0.0/[0.10051925] </row>
		<row> train/prediction: 0.0/[0.09882955] </row>
		<row> train/prediction: 0.0/[0.09412941] </row>
		<row> train/prediction: 0.0/[0.08159547] </row>
		<row> train/prediction: 0.0/[0.06714658] </row>
		<row> train/prediction: 0.0/[0.05729111] </row>
		<row> train/prediction: 0.0/[0.04648836] </row>
		<row> train/prediction: 0.0/[0.03596254] </row>
		<row> train/prediction: 0.0/[0.02968366] </row>
		<row> train/prediction: 0.0/[0.02841368] </row>
		<row> train/prediction: 0.0/[0.02839437] </row>
		<row> train/prediction: 0.0/[0.02357975] </row>
		<row> train/prediction: 0.0/[0.01713831] </row>
		<row> train/prediction: 0.0/[0.0091672] </row>
		<row> train/prediction: 0.0/[-0.00753477] </row>
		<row> train/prediction: 0.0/[-0.02824521] </row>
		<row> train/prediction: 0.0/[-0.02666239] </row>
		<row> train/prediction: 0.0/[-0.00245171] </row>
		<row> train/prediction: 0.0/[0.01372464] </row>
		<row> train/prediction: 0.0/[0.02900904] </row>
		<row> train/prediction: 0.0/[0.03919371] </row>
		<row> train/prediction: 0.0/[0.02926244] </row>
		<row> train/prediction: 0.0/[0.00947313] </row>
		<row> train/prediction: 0.0/[-0.00045479] </row>
		<row> train/prediction: 0.0/[0.00354959] </row>
		<row> train/prediction: 0.0/[0.02679328] </row>
		<row> train/prediction: 0.0/[0.06129096] </row>
		<row> train/prediction: 0.0/[0.08111141] </row>
		<row> train/prediction: 0.0/[0.09515825] </row>
		<row> train/prediction: 0.0/[0.11494692] </row>
		<row> train/prediction: 0.0/[0.13352607] </row>
		<row> train/prediction: 0.0/[0.14298853] </row>
		<row> train/prediction: 0.0/[0.14162432] </row>
		<row> train/prediction: 0.0/[0.14406973] </row>
		<row> train/prediction: 0.0/[0.14090069] </row>
		<row> train/prediction: 0.0/[0.12791128] </row>
		<row> train/prediction: 0.0/[0.10132387] </row>
		<row> train/prediction: 0.0/[0.07191087] </row>
		<row> train/prediction: 0.0/[0.05139863] </row>
		<row> train/prediction: 0.0/[0.03423728] </row>
		<row> train/prediction: 0.0/[0.02074935] </row>
		<row> train/prediction: 0.45/[0.02939724] </row>
		<row> train/prediction: 0.45/[0.06548964] </row>
		<row> train/prediction: 0.45/[0.09518526] </row>
		<row> train/prediction: 0.45/[0.12331931] </row>
		<row> train/prediction: 0.45/[0.15483743] </row>
		<row> train/prediction: 0.45/[0.19882694] </row>
		<row> train/prediction: 0.45/[0.22038105] </row>
		<row> train/prediction: 0.45/[0.21403563] </row>
		<row> train/prediction: 0.45/[0.20213115] </row>
		<row> train/prediction: 0.45/[0.18379825] </row>
		<row> train/prediction: 0.45/[0.15659949] </row>
		<row> train/prediction: 0.0/[0.13593788] </row>
		<row> train/prediction: 0.0/[0.12864162] </row>
		<row> train/prediction: 0.0/[0.1343964] </row>
		<row> train/prediction: 0.0/[0.14636827] </row>
		<row> train/prediction: 0.0/[0.15533632] </row>
		<row> train/prediction: 0.0/[0.15302563] </row>
		<row> train/prediction: 0.0/[0.13880086] </row>
		<row> train/prediction: 0.0/[0.12859479] </row>
		<row> train/prediction: 0.0/[0.11480403] </row>
		<row> train/prediction: 0.0/[0.09416978] </row>
		<row> train/prediction: 0.0/[0.07364609] </row>
		<row> train/prediction: 0.0/[0.05659717] </row>
		<row> train/prediction: 0.0/[0.04663104] </row>
		<row> train/prediction: 0.0/[0.03957108] </row>
		<row> train/prediction: 0.0/[0.02910316] </row>
		<row> train/prediction: 0.0/[0.01665965] </row>
		<row> train/prediction: 0.0/[0.00449219] </row>
		<row> train/prediction: 0.0/[-0.00416892] </row>
		<row> train/prediction: 0.0/[-0.00265583] </row>
		<row> train/prediction: 0.0/[0.00707594] </row>
		<row> train/prediction: 0.0/[0.0183946] </row>
		<row> train/prediction: 0.0/[0.02069321] </row>
		<row> train/prediction: 0.0/[0.01824757] </row>
		<row> train/prediction: 0.0/[0.0381994] </row>
		<row> train/prediction: 0.0/[0.05235068] </row>
		<row> train/prediction: 0.0/[0.05157099] </row>
		<row> train/prediction: 0.0/[0.04350691] </row>
		<row> train/prediction: 0.0/[0.03988098] </row>
		<row> train/prediction: 0.0/[0.05064318] </row>
		<row> train/prediction: 0.0/[0.07871312] </row>
		<row> train/prediction: 0.0/[0.10994667] </row>
		<row> train/prediction: 0.0/[0.13312548] </row>
		<row> train/prediction: 0.0/[0.15128893] </row>
		<row> train/prediction: 0.0/[0.16767603] </row>
		<row> train/prediction: 0.0/[0.17804508] </row>
		<row> train/prediction: 0.0/[0.1781328] </row>
		<row> train/prediction: 0.0/[0.17886549] </row>
		<row> train/prediction: 0.0/[0.17692366] </row>
		<row> train/prediction: 0.0/[0.1496908] </row>
		<row> train/prediction: 0.0/[0.10215552] </row>
		<row> train/prediction: 0.0/[0.0690893] </row>
		<row> train/prediction: 0.0/[0.05250872] </row>
		<row> train/prediction: 0.0/[0.03829673] </row>
		<row> train/prediction: 0.0/[0.02631164] </row>
		<row> train/prediction: 0.0/[0.01865431] </row>
		<row> train/prediction: 0.0/[0.01742086] </row>
		<row> train/prediction: 0.0/[0.02277797] </row>
		<row> train/prediction: 0.0/[0.02816465] </row>
		<row> train/prediction: 0.0/[0.032094] </row>
		<row> train/prediction: 0.0/[0.03413743] </row>
		<row> train/prediction: 0.0/[0.03164346] </row>
		<row> train/prediction: 0.0/[0.02863105] </row>
		<row> train/prediction: 0.0/[0.02601853] </row>
		<row> train/prediction: 0.0/[0.02614591] </row>
		<row> train/prediction: 0.0/[0.02818327] </row>
		<row> train/prediction: 0.0/[0.03263081] </row>
		<row> train/prediction: 0.0/[0.050899] </row>
		<row> train/prediction: 0.0/[0.09054565] </row>
		<row> train/prediction: 0.0/[0.1381025] </row>
		<row> train/prediction: 0.0/[0.18218651] </row>
		<row> train/prediction: 0.0/[0.21973196] </row>
		<row> train/prediction: 0.0/[0.2391603] </row>
		<row> train/prediction: 0.5/[0.23025995] </row>
		<row> train/prediction: 0.5/[0.22508526] </row>
		<row> train/prediction: 0.5/[0.21233967] </row>
		<row> train/prediction: 0.5/[0.2043201] </row>
		<row> train/prediction: 0.5/[0.26043728] </row>
		<row> train/prediction: 0.5/[0.34684196] </row>
		<row> train/prediction: 0.5/[0.34377554] </row>
		<row> train/prediction: 0.5/[0.27056512] </row>
		<row> train/prediction: 0.5/[0.1685054] </row>
		<row> train/prediction: 0.5/[0.09826568] </row>
		<row> train/prediction: 0.5/[0.07177368] </row>
		<row> train/prediction: 0.0/[0.06252234] </row>
		<row> train/prediction: 0.0/[0.0537981] </row>
		<row> train/prediction: 0.0/[0.04456982] </row>
		<row> train/prediction: 0.0/[0.03502648] </row>
		<row> train/prediction: 0.0/[0.02550591] </row>
		<row> train/prediction: 0.0/[0.01668757] </row>
		<row> train/prediction: 0.0/[0.00792793] </row>
		<row> train/prediction: 0.0/[-0.00059625] </row>
		<row> train/prediction: 0.0/[-0.00824908] </row>
		<row> train/prediction: 0.0/[-0.011592] </row>
		<row> train/prediction: 0.0/[0.00067776] </row>
		<row> train/prediction: 0.0/[0.01569811] </row>
		<row> train/prediction: 0.0/[0.03294652] </row>
		<row> train/prediction: 0.0/[0.06724915] </row>
		<row> train/prediction: 0.0/[0.10499065] </row>
		<row> train/prediction: 0.0/[0.14316489] </row>
		<row> train/prediction: 0.0/[0.17325541] </row>
		<row> train/prediction: 0.0/[0.1897678] </row>
		<row> train/prediction: 0.0/[0.19399634] </row>
		<row> train/prediction: 0.0/[0.19815241] </row>
		<row> train/prediction: 0.0/[0.21659866] </row>
		<row> train/prediction: 0.0/[0.20966741] </row>
		<row> train/prediction: 0.0/[0.16035745] </row>
		<row> train/prediction: 0.0/[0.12527543] </row>
		<row> train/prediction: 0.0/[0.1237587] </row>
		<row> train/prediction: 0.0/[0.1326535] </row>
		<row> train/prediction: 0.0/[0.12950005] </row>
		<row> train/prediction: 0.0/[0.11132266] </row>
		<row> train/prediction: 0.0/[0.09211858] </row>
		<row> train/prediction: 0.0/[0.07543825] </row>
		<row> train/prediction: 0.0/[0.05951388] </row>
		<row> train/prediction: 0.0/[0.04375449] </row>
		<row> train/prediction: 0.0/[0.03240876] </row>
		<row> train/prediction: 0.0/[0.03168712] </row>
		<row> train/prediction: 0.0/[0.03739643] </row>
		<row> train/prediction: 0.0/[0.08034518] </row>
		<row> train/prediction: 0.0/[0.16804913] </row>
		<row> train/prediction: 0.0/[0.19656238] </row>
		<row> train/prediction: 0.0/[0.24006152] </row>
		<row> train/prediction: 0.0/[0.24013203] </row>
		<row> train/prediction: 0.0/[0.18936524] </row>
		<row> train/prediction: 0.0/[0.15373379] </row>
		<row> train/prediction: 0.0/[0.14293176] </row>
		<row> train/prediction: 0.0/[0.12727444] </row>
		<row> train/prediction: 0.0/[0.10198742] </row>
		<row> train/prediction: 0.0/[0.07877488] </row>
		<row> train/prediction: 0.0/[0.05720785] </row>
		<row> train/prediction: 0.0/[0.03691005] </row>
		<row> train/prediction: 0.0/[0.02099542] </row>
		<row> train/prediction: 0.0/[0.01115184] </row>
		<row> train/prediction: 0.0/[0.00730173] </row>
		<row> train/prediction: 0.0/[0.01613097] </row>
		<row> train/prediction: 0.0/[0.01319688] </row>
		<row> train/prediction: 0.0/[0.00965045] </row>
		<row> train/prediction: 0.0/[0.00773873] </row>
		<row> train/prediction: 0.0/[0.00828194] </row>
		<row> train/prediction: 0.0/[0.00732369] </row>
		<row> train/prediction: 0.0/[0.00216384] </row>
		<row> train/prediction: 0.0/[-0.00328812] </row>
		<row> train/prediction: 0.0/[-0.00568568] </row>
		<row> train/prediction: 0.0/[-0.00300113] </row>
		<row> train/prediction: 0.0/[0.00298668] </row>
		<row> train/prediction: 0.0/[0.00303167] </row>
		<row> train/prediction: 0.0/[-0.00042937] </row>
		<row> train/prediction: 0.0/[0.00015733] </row>
		<row> train/prediction: 0.0/[0.00669151] </row>
		<row> train/prediction: 0.0/[0.00727662] </row>
		<row> train/prediction: 0.0/[0.00132755] </row>
		<row> train/prediction: 0.0/[-0.00441457] </row>
		<row> train/prediction: 0.0/[-0.0062292] </row>
		<row> train/prediction: 0.0/[-0.00521422] </row>
		<row> train/prediction: 0.0/[-0.00627071] </row>
		<row> train/prediction: 0.0/[-0.00849999] </row>
		<row> train/prediction: 0.0/[-0.00905006] </row>
		<row> train/prediction: 0.0/[-0.00929968] </row>
		<row> train/prediction: 0.0/[-0.01095555] </row>
		<row> train/prediction: 0.0/[-0.01003904] </row>
		<row> train/prediction: 0.0/[-0.00459395] </row>
		<row> train/prediction: 0.0/[0.00262118] </row>
		<row> train/prediction: 0.0/[0.0099619] </row>
		<row> train/prediction: 0.0/[0.01499331] </row>
		<row> train/prediction: 0.0/[0.01638619] </row>
		<row> train/prediction: 0.0/[0.01582975] </row>
		<row> train/prediction: 0.0/[0.01668726] </row>
		<row> train/prediction: 0.0/[0.01896582] </row>
		<row> train/prediction: 0.0/[0.02180459] </row>
		<row> train/prediction: 0.0/[0.02460786] </row>
		<row> train/prediction: 0.0/[0.02826983] </row>
		<row> train/prediction: 0.0/[0.03231505] </row>
		<row> train/prediction: 0.0/[0.03643669] </row>
		<row> train/prediction: 0.0/[0.03922293] </row>
		<row> train/prediction: 0.0/[0.04130768] </row>
		<row> train/prediction: 0.0/[0.03939975] </row>
		<row> train/prediction: 0.0/[0.03358369] </row>
		<row> train/prediction: 0.0/[0.03648475] </row>
		<row> train/prediction: 0.0/[0.06826121] </row>
		<row> train/prediction: 0.0/[0.07989097] </row>
		<row> train/prediction: 0.0/[0.09208882] </row>
		<row> train/prediction: 0.0/[0.09925027] </row>
		<row> train/prediction: 0.0/[0.09376709] </row>
		<row> train/prediction: 0.0/[0.08665115] </row>
		<row> train/prediction: 0.0/[0.07577216] </row>
		<row> train/prediction: 0.0/[0.06400874] </row>
		<row> train/prediction: 0.0/[0.05295426] </row>
		<row> train/prediction: 0.0/[0.04114611] </row>
		<row> train/prediction: 0.0/[0.03021953] </row>
		<row> train/prediction: 0.0/[0.01902517] </row>
		<row> train/prediction: 0.0/[0.00423986] </row>
		<row> train/prediction: 0.0/[-0.008861] </row>
		<row> train/prediction: 0.0/[-0.00939815] </row>
		<row> train/prediction: 0.0/[0.02200179] </row>
		<row> train/prediction: 0.0/[0.09886857] </row>
		<row> train/prediction: 0.3/[0.17027527] </row>
		<row> train/prediction: 0.3/[0.2166512] </row>
		<row> train/prediction: 0.3/[0.235856] </row>
		<row> train/prediction: 0.3/[0.2371161] </row>
		<row> train/prediction: 0.3/[0.22746181] </row>
		<row> train/prediction: 0.3/[0.22359994] </row>
		<row> train/prediction: 0.3/[0.2308484] </row>
		<row> train/prediction: 0.3/[0.22951284] </row>
		<row> train/prediction: 0.3/[0.22308418] </row>
		<row> train/prediction: 0.3/[0.21106666] </row>
		<row> train/prediction: 0.3/[0.17872737] </row>
		<row> train/prediction: 0.0/[0.13932951] </row>
		<row> train/prediction: 0.0/[0.11316042] </row>
		<row> train/prediction: 0.0/[0.09686679] </row>
		<row> train/prediction: 0.0/[0.08564712] </row>
		<row> train/prediction: 0.0/[0.07995898] </row>
		<row> train/prediction: 0.0/[0.07595] </row>
		<row> train/prediction: 0.0/[0.06954216] </row>
		<row> train/prediction: 0.0/[0.06276985] </row>
		<row> train/prediction: 0.0/[0.0561059] </row>
		<row> train/prediction: 0.0/[0.04801399] </row>
		<row> train/prediction: 0.0/[0.03917065] </row>
		<row> train/prediction: 0.0/[0.03166305] </row>
		<row> train/prediction: 0.0/[0.02689784] </row>
		<row> train/prediction: 0.0/[0.02534567] </row>
		<row> train/prediction: 0.0/[0.02662307] </row>
		<row> train/prediction: 0.0/[0.03119905] </row>
		<row> train/prediction: 0.0/[0.04023328] </row>
		<row> train/prediction: 0.0/[0.04297903] </row>
		<row> train/prediction: 0.0/[0.03879523] </row>
		<row> train/prediction: 0.0/[0.03908533] </row>
		<row> train/prediction: 0.0/[0.04431478] </row>
		<row> train/prediction: 0.0/[0.04905651] </row>
		<row> train/prediction: 0.0/[0.05029084] </row>
		<row> train/prediction: 0.0/[0.04712331] </row>
		<row> train/prediction: 0.0/[0.03840224] </row>
		<row> train/prediction: 0.0/[0.02703694] </row>
		<row> train/prediction: 0.0/[0.02099638] </row>
		<row> train/prediction: 0.0/[0.01805409] </row>
		<row> train/prediction: 0.0/[0.01247565] </row>
		<row> train/prediction: 0.0/[0.00896674] </row>
		<row> train/prediction: 0.0/[0.01519661] </row>
		<row> train/prediction: 0.0/[0.02292592] </row>
		<row> train/prediction: 0.0/[0.02664344] </row>
		<row> train/prediction: 0.0/[0.03084057] </row>
		<row> train/prediction: 0.0/[0.03358692] </row>
		<row> train/prediction: 0.0/[0.07164658] </row>
		<row> train/prediction: 0.71/[0.14377272] </row>
		<row> train/prediction: 0.71/[0.19397742] </row>
		<row> train/prediction: 0.71/[0.22426957] </row>
		<row> train/prediction: 0.71/[0.24589264] </row>
		<row> train/prediction: 0.71/[0.25195602] </row>
		<row> train/prediction: 0.71/[0.23769963] </row>
		<row> train/prediction: 0.71/[0.23063058] </row>
		<row> train/prediction: 0.71/[0.2193602] </row>
		<row> train/prediction: 0.71/[0.18469995] </row>
		<row> train/prediction: 0.71/[0.15080929] </row>
		<row> train/prediction: 0.71/[0.12819894] </row>
		<row> train/prediction: 0.0/[0.11479774] </row>
		<row> train/prediction: 0.0/[0.09863203] </row>
		<row> train/prediction: 0.0/[0.08231147] </row>
		<row> train/prediction: 0.0/[0.07085076] </row>
		<row> train/prediction: 0.0/[0.06524239] </row>
		<row> train/prediction: 0.0/[0.0654187] </row>
		<row> train/prediction: 0.0/[0.07267781] </row>
		<row> train/prediction: 0.0/[0.07575811] </row>
		<row> train/prediction: 0.0/[0.05875067] </row>
		<row> train/prediction: 0.0/[0.03393654] </row>
		<row> train/prediction: 0.0/[0.02404815] </row>
		<row> train/prediction: 0.0/[0.02585939] </row>
		<row> train/prediction: 0.0/[0.03168106] </row>
		<row> train/prediction: 0.0/[0.03647162] </row>
		<row> train/prediction: 0.0/[0.03645806] </row>
		<row> train/prediction: 0.0/[0.03310368] </row>
		<row> train/prediction: 0.0/[0.02904863] </row>
		<row> train/prediction: 0.0/[0.02879859] </row>
		<row> train/prediction: 0.0/[0.04326677] </row>
		<row> train/prediction: 0.0/[0.07746348] </row>
		<row> train/prediction: 0.8/[0.11778481] </row>
		<row> train/prediction: 0.8/[0.16464615] </row>
		<row> train/prediction: 0.8/[0.2155362] </row>
		<row> train/prediction: 0.8/[0.21042693] </row>
		<row> train/prediction: 0.8/[0.20608199] </row>
		<row> train/prediction: 0.8/[0.20981744] </row>
		<row> train/prediction: 0.8/[0.20014226] </row>
		<row> train/prediction: 0.8/[0.18232295] </row>
		<row> train/prediction: 0.8/[0.16199394] </row>
		<row> train/prediction: 0.8/[0.13821174] </row>
		<row> train/prediction: 0.8/[0.11606786] </row>
		<row> train/prediction: 0.0/[0.10485236] </row>
		<row> train/prediction: 0.0/[0.10821528] </row>
		<row> train/prediction: 0.0/[0.11076872] </row>
		<row> train/prediction: 0.0/[0.09746519] </row>
		<row> train/prediction: 0.0/[0.07891198] </row>
		<row> train/prediction: 0.0/[0.06568789] </row>
		<row> train/prediction: 0.0/[0.0509345] </row>
		<row> train/prediction: 0.0/[0.03097175] </row>
		<row> train/prediction: 0.0/[0.01450247] </row>
		<row> train/prediction: 0.0/[0.0185958] </row>
		<row> train/prediction: 0.0/[0.05366823] </row>
		<row> train/prediction: 0.0/[0.10017127] </row>
		<row> train/prediction: 0.0/[0.14474747] </row>
		<row> train/prediction: 0.0/[0.17902373] </row>
		<row> train/prediction: 0.0/[0.20506597] </row>
		<row> train/prediction: 0.0/[0.25978148] </row>
		<row> train/prediction: 0.0/[0.33755776] </row>
		<row> train/prediction: 0.0/[0.34014398] </row>
		<row> train/prediction: 0.0/[0.2389284] </row>
		<row> train/prediction: 0.0/[0.15527254] </row>
		<row> train/prediction: 0.0/[0.11595971] </row>
		<row> train/prediction: 0.0/[0.08717282] </row>
		<row> train/prediction: 0.0/[0.06329367] </row>
		<row> train/prediction: 0.0/[0.05423746] </row>
		<row> train/prediction: 0.0/[0.06674252] </row>
		<row> train/prediction: 0.0/[0.09209797] </row>
		<row> train/prediction: 0.12/[0.1312392] </row>
		<row> train/prediction: 0.12/[0.16882652] </row>
		<row> train/prediction: 0.12/[0.19872507] </row>
		<row> train/prediction: 0.12/[0.22519746] </row>
		<row> train/prediction: 0.12/[0.23109716] </row>
		<row> train/prediction: 0.12/[0.1974323] </row>
		<row> train/prediction: 0.12/[0.14885469] </row>
		<row> train/prediction: 0.12/[0.10720311] </row>
		<row> train/prediction: 0.12/[0.08404059] </row>
		<row> train/prediction: 0.12/[0.07178868] </row>
		<row> train/prediction: 0.12/[0.06235313] </row>
		<row> train/prediction: 0.0/[0.04860455] </row>
		<row> train/prediction: 0.0/[0.02980811] </row>
		<row> train/prediction: 0.0/[0.0181708] </row>
		<row> train/prediction: 0.0/[0.01299074] </row>
		<row> train/prediction: 0.0/[0.00503678] </row>
		<row> train/prediction: 0.0/[0.0001233] </row>
		<row> train/prediction: 0.0/[0.000576] </row>
		<row> train/prediction: 0.0/[0.00528114] </row>
		<row> train/prediction: 0.0/[0.01280848] </row>
		<row> train/prediction: 0.0/[0.01986838] </row>
		<row> train/prediction: 0.0/[0.02677204] </row>
		<row> train/prediction: 0.0/[0.03413839] </row>
		<row> train/prediction: 0.0/[0.04247715] </row>
		<row> train/prediction: 0.0/[0.04720768] </row>
		<row> train/prediction: 0.0/[0.0452748] </row>
		<row> train/prediction: 0.0/[0.04264897] </row>
		<row> train/prediction: 0.0/[0.04036189] </row>
		<row> train/prediction: 0.0/[0.03727473] </row>
		<row> train/prediction: 0.0/[0.03319866] </row>
		<row> train/prediction: 0.0/[0.02770692] </row>
		<row> train/prediction: 0.0/[0.0210101] </row>
		<row> train/prediction: 0.0/[0.01850883] </row>
		<row> train/prediction: 0.0/[0.02023515] </row>
		<row> train/prediction: 0.0/[0.02415319] </row>
		<row> train/prediction: 0.0/[0.03066757] </row>
		<row> train/prediction: 0.0/[0.04169806] </row>
		<row> train/prediction: 0.0/[0.05497159] </row>
		<row> train/prediction: 0.0/[0.0664674] </row>
		<row> train/prediction: 0.0/[0.07160644] </row>
		<row> train/prediction: 0.0/[0.07215711] </row>
		<row> train/prediction: 0.0/[0.07016667] </row>
		<row> train/prediction: 0.0/[0.06300381] </row>
		<row> train/prediction: 0.0/[0.0517372] </row>
		<row> train/prediction: 0.0/[0.05070926] </row>
		<row> train/prediction: 0.0/[0.06571195] </row>
		<row> train/prediction: 0.0/[0.0811162] </row>
		<row> train/prediction: 0.0/[0.09697232] </row>
		<row> train/prediction: 0.0/[0.1043845] </row>
		<row> train/prediction: 0.0/[0.09488647] </row>
		<row> train/prediction: 0.0/[0.08032265] </row>
		<row> train/prediction: 0.0/[0.0709244] </row>
		<row> train/prediction: 0.0/[0.06319529] </row>
		<row> train/prediction: 0.0/[0.05098353] </row>
		<row> train/prediction: 0.0/[0.03303885] </row>
		<row> train/prediction: 0.0/[0.02458497] </row>
		<row> train/prediction: 0.0/[0.01798977] </row>
		<row> train/prediction: 0.0/[0.00707159] </row>
		<row> train/prediction: 0.0/[0.00066438] </row>
		<row> train/prediction: 0.0/[-0.0019194] </row>
		<row> train/prediction: 0.0/[-0.00358982] </row>
		<row> train/prediction: 0.0/[-0.00580139] </row>
		<row> train/prediction: 0.0/[-0.00635762] </row>
		<row> train/prediction: 0.0/[0.01051962] </row>
		<row> train/prediction: 0.0/[0.04023432] </row>
		<row> train/prediction: 0.0/[0.05270103] </row>
		<row> train/prediction: 0.0/[0.0539641] </row>
		<row> train/prediction: 0.0/[0.04195138] </row>
		<row> train/prediction: 0.0/[0.02784107] </row>
		<row> train/prediction: 0.0/[0.02064351] </row>
		<row> train/prediction: 0.0/[0.01138093] </row>
		<row> train/prediction: 0.0/[0.00260151] </row>
		<row> train/prediction: 0.0/[-0.00058598] </row>
		<row> train/prediction: 0.0/[0.0029831] </row>
		<row> train/prediction: 0.0/[0.00873271] </row>
		<row> train/prediction: 0.0/[0.00899602] </row>
		<row> train/prediction: 0.0/[0.00795988] </row>
		<row> train/prediction: 0.0/[0.01337947] </row>
		<row> train/prediction: 0.0/[0.02775072] </row>
		<row> train/prediction: 0.0/[0.04377964] </row>
		<row> train/prediction: 0.0/[0.05546382] </row>
		<row> train/prediction: 0.0/[0.06433168] </row>
		<row> train/prediction: 0.0/[0.06876661] </row>
		<row> train/prediction: 0.0/[0.07370403] </row>
		<row> train/prediction: 0.0/[0.07873213] </row>
		<row> train/prediction: 0.0/[0.08462168] </row>
		<row> train/prediction: 0.0/[0.11535812] </row>
		<row> train/prediction: 0.0/[0.20818722] </row>
		<row> train/prediction: 0.0/[0.27711266] </row>
		<row> train/prediction: 0.0/[0.2803176] </row>
		<row> train/prediction: 0.0/[0.26406947] </row>
		<row> train/prediction: 0.0/[0.2579648] </row>
		<row> train/prediction: 0.0/[0.25380573] </row>
		<row> train/prediction: 0.0/[0.23611903] </row>
		<row> train/prediction: 0.0/[0.1851944] </row>
		<row> train/prediction: 0.0/[0.1317718] </row>
		<row> train/prediction: 0.0/[0.10781108] </row>
		<row> train/prediction: 0.0/[0.09344961] </row>
		<row> train/prediction: 0.0/[0.08105262] </row>
		<row> train/prediction: 0.0/[0.08027449] </row>
		<row> train/prediction: 0.0/[0.08713879] </row>
		<row> train/prediction: 0.0/[0.12922332] </row>
		<row> train/prediction: 0.0/[0.0974286] </row>
		<row> train/prediction: 0.0/[0.04608953] </row>
		<row> train/prediction: 0.0/[0.0283254] </row>
		<row> train/prediction: 0.0/[0.02417987] </row>
		<row> train/prediction: 0.0/[0.02318829] </row>
		<row> train/prediction: 0.0/[0.02309464] </row>
		<row> train/prediction: 0.0/[0.02162818] </row>
		<row> train/prediction: 0.0/[0.02043799] </row>
		<row> train/prediction: 0.0/[0.0227645] </row>
		<row> train/prediction: 0.0/[0.03329551] </row>
		<row> train/prediction: 0.0/[0.04016701] </row>
		<row> train/prediction: 0.0/[0.04053425] </row>
		<row> train/prediction: 0.0/[0.04401037] </row>
		<row> train/prediction: 0.0/[0.05394982] </row>
		<row> train/prediction: 0.0/[0.06361048] </row>
		<row> train/prediction: 0.0/[0.07733675] </row>
		<row> train/prediction: 0.0/[0.09101608] </row>
		<row> train/prediction: 0.0/[0.10190386] </row>
		<row> train/prediction: 0.0/[0.1112065] </row>
		<row> train/prediction: 0.0/[0.11811179] </row>
		<row> train/prediction: 0.0/[0.12277701] </row>
		<row> train/prediction: 0.0/[0.1310137] </row>
		<row> train/prediction: 0.0/[0.13800803] </row>
		<row> train/prediction: 0.0/[0.1402596] </row>
		<row> train/prediction: 0.0/[0.14308283] </row>
		<row> train/prediction: 0.0/[0.14629379] </row>
		<row> train/prediction: 0.0/[0.14959008] </row>
		<row> train/prediction: 0.0/[0.1517052] </row>
		<row> train/prediction: 0.0/[0.15224786] </row>
		<row> train/prediction: 0.0/[0.1495305] </row>
		<row> train/prediction: 0.0/[0.14430852] </row>
		<row> train/prediction: 0.0/[0.13785066] </row>
		<row> train/prediction: 0.0/[0.13483784] </row>
		<row> train/prediction: 0.0/[0.1339401] </row>
		<row> train/prediction: 0.0/[0.13570726] </row>
		<row> train/prediction: 0.0/[0.14429209] </row>
		<row> train/prediction: 0.0/[0.15252668] </row>
		<row> train/prediction: 0.0/[0.15977694] </row>
		<row> train/prediction: 0.0/[0.16381347] </row>
		<row> train/prediction: 0.0/[0.16315159] </row>
		<row> train/prediction: 0.0/[0.15222049] </row>
		<row> train/prediction: 0.0/[0.13156016] </row>
		<row> train/prediction: 0.0/[0.11180544] </row>
		<row> train/prediction: 0.0/[0.09277727] </row>
		<row> train/prediction: 0.0/[0.08208176] </row>
		<row> train/prediction: 0.0/[0.07577209] </row>
		<row> train/prediction: 0.0/[0.06758939] </row>
		<row> train/prediction: 0.0/[0.05695424] </row>
		<row> train/prediction: 0.0/[0.04475873] </row>
		<row> train/prediction: 0.0/[0.03579441] </row>
		<row> train/prediction: 0.0/[0.03197853] </row>
		<row> train/prediction: 0.0/[0.03061016] </row>
		<row> train/prediction: 0.0/[0.02919446] </row>
		<row> train/prediction: 0.0/[0.02827026] </row>
		<row> train/prediction: 0.0/[0.02711029] </row>
		<row> train/prediction: 0.0/[0.02551822] </row>
		<row> train/prediction: 0.0/[0.02417732] </row>
		<row> train/prediction: 0.0/[0.02236896] </row>
		<row> train/prediction: 0.0/[0.02097841] </row>
		<row> train/prediction: 0.0/[0.02113792] </row>
		<row> train/prediction: 0.0/[0.02106741] </row>
		<row> train/prediction: 0.0/[0.02036294] </row>
		<row> train/prediction: 0.0/[0.01937754] </row>
		<row> train/prediction: 0.0/[0.0182287] </row>
		<row> train/prediction: 0.0/[0.01755331] </row>
		<row> train/prediction: 0.0/[0.01727501] </row>
		<row> train/prediction: 0.0/[0.01719947] </row>
		<row> train/prediction: 0.0/[0.01757384] </row>
		<row> train/prediction: 0.0/[0.01757202] </row>
		<row> train/prediction: 0.0/[0.01800371] </row>
		<row> train/prediction: 0.0/[0.01912866] </row>
		<row> train/prediction: 0.0/[0.01850535] </row>
		<row> train/prediction: 0.0/[0.01743539] </row>
		<row> train/prediction: 0.0/[0.01716775] </row>
		<row> train/prediction: 0.0/[0.0179293] </row>
		<row> train/prediction: 0.0/[0.02056797] </row>
		<row> train/prediction: 0.0/[0.02121514] </row>
		<row> train/prediction: 0.0/[0.01906923] </row>
		<row> train/prediction: 0.0/[0.02048523] </row>
		<row> train/prediction: 0.0/[0.02553502] </row>
		<row> train/prediction: 0.0/[0.02809497] </row>
		<row> train/prediction: 0.0/[0.02797445] </row>
		<row> train/prediction: 0.0/[0.02610903] </row>
		<row> train/prediction: 0.0/[0.02337269] </row>
		<row> train/prediction: 0.0/[0.02144468] </row>
		<row> train/prediction: 0.0/[0.02090215] </row>
		<row> train/prediction: 0.0/[0.02144255] </row>
		<row> train/prediction: 0.0/[0.02077989] </row>
		<row> train/prediction: 0.0/[0.01895227] </row>
		<row> train/prediction: 0.0/[0.02115332] </row>
		<row> train/prediction: 0.0/[0.0234571] </row>
		<row> train/prediction: 0.0/[0.02494859] </row>
		<row> train/prediction: 0.0/[0.02930637] </row>
		<row> train/prediction: 0.0/[0.03058904] </row>
		<row> train/prediction: 0.0/[0.0274329] </row>
		<row> train/prediction: 0.0/[0.0255566] </row>
		<row> train/prediction: 0.0/[0.02374578] </row>
		<row> train/prediction: 0.0/[0.01928698] </row>
		<row> train/prediction: 0.0/[0.02184485] </row>
		<row> train/prediction: 0.0/[0.02510159] </row>
		<row> train/prediction: 0.0/[0.02399541] </row>
		<row> train/prediction: 0.0/[0.02229655] </row>
		<row> train/prediction: 0.0/[0.02048046] </row>
		<row> train/prediction: 0.0/[0.01948524] </row>
		<row> train/prediction: 0.0/[0.02035087] </row>
		<row> train/prediction: 0.0/[0.02279161] </row>
		<row> train/prediction: 0.0/[0.02479506] </row>
		<row> train/prediction: 0.0/[0.02540139] </row>
		<row> train/prediction: 0.0/[0.02418499] </row>
		<row> train/prediction: 0.0/[0.02220983] </row>
		<row> train/prediction: 0.0/[0.0244514] </row>
		<row> train/prediction: 0.0/[0.02613255] </row>
		<row> train/prediction: 0.0/[0.02332144] </row>
		<row> train/prediction: 0.0/[0.02037815] </row>
		<row> train/prediction: 0.0/[0.02088109] </row>
		<row> train/prediction: 0.0/[0.02211352] </row>
		<row> train/prediction: 0.0/[0.02121074] </row>
		<row> train/prediction: 0.0/[0.02006071] </row>
		<row> train/prediction: 0.0/[0.02111942] </row>
		<row> train/prediction: 0.0/[0.01982761] </row>
		<row> train/prediction: 0.0/[0.01994585] </row>
		<row> train/prediction: 0.0/[0.02164954] </row>
		<row> train/prediction: 0.0/[0.02324354] </row>
		<row> train/prediction: 0.0/[0.02278033] </row>
		<row> train/prediction: 0.0/[0.02281667] </row>
		<row> train/prediction: 0.0/[0.02697613] </row>
		<row> train/prediction: 0.0/[0.03388006] </row>
		<row> train/prediction: 0.0/[0.0344809] </row>
		<row> train/prediction: 0.0/[0.0259385] </row>
		<row> train/prediction: 0.0/[0.01800293] </row>
		<row> train/prediction: 0.0/[0.03059699] </row>
		<row> train/prediction: 0.0/[0.06448106] </row>
		<row> train/prediction: 0.0/[0.08083253] </row>
		<row> train/prediction: 0.0/[0.07772847] </row>
		<row> train/prediction: 0.0/[0.05322266] </row>
		<row> train/prediction: 0.0/[0.02435513] </row>
		<row> train/prediction: 0.0/[0.00764655] </row>
		<row> train/prediction: 0.0/[0.00564808] </row>
		<row> train/prediction: 0.0/[0.00908611] </row>
		<row> train/prediction: 0.0/[0.01127457] </row>
		<row> train/prediction: 0.0/[0.01291512] </row>
		<row> train/prediction: 0.0/[0.01600325] </row>
		<row> train/prediction: 0.0/[0.02316453] </row>
		<row> train/prediction: 0.0/[0.03083845] </row>
		<row> train/prediction: 0.0/[0.01570601] </row>
		<row> train/prediction: 0.0/[0.01089323] </row>
		<row> train/prediction: 0.0/[0.02045235] </row>
		<row> train/prediction: 0.0/[0.02500271] </row>
		<row> train/prediction: 0.0/[0.02724555] </row>
		<row> train/prediction: 0.0/[0.03158084] </row>
		<row> train/prediction: 0.0/[0.032657] </row>
		<row> train/prediction: 0.0/[0.02111867] </row>
		<row> train/prediction: 0.0/[0.00356265] </row>
		<row> train/prediction: 0.0/[-0.00961713] </row>
		<row> train/prediction: 0.0/[-0.01567224] </row>
		<row> train/prediction: 0.0/[-0.00330926] </row>
		<row> train/prediction: 0.0/[0.06842211] </row>
		<row> train/prediction: 0.4/[0.16187564] </row>
		<row> train/prediction: 0.4/[0.2113275] </row>
		<row> train/prediction: 0.4/[0.23071292] </row>
		<row> train/prediction: 0.4/[0.23032036] </row>
		<row> train/prediction: 0.4/[0.22844303] </row>
		<row> train/prediction: 0.4/[0.22322682] </row>
		<row> train/prediction: 0.4/[0.21286571] </row>
		<row> train/prediction: 0.4/[0.1956088] </row>
		<row> train/prediction: 0.4/[0.19227618] </row>
		<row> train/prediction: 0.4/[0.15569523] </row>
		<row> train/prediction: 0.4/[0.07621116] </row>
		<row> train/prediction: 0.0/[0.03787674] </row>
		<row> train/prediction: 0.0/[0.03267806] </row>
		<row> train/prediction: 0.0/[0.03875297] </row>
		<row> train/prediction: 0.0/[0.04210133] </row>
		<row> train/prediction: 0.0/[0.03866357] </row>
		<row> train/prediction: 0.0/[0.0369842] </row>
		<row> train/prediction: 0.0/[0.04629733] </row>
		<row> train/prediction: 0.0/[0.06088267] </row>
		<row> train/prediction: 0.0/[0.06332111] </row>
		<row> train/prediction: 0.0/[0.05442095] </row>
		<row> train/prediction: 0.0/[0.04370964] </row>
		<row> train/prediction: 0.0/[0.03605692] </row>
		<row> train/prediction: 0.4/[0.02962926] </row>
		<row> train/prediction: 0.4/[0.02468177] </row>
		<row> train/prediction: 0.4/[0.0191366] </row>
		<row> train/prediction: 0.4/[0.01199245] </row>
		<row> train/prediction: 0.4/[0.0049308] </row>
		<row> train/prediction: 0.4/[0.01025807] </row>
		<row> train/prediction: 0.4/[0.05861549] </row>
		<row> train/prediction: 0.4/[0.12738849] </row>
		<row> train/prediction: 0.4/[0.20237383] </row>
		<row> train/prediction: 0.4/[0.26723203] </row>
		<row> train/prediction: 0.4/[0.28422913] </row>
		<row> train/prediction: 0.0/[0.28459173] </row>
		<row> train/prediction: 0.0/[0.2899721] </row>
		<row> train/prediction: 0.0/[0.28665453] </row>
		<row> train/prediction: 0.0/[0.26964515] </row>
		<row> train/prediction: 0.0/[0.24804735] </row>
		<row> train/prediction: 0.0/[0.1949408] </row>
		<row> train/prediction: 0.0/[0.16986969] </row>
		<row> train/prediction: 0.0/[0.17057016] </row>
		<row> train/prediction: 0.0/[0.17299123] </row>
		<row> train/prediction: 0.0/[0.16899374] </row>
		<row> train/prediction: 0.0/[0.16588953] </row>
		<row> train/prediction: 0.0/[0.16090152] </row>
		<row> train/prediction: 0.0/[0.14982104] </row>
		<row> train/prediction: 0.0/[0.13408993] </row>
		<row> train/prediction: 0.0/[0.112726] </row>
		<row> train/prediction: 0.0/[0.08889832] </row>
		<row> train/prediction: 0.0/[0.0694333] </row>
		<row> train/prediction: 0.0/[0.0575076] </row>
		<row> train/prediction: 0.0/[0.05032068] </row>
		<row> train/prediction: 0.0/[0.04260852] </row>
		<row> train/prediction: 0.0/[0.03695334] </row>
		<row> train/prediction: 0.0/[0.03463831] </row>
		<row> train/prediction: 0.0/[0.03266741] </row>
		<row> train/prediction: 0.0/[0.03340374] </row>
		<row> train/prediction: 0.0/[0.04519798] </row>
		<row> train/prediction: 0.0/[0.0581428] </row>
		<row> train/prediction: 0.0/[0.06783473] </row>
		<row> train/prediction: 0.0/[0.09405939] </row>
		<row> train/prediction: 0.0/[0.11163535] </row>
		<row> train/prediction: 0.0/[0.11295528] </row>
		<row> train/prediction: 0.0/[0.1222427] </row>
		<row> train/prediction: 0.0/[0.12811992] </row>
		<row> train/prediction: 0.0/[0.11809866] </row>
		<row> train/prediction: 0.0/[0.11467114] </row>
		<row> train/prediction: 0.0/[0.1266381] </row>
		<row> train/prediction: 0.0/[0.11896876] </row>
		<row> train/prediction: 0.0/[0.05768815] </row>
		<row> train/prediction: 0.0/[0.00055306] </row>
		<row> train/prediction: 0.0/[-0.03633911] </row>
		<row> train/prediction: 0.0/[-0.05137338] </row>
		<row> train/prediction: 0.0/[-0.05083332] </row>
		<row> train/prediction: 0.0/[-0.04030357] </row>
		<row> train/prediction: 0.0/[-0.02756316] </row>
		<row> train/prediction: 0.0/[-0.01446912] </row>
		<row> train/prediction: 0.0/[-0.00543008] </row>
		<row> train/prediction: 0.0/[-0.00098365] </row>
		<row> train/prediction: 0.0/[0.00499799] </row>
		<row> train/prediction: 0.0/[0.01618779] </row>
		<row> train/prediction: 0.0/[0.030178] </row>
		<row> train/prediction: 0.0/[0.01295698] </row>
		<row> train/prediction: 0.0/[0.00848118] </row>
		<row> train/prediction: 0.0/[0.01733313] </row>
		<row> train/prediction: 0.0/[0.0254057] </row>
		<row> train/prediction: 0.0/[0.0385442] </row>
		<row> train/prediction: 0.0/[0.07407781] </row>
		<row> train/prediction: 0.0/[0.12276122] </row>
		<row> train/prediction: 0.0/[0.16950029] </row>
		<row> train/prediction: 0.0/[0.20352757] </row>
		<row> train/prediction: 0.0/[0.21370018] </row>
		<row> train/prediction: 0.0/[0.21679458] </row>
		<row> train/prediction: 0.0/[0.19286403] </row>
		<row> train/prediction: 0.0/[0.14209676] </row>
		<row> train/prediction: 0.0/[0.09461365] </row>
		<row> train/prediction: 0.0/[0.06460864] </row>
		<row> train/prediction: 0.0/[0.05003325] </row>
		<row> train/prediction: 0.0/[0.05429005] </row>
		<row> train/prediction: 0.0/[0.0744367] </row>
		<row> train/prediction: 0.0/[0.09954343] </row>
		<row> train/prediction: 0.0/[0.13014713] </row>
		<row> train/prediction: 0.0/[0.15448071] </row>
		<row> train/prediction: 0.0/[0.14258564] </row>
		<row> train/prediction: 0.0/[0.10603564] </row>
		<row> train/prediction: 0.0/[0.12288955] </row>
		<row> train/prediction: 0.0/[0.12409642] </row>
		<row> train/prediction: 0.0/[0.09689064] </row>
		<row> train/prediction: 0.0/[0.06771792] </row>
		<row> train/prediction: 0.4/[0.04887061] </row>
		<row> train/prediction: 0.4/[0.04981969] </row>
		<row> train/prediction: 0.4/[0.07097383] </row>
		<row> train/prediction: 0.4/[0.09514127] </row>
		<row> train/prediction: 0.4/[0.09282281] </row>
		<row> train/prediction: 0.4/[0.06573717] </row>
		<row> train/prediction: 0.4/[0.04747548] </row>
		<row> train/prediction: 0.4/[0.03656423] </row>
		<row> train/prediction: 0.4/[0.02978626] </row>
		<row> train/prediction: 0.4/[0.02626955] </row>
		<row> train/prediction: 0.4/[0.02367408] </row>
		<row> train/prediction: 0.0/[0.02697531] </row>
		<row> train/prediction: 0.0/[0.06134047] </row>
		<row> train/prediction: 0.0/[0.15010685] </row>
		<row> train/prediction: 0.0/[0.22539183] </row>
		<row> train/prediction: 0.0/[0.2450419] </row>
		<row> train/prediction: 0.0/[0.2468979] </row>
		<row> train/prediction: 0.0/[0.24416682] </row>
		<row> train/prediction: 0.0/[0.21911612] </row>
		<row> train/prediction: 0.0/[0.15854211] </row>
		<row> train/prediction: 0.0/[0.09389712] </row>
		<row> train/prediction: 0.0/[0.04269868] </row>
		<row> train/prediction: 0.0/[0.02604722] </row>
		<row> train/prediction: 0.0/[0.02364432] </row>
		<row> train/prediction: 0.0/[0.0225996] </row>
		<row> train/prediction: 0.0/[0.02132732] </row>
		<row> train/prediction: 0.0/[0.01889803] </row>
		<row> train/prediction: 0.0/[0.01668901] </row>
		<row> train/prediction: 0.0/[0.0154342] </row>
		<row> train/prediction: 0.0/[0.01466226] </row>
		<row> train/prediction: 0.0/[0.01320458] </row>
		<row> train/prediction: 0.0/[0.01181168] </row>
		<row> train/prediction: 0.0/[0.01057276] </row>
		<row> train/prediction: 0.0/[0.00686453] </row>
		<row> train/prediction: 0.0/[0.0026292] </row>
		<row> train/prediction: 0.0/[0.00147802] </row>
		<row> train/prediction: 0.0/[0.00283244] </row>
		<row> train/prediction: 0.0/[0.00361992] </row>
		<row> train/prediction: 0.0/[0.00156056] </row>
		<row> train/prediction: 0.0/[-7.493049e-05] </row>
		<row> train/prediction: 0.0/[0.00118258] </row>
		<row> train/prediction: 0.0/[0.00606064] </row>
		<row> train/prediction: 0.0/[0.01252777] </row>
		<row> train/prediction: 0.0/[0.01350422] </row>
		<row> train/prediction: 0.0/[0.00641359] </row>
		<row> train/prediction: 0.0/[-0.00557078] </row>
		<row> train/prediction: 0.0/[-0.01473122] </row>
		<row> train/prediction: 0.0/[-0.01573509] </row>
		<row> train/prediction: 0.0/[-0.00730035] </row>
		<row> train/prediction: 0.0/[0.00370569] </row>
		<row> train/prediction: 0.0/[0.01545384] </row>
		<row> train/prediction: 0.0/[0.02591611] </row>
		<row> train/prediction: 0.0/[0.02005563] </row>
		<row> train/prediction: 0.0/[0.00442722] </row>
		<row> train/prediction: 0.0/[-0.00728083] </row>
		<row> train/prediction: 0.0/[-0.01070694] </row>
		<row> train/prediction: 0.0/[-0.00849645] </row>
		<row> train/prediction: 0.0/[0.00076515] </row>
		<row> train/prediction: 0.0/[0.0096387] </row>
		<row> train/prediction: 0.0/[0.0111216] </row>
		<row> train/prediction: 0.0/[0.01076766] </row>
		<row> train/prediction: 0.0/[0.01230135] </row>
		<row> train/prediction: 0.0/[0.01046771] </row>
		<row> train/prediction: 0.0/[0.00520969] </row>
		<row> train/prediction: 0.0/[-0.00330598] </row>
		<row> train/prediction: 0.0/[-0.01244092] </row>
		<row> train/prediction: 0.0/[-0.01541162] </row>
		<row> train/prediction: 0.0/[-0.01686764] </row>
		<row> train/prediction: 0.0/[-0.01981396] </row>
		<row> train/prediction: 0.0/[-0.01352538] </row>
		<row> train/prediction: 0.0/[-0.00532456] </row>
		<row> train/prediction: 0.0/[-0.00177705] </row>
		<row> train/prediction: 0.0/[-0.00069152] </row>
		<row> train/prediction: 0.0/[-0.00114012] </row>
		<row> train/prediction: 0.0/[-0.00324541] </row>
		<row> train/prediction: 0.0/[-0.00280568] </row>
		<row> train/prediction: 0.0/[0.00307223] </row>
		<row> train/prediction: 0.0/[0.0113306] </row>
		<row> train/prediction: 0.0/[0.01503764] </row>
		<row> train/prediction: 0.0/[0.01509046] </row>
		<row> train/prediction: 0.0/[0.01506221] </row>
		<row> train/prediction: 0.0/[0.0158271] </row>
		<row> train/prediction: 0.0/[0.02009776] </row>
		<row> train/prediction: 0.0/[0.03156359] </row>
		<row> train/prediction: 0.0/[0.05233183] </row>
		<row> train/prediction: 0.0/[0.08632934] </row>
		<row> train/prediction: 0.0/[0.14400826] </row>
		<row> train/prediction: 0.0/[0.19339228] </row>
		<row> train/prediction: 0.0/[0.21045685] </row>
		<row> train/prediction: 0.0/[0.2162559] </row>
		<row> train/prediction: 0.0/[0.19892216] </row>
		<row> train/prediction: 0.0/[0.17654333] </row>
		<row> train/prediction: 0.0/[0.16423759] </row>
		<row> train/prediction: 0.0/[0.15643394] </row>
		<row> train/prediction: 0.0/[0.15042344] </row>
		<row> train/prediction: 0.0/[0.14011237] </row>
		<row> train/prediction: 0.0/[0.11649378] </row>
		<row> train/prediction: 0.0/[0.07841884] </row>
		<row> train/prediction: 0.0/[0.06003541] </row>
		<row> train/prediction: 0.0/[0.06043664] </row>
		<row> train/prediction: 0.35000000000000003/[0.06444113] </row>
		<row> train/prediction: 0.35000000000000003/[0.0998025] </row>
		<row> train/prediction: 0.35000000000000003/[0.15858679] </row>
		<row> train/prediction: 0.35000000000000003/[0.20047736] </row>
		<row> train/prediction: 0.35000000000000003/[0.20928457] </row>
		<row> train/prediction: 0.35000000000000003/[0.20234743] </row>
		<row> train/prediction: 0.35000000000000003/[0.18737152] </row>
		<row> train/prediction: 0.35000000000000003/[0.1692521] </row>
		<row> train/prediction: 0.35000000000000003/[0.14436616] </row>
		<row> train/prediction: 0.35000000000000003/[0.0997051] </row>
		<row> train/prediction: 0.35000000000000003/[0.05801316] </row>
		<row> train/prediction: 0.0/[0.04144621] </row>
		<row> train/prediction: 0.0/[0.04153487] </row>
		<row> train/prediction: 0.0/[0.04912702] </row>
		<row> train/prediction: 0.0/[0.06524983] </row>
		<row> train/prediction: 0.0/[0.08572367] </row>
		<row> train/prediction: 0.0/[0.10314401] </row>
		<row> train/prediction: 0.0/[0.10271324] </row>
		<row> train/prediction: 0.0/[0.08814141] </row>
		<row> train/prediction: 0.0/[0.05807802] </row>
		<row> train/prediction: 0.0/[0.04064358] </row>
		<row> train/prediction: 0.0/[0.03803419] </row>
		<row> train/prediction: 0.0/[0.04067628] </row>
		<row> train/prediction: 0.0/[0.04268902] </row>
		<row> train/prediction: 0.0/[0.03943288] </row>
		<row> train/prediction: 0.0/[0.03440369] </row>
		<row> train/prediction: 0.0/[0.0269555] </row>
		<row> train/prediction: 0.0/[0.01820869] </row>
		<row> train/prediction: 0.0/[0.01135117] </row>
		<row> train/prediction: 0.0/[0.00806207] </row>
		<row> train/prediction: 0.0/[0.00589355] </row>
		<row> train/prediction: 0.0/[0.00419437] </row>
		<row> train/prediction: 0.0/[0.00370052] </row>
		<row> train/prediction: 0.0/[0.00322462] </row>
		<row> train/prediction: 0.0/[0.00115676] </row>
		<row> train/prediction: 0.0/[-7.297844e-05] </row>
		<row> train/prediction: 0.0/[-0.00082238] </row>
		<row> train/prediction: 0.0/[0.00218614] </row>
		<row> train/prediction: 0.0/[0.00882971] </row>
		<row> train/prediction: 0.0/[0.00915887] </row>
		<row> train/prediction: 0.0/[0.00632552] </row>
		<row> train/prediction: 0.0/[0.00737314] </row>
		<row> train/prediction: 0.0/[0.01222029] </row>
		<row> train/prediction: 0.0/[0.01450999] </row>
		<row> train/prediction: 0.0/[0.02576561] </row>
		<row> train/prediction: 0.0/[0.05158328] </row>
		<row> train/prediction: 0.25/[0.09028114] </row>
		<row> train/prediction: 0.25/[0.12789413] </row>
		<row> train/prediction: 0.25/[0.15737787] </row>
		<row> train/prediction: 0.25/[0.18041639] </row>
		<row> train/prediction: 0.25/[0.19642852] </row>
		<row> train/prediction: 0.25/[0.2026183] </row>
		<row> train/prediction: 0.25/[0.19528928] </row>
		<row> train/prediction: 0.25/[0.18028966] </row>
		<row> train/prediction: 0.25/[0.18287566] </row>
		<row> train/prediction: 0.25/[0.20865345] </row>
		<row> train/prediction: 0.25/[0.2215975] </row>
		<row> train/prediction: 0.0/[0.20179763] </row>
		<row> train/prediction: 0.0/[0.16680992] </row>
		<row> train/prediction: 0.0/[0.13867141] </row>
		<row> train/prediction: 0.0/[0.12179406] </row>
		<row> train/prediction: 0.0/[0.1113755] </row>
		<row> train/prediction: 0.0/[0.1021702] </row>
		<row> train/prediction: 0.0/[0.09221646] </row>
		<row> train/prediction: 0.0/[0.0824485] </row>
		<row> train/prediction: 0.0/[0.07338141] </row>
		<row> train/prediction: 0.0/[0.06496836] </row>
		<row> train/prediction: 0.0/[0.05839387] </row>
		<row> train/prediction: 0.0/[0.05450015] </row>
		<row> train/prediction: 0.0/[0.05362763] </row>
		<row> train/prediction: 0.0/[0.05123556] </row>
		<row> train/prediction: 0.0/[0.04636625] </row>
		<row> train/prediction: 0.0/[0.04734269] </row>
		<row> train/prediction: 0.0/[0.03677399] </row>
		<row> train/prediction: 0.0/[0.01854133] </row>
		<row> train/prediction: 0.0/[0.00781713] </row>
		<row> train/prediction: 0.0/[0.00890776] </row>
		<row> train/prediction: 0.6/[0.03777555] </row>
		<row> train/prediction: 0.6/[0.0938385] </row>
		<row> train/prediction: 0.6/[0.1464386] </row>
		<row> train/prediction: 0.6/[0.1816754] </row>
		<row> train/prediction: 0.6/[0.19714053] </row>
		<row> train/prediction: 0.6/[0.18567482] </row>
		<row> train/prediction: 0.6/[0.17825574] </row>
		<row> train/prediction: 0.6/[0.20365718] </row>
		<row> train/prediction: 0.6/[0.2041595] </row>
		<row> train/prediction: 0.6/[0.18449512] </row>
		<row> train/prediction: 0.6/[0.15581289] </row>
		<row> train/prediction: 0.0/[0.12042257] </row>
		<row> train/prediction: 0.0/[0.08576629] </row>
		<row> train/prediction: 0.0/[0.06526408] </row>
		<row> train/prediction: 0.0/[0.05721935] </row>
		<row> train/prediction: 0.0/[0.05390476] </row>
		<row> train/prediction: 0.0/[0.05121163] </row>
		<row> train/prediction: 0.0/[0.05031933] </row>
		<row> train/prediction: 0.0/[0.04150652] </row>
		<row> train/prediction: 0.0/[0.03334093] </row>
		<row> train/prediction: 0.0/[0.03461669] </row>
		<row> train/prediction: 0.0/[0.03877706] </row>
		<row> train/prediction: 0.0/[0.04047205] </row>
		<row> train/prediction: 0.0/[0.03639975] </row>
		<row> train/prediction: 0.0/[0.02794374] </row>
		<row> train/prediction: 0.0/[0.02334154] </row>
		<row> train/prediction: 0.0/[0.0268638] </row>
		<row> train/prediction: 0.0/[0.02579491] </row>
		<row> train/prediction: 0.0/[0.02123943] </row>
		<row> train/prediction: 0.0/[0.01841027] </row>
		<row> train/prediction: 0.0/[0.01957019] </row>
		<row> train/prediction: 0.0/[0.02553991] </row>
		<row> train/prediction: 0.0/[0.0297845] </row>
		<row> train/prediction: 0.0/[0.0307402] </row>
		<row> train/prediction: 0.0/[0.0320057] </row>
		<row> train/prediction: 0.0/[0.02521049] </row>
		<row> train/prediction: 0.0/[0.01910168] </row>
		<row> train/prediction: 0.0/[0.02006838] </row>
		<row> train/prediction: 0.0/[0.02387075] </row>
		<row> train/prediction: 0.0/[0.0248787] </row>
		<row> train/prediction: 0.0/[0.02387993] </row>
		<row> train/prediction: 0.0/[0.0246973] </row>
		<row> train/prediction: 0.0/[0.02632143] </row>
		<row> train/prediction: 0.0/[0.02655149] </row>
		<row> train/prediction: 0.0/[0.02625632] </row>
		<row> train/prediction: 0.0/[0.0265626] </row>
		<row> train/prediction: 0.0/[0.02783193] </row>
		<row> train/prediction: 0.0/[0.02938212] </row>
		<row> train/prediction: 0.0/[0.03020696] </row>
		<row> train/prediction: 0.0/[0.03076492] </row>
		<row> train/prediction: 0.0/[0.03215492] </row>
		<row> train/prediction: 0.0/[0.03445999] </row>
		<row> train/prediction: 0.0/[0.03699256] </row>
		<row> train/prediction: 0.0/[0.03818628] </row>
		<row> train/prediction: 0.0/[0.0377262] </row>
		<row> train/prediction: 0.0/[0.03688842] </row>
		<row> train/prediction: 0.0/[0.03726086] </row>
		<row> train/prediction: 0.0/[0.04341049] </row>
		<row> train/prediction: 0.0/[0.0528445] </row>
		<row> train/prediction: 0.0/[0.06280329] </row>
		<row> train/prediction: 0.0/[0.07348385] </row>
		<row> train/prediction: 0.0/[0.07894772] </row>
		<row> train/prediction: 0.0/[0.07823914] </row>
		<row> train/prediction: 0.0/[0.07519235] </row>
		<row> train/prediction: 0.0/[0.06716064] </row>
		<row> train/prediction: 0.0/[0.05702597] </row>
		<row> train/prediction: 0.0/[0.04954352] </row>
		<row> train/prediction: 0.0/[0.04238349] </row>
		<row> train/prediction: 0.0/[0.0303603] </row>
		<row> train/prediction: 0.0/[0.01883324] </row>
		<row> train/prediction: 0.0/[0.01373255] </row>
		<row> train/prediction: 0.0/[0.01429502] </row>
		<row> train/prediction: 0.0/[0.016047] </row>
		<row> train/prediction: 0.0/[0.01964892] </row>
		<row> train/prediction: 0.0/[0.02157941] </row>
		<row> train/prediction: 0.0/[0.02224557] </row>
		<row> train/prediction: 0.0/[0.01934887] </row>
		<row> train/prediction: 0.0/[0.01033077] </row>
		<row> train/prediction: 0.0/[0.00145545] </row>
		<row> train/prediction: 0.0/[0.00158622] </row>
		<row> train/prediction: 0.0/[0.01317289] </row>
		<row> train/prediction: 0.0/[0.01825366] </row>
		<row> train/prediction: 0.0/[0.01450582] </row>
		<row> train/prediction: 0.0/[0.00870346] </row>
		<row> train/prediction: 0.0/[0.01122529] </row>
		<row> train/prediction: 0.0/[0.03525915] </row>
		<row> train/prediction: 0.0/[0.06022211] </row>
		<row> train/prediction: 0.0/[0.06404056] </row>
		<row> train/prediction: 0.0/[0.07148135] </row>
		<row> train/prediction: 0.0/[0.08069564] </row>
		<row> train/prediction: 0.0/[0.08881423] </row>
		<row> train/prediction: 0.0/[0.12147851] </row>
		<row> train/prediction: 0.0/[0.13883322] </row>
		<row> train/prediction: 0.0/[0.1584289] </row>
		<row> train/prediction: 0.0/[0.16292462] </row>
		<row> train/prediction: 0.01/[0.11677179] </row>
		<row> train/prediction: 0.01/[0.08459622] </row>
		<row> train/prediction: 0.01/[0.07799958] </row>
		<row> train/prediction: 0.01/[0.09699254] </row>
		<row> train/prediction: 0.01/[0.11572825] </row>
		<row> train/prediction: 0.01/[0.09207737] </row>
		<row> train/prediction: 0.01/[0.0643332] </row>
		<row> train/prediction: 0.01/[0.06987807] </row>
		<row> train/prediction: 0.01/[0.08266184] </row>
		<row> train/prediction: 0.01/[0.1010641] </row>
		<row> train/prediction: 0.01/[0.13565695] </row>
		<row> train/prediction: 0.0/[0.16346715] </row>
		<row> train/prediction: 0.0/[0.15830228] </row>
		<row> train/prediction: 0.0/[0.14360368] </row>
		<row> train/prediction: 0.0/[0.1430921] </row>
		<row> train/prediction: 0.0/[0.14957318] </row>
		<row> train/prediction: 0.0/[0.14635116] </row>
		<row> train/prediction: 0.0/[0.10654636] </row>
		<row> train/prediction: 0.18/[0.06336012] </row>
		<row> train/prediction: 0.18/[0.05784661] </row>
		<row> train/prediction: 0.18/[0.06462687] </row>
		<row> train/prediction: 0.18/[0.07520171] </row>
		<row> train/prediction: 0.18/[0.09127589] </row>
		<row> train/prediction: 0.18/[0.11992765] </row>
		<row> train/prediction: 0.18/[0.21202737] </row>
		<row> train/prediction: 0.18/[0.2616258] </row>
		<row> train/prediction: 0.18/[0.25829726] </row>
		<row> train/prediction: 0.18/[0.24586782] </row>
		<row> train/prediction: 0.18/[0.25631443] </row>
		<row> train/prediction: 0.0/[0.24591851] </row>
		<row> train/prediction: 0.0/[0.21893498] </row>
		<row> train/prediction: 0.0/[0.17043272] </row>
		<row> train/prediction: 0.0/[0.12428996] </row>
		<row> train/prediction: 0.0/[0.090994] </row>
		<row> train/prediction: 0.0/[0.06742684] </row>
		<row> train/prediction: 0.0/[0.04801533] </row>
		<row> train/prediction: 0.0/[0.0335806] </row>
		<row> train/prediction: 0.0/[0.02447168] </row>
		<row> train/prediction: 0.0/[0.0193617] </row>
		<row> train/prediction: 0.0/[0.01661537] </row>
		<row> train/prediction: 0.0/[0.01640733] </row>
		<row> train/prediction: 0.0/[0.01631085] </row>
	</data>
</root>
